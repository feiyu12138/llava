[2024-03-23 15:45:53,010] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:45:56,565] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7: setting --include=localhost:0,1,2,3,4,5,6,7
[2024-03-23 15:45:56,565] [INFO] [runner.py:571:main] cmd = /home/jchen293/.conda/envs/llava_git/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path lmsys/vicuna-7b-v1.5 --version v1 --data_path /datasets/jchen293/data/llava_datasets/LLaVA-Tuning/llava_v1_5_mix665k.json --image_folder /datasets/jchen293/data/llava_datasets/LLaVA-Tuning --vision_tower openai/clip-vit-large-patch14-336 --pretrain_mm_mlp_adapter /datasets/jchen293/weights/llava/checkpoint/llava-v1.5-7b-pretrain-stride-8-layer-16-grouping-avgpool1d/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /datasets/jchen293/weights/llava/checkpoint/llava-v1.5-7b-stride-8-layer-16-grouping-avgpool1d --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb --stride 8 --layer 16 --grouping avgpool1d
[2024-03-23 15:45:59,055] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:00,942] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-03-23 15:46:00,942] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-03-23 15:46:00,942] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-03-23 15:46:00,942] [INFO] [launch.py:163:main] dist_world_size=8
[2024-03-23 15:46:00,942] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-03-23 15:46:16,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,104] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,113] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,177] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,214] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,263] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,265] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:16,294] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:22,102] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,104] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,107] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,108] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,109] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,116] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,117] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,117] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:22,117] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
[2024-03-23 15:46:42,201] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 707, num_elems = 15.36B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.13s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.37s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.02s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.36s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.19s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:40<00:40, 40.46s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.39s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 23.23s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.95s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 23.12s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.80s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 23.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.97s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 23.28s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.99s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 22.90s/it]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.54s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 23.22s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.91s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 23.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.94s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:53<00:53, 53.39s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:03<00:00, 27.78s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:03<00:00, 31.62s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
[2024-03-23 15:47:47,025] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 1098, num_elems = 15.67B
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Formatting inputs...Skip in lazy mode
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Parameter Offload: Total persistent parameters: 599040 in 312 params
wandb: Currently logged in as: jienengchen01. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /home/jchen293/code/llava_git/llava/wandb/run-20240323_155011-921otds0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-flower-73
wandb: â­ï¸ View project at https://wandb.ai/jienengchen01/huggingface
wandb: ðŸš€ View run at https://wandb.ai/jienengchen01/huggingface/runs/921otds0
  0%|          | 0/5198 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/5198 [01:11<103:46:12, 71.88s/it]                                                    {'loss': 1.3701, 'learning_rate': 1.282051282051282e-07, 'epoch': 0.0}
  0%|          | 1/5198 [01:11<103:46:12, 71.88s/it]  0%|          | 2/5198 [01:27<56:11:40, 38.93s/it]                                                    {'loss': 1.3814, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
  0%|          | 2/5198 [01:27<56:11:40, 38.93s/it]  0%|          | 3/5198 [01:40<38:44:56, 26.85s/it]                                                   {'loss': 1.3726, 'learning_rate': 3.846153846153847e-07, 'epoch': 0.0}
  0%|          | 3/5198 [01:40<38:44:56, 26.85s/it]  0%|          | 4/5198 [01:52<30:24:46, 21.08s/it]                                                   {'loss': 1.4132, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
  0%|          | 4/5198 [01:52<30:24:46, 21.08s/it]  0%|          | 5/5198 [02:04<25:39:44, 17.79s/it]                                                   {'loss': 1.3707, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.0}
  0%|          | 5/5198 [02:04<25:39:44, 17.79s/it]  0%|          | 6/5198 [02:18<23:42:44, 16.44s/it]                                                   {'loss': 1.4053, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
  0%|          | 6/5198 [02:18<23:42:44, 16.44s/it]  0%|          | 7/5198 [02:29<21:21:04, 14.81s/it]                                                   {'loss': 1.3906, 'learning_rate': 8.974358974358975e-07, 'epoch': 0.0}
  0%|          | 7/5198 [02:29<21:21:04, 14.81s/it]  0%|          | 8/5198 [02:41<20:11:45, 14.01s/it]                                                   {'loss': 1.3488, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.0}
  0%|          | 8/5198 [02:42<20:11:45, 14.01s/it]  0%|          | 9/5198 [02:53<19:14:00, 13.34s/it]                                                   {'loss': 1.3895, 'learning_rate': 1.153846153846154e-06, 'epoch': 0.0}
  0%|          | 9/5198 [02:53<19:14:00, 13.34s/it]  0%|          | 10/5198 [03:05<18:26:32, 12.80s/it]                                                    {'loss': 1.3203, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.0}
  0%|          | 10/5198 [03:05<18:26:32, 12.80s/it]  0%|          | 11/5198 [03:17<17:58:53, 12.48s/it]                                                    {'loss': 1.3389, 'learning_rate': 1.4102564102564104e-06, 'epoch': 0.0}
  0%|          | 11/5198 [03:17<17:58:53, 12.48s/it]  0%|          | 12/5198 [03:29<17:46:11, 12.34s/it]                                                    {'loss': 1.3275, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}
  0%|          | 12/5198 [03:29<17:46:11, 12.34s/it]  0%|          | 13/5198 [03:41<17:54:37, 12.44s/it]                                                    {'loss': 1.2557, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.0}
  0%|          | 13/5198 [03:41<17:54:37, 12.44s/it]  0%|          | 14/5198 [03:54<17:52:55, 12.42s/it]                                                    {'loss': 1.1996, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.0}
  0%|          | 14/5198 [03:54<17:52:55, 12.42s/it]  0%|          | 15/5198 [04:05<17:33:48, 12.20s/it]                                                    {'loss': 1.214, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.0}
  0%|          | 15/5198 [04:05<17:33:48, 12.20s/it]  0%|          | 16/5198 [04:17<17:27:35, 12.13s/it]                                                    {'loss': 1.2576, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.0}
  0%|          | 16/5198 [04:18<17:27:35, 12.13s/it]  0%|          | 17/5198 [04:30<17:44:40, 12.33s/it]                                                    {'loss': 1.1653, 'learning_rate': 2.1794871794871797e-06, 'epoch': 0.0}
  0%|          | 17/5198 [04:30<17:44:40, 12.33s/it]  0%|          | 18/5198 [04:42<17:23:44, 12.09s/it]                                                    {'loss': 1.134, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.0}
  0%|          | 18/5198 [04:42<17:23:44, 12.09s/it]  0%|          | 19/5198 [04:54<17:35:06, 12.22s/it]                                                    {'loss': 1.1945, 'learning_rate': 2.435897435897436e-06, 'epoch': 0.0}
  0%|          | 19/5198 [04:54<17:35:06, 12.22s/it]  0%|          | 20/5198 [05:07<17:55:20, 12.46s/it]                                                    {'loss': 1.0922, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.0}
  0%|          | 20/5198 [05:07<17:55:20, 12.46s/it]  0%|          | 21/5198 [05:19<17:32:42, 12.20s/it]                                                    {'loss': 1.1828, 'learning_rate': 2.6923076923076923e-06, 'epoch': 0.0}
  0%|          | 21/5198 [05:19<17:32:42, 12.20s/it]  0%|          | 22/5198 [05:31<17:37:20, 12.26s/it]                                                    {'loss': 1.1381, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.0}
  0%|          | 22/5198 [05:31<17:37:20, 12.26s/it]  0%|          | 23/5198 [05:43<17:22:32, 12.09s/it]                                                    {'loss': 1.0611, 'learning_rate': 2.948717948717949e-06, 'epoch': 0.0}
  0%|          | 23/5198 [05:43<17:22:32, 12.09s/it]  0%|          | 24/5198 [05:55<17:22:42, 12.09s/it]                                                    {'loss': 1.1615, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.0}
  0%|          | 24/5198 [05:55<17:22:42, 12.09s/it]  0%|          | 25/5198 [06:07<17:28:35, 12.16s/it]                                                    {'loss': 1.1123, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.0}
  0%|          | 25/5198 [06:08<17:28:35, 12.16s/it]  1%|          | 26/5198 [06:20<17:39:42, 12.29s/it]                                                    {'loss': 1.0989, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}
  1%|          | 26/5198 [06:20<17:39:42, 12.29s/it]  1%|          | 27/5198 [06:32<17:39:29, 12.29s/it]                                                    {'loss': 1.1025, 'learning_rate': 3.4615384615384617e-06, 'epoch': 0.01}
  1%|          | 27/5198 [06:32<17:39:29, 12.29s/it]  1%|          | 28/5198 [06:44<17:12:16, 11.98s/it]                                                    {'loss': 1.1018, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.01}
  1%|          | 28/5198 [06:44<17:12:16, 11.98s/it]  1%|          | 29/5198 [06:58<18:24:41, 12.82s/it]                                                    {'loss': 1.0568, 'learning_rate': 3.7179487179487184e-06, 'epoch': 0.01}
  1%|          | 29/5198 [06:58<18:24:41, 12.82s/it]  1%|          | 30/5198 [07:10<17:51:13, 12.44s/it]                                                    {'loss': 1.0555, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.01}
  1%|          | 30/5198 [07:10<17:51:13, 12.44s/it]  1%|          | 31/5198 [07:22<17:35:57, 12.26s/it]                                                    {'loss': 1.1005, 'learning_rate': 3.974358974358974e-06, 'epoch': 0.01}
  1%|          | 31/5198 [07:22<17:35:57, 12.26s/it]  1%|          | 32/5198 [07:34<17:34:14, 12.24s/it]                                                    {'loss': 1.0277, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.01}
  1%|          | 32/5198 [07:34<17:34:14, 12.24s/it]  1%|          | 33/5198 [07:47<17:59:15, 12.54s/it]                                                    {'loss': 1.0523, 'learning_rate': 4.230769230769231e-06, 'epoch': 0.01}
  1%|          | 33/5198 [07:47<17:59:15, 12.54s/it]  1%|          | 34/5198 [07:59<17:42:24, 12.34s/it]                                                    {'loss': 1.0352, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.01}
  1%|          | 34/5198 [07:59<17:42:24, 12.34s/it]  1%|          | 35/5198 [08:13<18:25:03, 12.84s/it]                                                    {'loss': 1.0065, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.01}
  1%|          | 35/5198 [08:13<18:25:03, 12.84s/it]  1%|          | 36/5198 [08:24<17:47:30, 12.41s/it]                                                    {'loss': 1.0416, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.01}
  1%|          | 36/5198 [08:24<17:47:30, 12.41s/it][2024-03-23 15:59:09,776] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 37/5198 [08:41<19:46:46, 13.80s/it]                                                    {'loss': 0.3082, 'learning_rate': 4.743589743589744e-06, 'epoch': 0.01}
  1%|          | 37/5198 [08:42<19:46:46, 13.80s/it]  1%|          | 38/5198 [08:57<20:37:15, 14.39s/it]                                                    {'loss': 1.0624, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.01}
  1%|          | 38/5198 [08:57<20:37:15, 14.39s/it]  1%|          | 39/5198 [09:09<19:25:50, 13.56s/it]                                                    {'loss': 1.0545, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 39/5198 [09:09<19:25:50, 13.56s/it]  1%|          | 40/5198 [09:21<18:41:18, 13.04s/it]                                                    {'loss': 1.0279, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.01}
  1%|          | 40/5198 [09:21<18:41:18, 13.04s/it]  1%|          | 41/5198 [09:33<18:17:29, 12.77s/it]                                                    {'loss': 1.0242, 'learning_rate': 5.256410256410257e-06, 'epoch': 0.01}
  1%|          | 41/5198 [09:33<18:17:29, 12.77s/it]  1%|          | 42/5198 [09:45<18:02:53, 12.60s/it]                                                    {'loss': 1.0797, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.01}
  1%|          | 42/5198 [09:45<18:02:53, 12.60s/it]  1%|          | 43/5198 [09:57<17:37:24, 12.31s/it]                                                    {'loss': 0.9773, 'learning_rate': 5.512820512820514e-06, 'epoch': 0.01}
  1%|          | 43/5198 [09:57<17:37:24, 12.31s/it]  1%|          | 44/5198 [10:09<17:43:38, 12.38s/it]                                                    {'loss': 1.0396, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.01}
  1%|          | 44/5198 [10:09<17:43:38, 12.38s/it]  1%|          | 45/5198 [10:21<17:29:07, 12.22s/it]                                                    {'loss': 1.0451, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.01}
  1%|          | 45/5198 [10:21<17:29:07, 12.22s/it]  1%|          | 46/5198 [10:33<17:35:23, 12.29s/it]                                                    {'loss': 1.0021, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.01}
  1%|          | 46/5198 [10:34<17:35:23, 12.29s/it]  1%|          | 47/5198 [10:45<17:24:40, 12.17s/it]                                                    {'loss': 0.9823, 'learning_rate': 6.025641025641026e-06, 'epoch': 0.01}
  1%|          | 47/5198 [10:45<17:24:40, 12.17s/it]  1%|          | 48/5198 [10:57<17:02:03, 11.91s/it]                                                    {'loss': 0.9812, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.01}
  1%|          | 48/5198 [10:57<17:02:03, 11.91s/it]  1%|          | 49/5198 [11:09<17:13:39, 12.04s/it]                                                    {'loss': 0.9823, 'learning_rate': 6.282051282051282e-06, 'epoch': 0.01}
  1%|          | 49/5198 [11:09<17:13:39, 12.04s/it]  1%|          | 50/5198 [11:22<17:46:29, 12.43s/it]                                                    {'loss': 0.9748, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.01}
  1%|          | 50/5198 [11:22<17:46:29, 12.43s/it]  1%|          | 51/5198 [11:34<17:34:49, 12.30s/it]                                                    {'loss': 1.0165, 'learning_rate': 6.538461538461539e-06, 'epoch': 0.01}
  1%|          | 51/5198 [11:34<17:34:49, 12.30s/it]  1%|          | 52/5198 [11:46<17:28:45, 12.23s/it]                                                    {'loss': 1.0109, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}
  1%|          | 52/5198 [11:46<17:28:45, 12.23s/it]  1%|          | 53/5198 [11:59<17:26:55, 12.21s/it]                                                    {'loss': 0.9945, 'learning_rate': 6.794871794871796e-06, 'epoch': 0.01}
  1%|          | 53/5198 [11:59<17:26:55, 12.21s/it]  1%|          | 54/5198 [12:11<17:21:39, 12.15s/it]                                                    {'loss': 0.9803, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.01}
  1%|          | 54/5198 [12:11<17:21:39, 12.15s/it]  1%|          | 55/5198 [12:22<17:12:56, 12.05s/it]                                                    {'loss': 1.0122, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.01}
  1%|          | 55/5198 [12:22<17:12:56, 12.05s/it][2024-03-23 16:03:08,573] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 56/5198 [12:40<19:41:18, 13.78s/it]                                                    {'loss': 0.3198, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.01}
  1%|          | 56/5198 [12:40<19:41:18, 13.78s/it]  1%|          | 57/5198 [12:53<19:04:29, 13.36s/it]                                                    {'loss': 0.9811, 'learning_rate': 7.307692307692308e-06, 'epoch': 0.01}
  1%|          | 57/5198 [12:53<19:04:29, 13.36s/it]  1%|          | 58/5198 [13:04<18:16:03, 12.79s/it]                                                    {'loss': 1.0165, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.01}
  1%|          | 58/5198 [13:04<18:16:03, 12.79s/it]  1%|          | 59/5198 [13:16<17:43:31, 12.42s/it]                                                    {'loss': 1.0327, 'learning_rate': 7.564102564102564e-06, 'epoch': 0.01}
  1%|          | 59/5198 [13:16<17:43:31, 12.42s/it]  1%|          | 60/5198 [13:29<18:06:24, 12.69s/it]                                                    {'loss': 1.0008, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.01}
  1%|          | 60/5198 [13:29<18:06:24, 12.69s/it]  1%|          | 61/5198 [13:42<18:21:51, 12.87s/it]                                                    {'loss': 0.9604, 'learning_rate': 7.820512820512822e-06, 'epoch': 0.01}
  1%|          | 61/5198 [13:42<18:21:51, 12.87s/it]  1%|          | 62/5198 [13:54<17:54:04, 12.55s/it]                                                    {'loss': 0.9777, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.01}
  1%|          | 62/5198 [13:54<17:54:04, 12.55s/it]  1%|          | 63/5198 [14:07<18:00:55, 12.63s/it]                                                    {'loss': 0.9209, 'learning_rate': 8.076923076923077e-06, 'epoch': 0.01}
  1%|          | 63/5198 [14:07<18:00:55, 12.63s/it]  1%|          | 64/5198 [14:19<17:57:19, 12.59s/it]                                                    {'loss': 0.998, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.01}
  1%|          | 64/5198 [14:20<17:57:19, 12.59s/it]  1%|â–         | 65/5198 [14:33<18:34:06, 13.02s/it]                                                    {'loss': 0.9858, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.01}
  1%|â–         | 65/5198 [14:34<18:34:06, 13.02s/it]  1%|â–         | 66/5198 [14:47<18:40:16, 13.10s/it]                                                    {'loss': 0.9633, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.01}
  1%|â–         | 66/5198 [14:47<18:40:16, 13.10s/it]  1%|â–         | 67/5198 [14:59<18:17:55, 12.84s/it]                                                    {'loss': 0.8938, 'learning_rate': 8.58974358974359e-06, 'epoch': 0.01}
  1%|â–         | 67/5198 [14:59<18:17:55, 12.84s/it]  1%|â–         | 68/5198 [15:11<18:02:40, 12.66s/it]                                                    {'loss': 0.9814, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.01}
  1%|â–         | 68/5198 [15:11<18:02:40, 12.66s/it]  1%|â–         | 69/5198 [15:23<17:48:05, 12.49s/it]                                                    {'loss': 0.9737, 'learning_rate': 8.846153846153847e-06, 'epoch': 0.01}
  1%|â–         | 69/5198 [15:23<17:48:05, 12.49s/it]  1%|â–         | 70/5198 [15:35<17:39:27, 12.40s/it]                                                    {'loss': 0.9669, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.01}
  1%|â–         | 70/5198 [15:35<17:39:27, 12.40s/it]  1%|â–         | 71/5198 [15:48<17:48:33, 12.51s/it]                                                    {'loss': 0.9473, 'learning_rate': 9.102564102564104e-06, 'epoch': 0.01}
  1%|â–         | 71/5198 [15:48<17:48:33, 12.51s/it]  1%|â–         | 72/5198 [16:01<17:57:23, 12.61s/it]                                                    {'loss': 0.9139, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.01}
  1%|â–         | 72/5198 [16:01<17:57:23, 12.61s/it]  1%|â–         | 73/5198 [16:13<17:35:18, 12.35s/it]                                                    {'loss': 0.992, 'learning_rate': 9.358974358974359e-06, 'epoch': 0.01}
  1%|â–         | 73/5198 [16:13<17:35:18, 12.35s/it]  1%|â–         | 74/5198 [16:24<17:07:38, 12.03s/it]                                                    {'loss': 0.9473, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.01}
  1%|â–         | 74/5198 [16:24<17:07:38, 12.03s/it]  1%|â–         | 75/5198 [16:36<17:16:55, 12.14s/it]                                                    {'loss': 0.9332, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.01}
  1%|â–         | 75/5198 [16:37<17:16:55, 12.14s/it]  1%|â–         | 76/5198 [16:48<17:05:41, 12.02s/it]                                                    {'loss': 0.9407, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.01}
  1%|â–         | 76/5198 [16:48<17:05:41, 12.02s/it]  1%|â–         | 77/5198 [17:00<17:09:46, 12.07s/it]                                                    {'loss': 0.9078, 'learning_rate': 9.871794871794872e-06, 'epoch': 0.01}
  1%|â–         | 77/5198 [17:00<17:09:46, 12.07s/it]  2%|â–         | 78/5198 [17:12<17:05:12, 12.01s/it]                                                    {'loss': 0.9793, 'learning_rate': 1e-05, 'epoch': 0.02}
  2%|â–         | 78/5198 [17:12<17:05:12, 12.01s/it]  2%|â–         | 79/5198 [17:24<17:09:52, 12.07s/it]                                                    {'loss': 1.0201, 'learning_rate': 1.012820512820513e-05, 'epoch': 0.02}
  2%|â–         | 79/5198 [17:25<17:09:52, 12.07s/it]  2%|â–         | 80/5198 [17:36<17:04:18, 12.01s/it]                                                    {'loss': 0.9602, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.02}
  2%|â–         | 80/5198 [17:36<17:04:18, 12.01s/it]  2%|â–         | 81/5198 [17:48<16:55:00, 11.90s/it]                                                    {'loss': 1.0101, 'learning_rate': 1.0384615384615386e-05, 'epoch': 0.02}
  2%|â–         | 81/5198 [17:48<16:55:00, 11.90s/it]  2%|â–         | 82/5198 [18:00<16:49:29, 11.84s/it]                                                    {'loss': 1.0334, 'learning_rate': 1.0512820512820514e-05, 'epoch': 0.02}
  2%|â–         | 82/5198 [18:00<16:49:29, 11.84s/it]  2%|â–         | 83/5198 [18:12<16:50:40, 11.86s/it]                                                    {'loss': 1.021, 'learning_rate': 1.0641025641025643e-05, 'epoch': 0.02}
  2%|â–         | 83/5198 [18:12<16:50:40, 11.86s/it]  2%|â–         | 84/5198 [18:24<17:06:14, 12.04s/it]                                                    {'loss': 0.9727, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.02}
  2%|â–         | 84/5198 [18:24<17:06:14, 12.04s/it]  2%|â–         | 85/5198 [18:36<16:55:06, 11.91s/it]                                                    {'loss': 0.948, 'learning_rate': 1.0897435897435898e-05, 'epoch': 0.02}
  2%|â–         | 85/5198 [18:36<16:55:06, 11.91s/it]  2%|â–         | 86/5198 [18:47<16:27:36, 11.59s/it]                                                    {'loss': 0.9438, 'learning_rate': 1.1025641025641028e-05, 'epoch': 0.02}
  2%|â–         | 86/5198 [18:47<16:27:36, 11.59s/it]  2%|â–         | 87/5198 [18:59<16:44:22, 11.79s/it]                                                    {'loss': 0.9991, 'learning_rate': 1.1153846153846154e-05, 'epoch': 0.02}
  2%|â–         | 87/5198 [18:59<16:44:22, 11.79s/it]  2%|â–         | 88/5198 [19:13<17:45:13, 12.51s/it]                                                    {'loss': 0.9683, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.02}
  2%|â–         | 88/5198 [19:13<17:45:13, 12.51s/it]  2%|â–         | 89/5198 [19:30<19:49:20, 13.97s/it]                                                    {'loss': 0.2953, 'learning_rate': 1.1410256410256411e-05, 'epoch': 0.02}
  2%|â–         | 89/5198 [19:30<19:49:20, 13.97s/it]  2%|â–         | 90/5198 [19:42<18:52:32, 13.30s/it]                                                    {'loss': 0.9142, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.02}
  2%|â–         | 90/5198 [19:42<18:52:32, 13.30s/it]  2%|â–         | 91/5198 [19:54<18:16:47, 12.89s/it]                                                    {'loss': 0.9773, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.02}
  2%|â–         | 91/5198 [19:54<18:16:47, 12.89s/it]  2%|â–         | 92/5198 [20:06<17:44:15, 12.51s/it]                                                    {'loss': 0.9847, 'learning_rate': 1.1794871794871796e-05, 'epoch': 0.02}
  2%|â–         | 92/5198 [20:06<17:44:15, 12.51s/it]  2%|â–         | 93/5198 [20:18<17:42:49, 12.49s/it]                                                    {'loss': 0.9908, 'learning_rate': 1.1923076923076925e-05, 'epoch': 0.02}
  2%|â–         | 93/5198 [20:18<17:42:49, 12.49s/it]  2%|â–         | 94/5198 [20:30<17:29:29, 12.34s/it]                                                    {'loss': 0.9425, 'learning_rate': 1.2051282051282051e-05, 'epoch': 0.02}
  2%|â–         | 94/5198 [20:30<17:29:29, 12.34s/it]  2%|â–         | 95/5198 [20:47<19:29:11, 13.75s/it]                                                    {'loss': 0.308, 'learning_rate': 1.217948717948718e-05, 'epoch': 0.02}
  2%|â–         | 95/5198 [20:47<19:29:11, 13.75s/it]  2%|â–         | 96/5198 [20:59<18:49:25, 13.28s/it]                                                    {'loss': 0.9524, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.02}
  2%|â–         | 96/5198 [20:59<18:49:25, 13.28s/it]  2%|â–         | 97/5198 [21:12<18:35:47, 13.12s/it]                                                    {'loss': 0.9553, 'learning_rate': 1.2435897435897436e-05, 'epoch': 0.02}
  2%|â–         | 97/5198 [21:12<18:35:47, 13.12s/it]  2%|â–         | 98/5198 [21:26<19:00:58, 13.42s/it]                                                    {'loss': 0.9815, 'learning_rate': 1.2564102564102565e-05, 'epoch': 0.02}
  2%|â–         | 98/5198 [21:26<19:00:58, 13.42s/it]  2%|â–         | 99/5198 [21:40<18:59:57, 13.41s/it]                                                    {'loss': 0.8906, 'learning_rate': 1.2692307692307693e-05, 'epoch': 0.02}
  2%|â–         | 99/5198 [21:40<18:59:57, 13.41s/it]  2%|â–         | 100/5198 [21:57<20:33:39, 14.52s/it]                                                     {'loss': 0.2938, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.02}
  2%|â–         | 100/5198 [21:57<20:33:39, 14.52s/it]  2%|â–         | 101/5198 [22:09<19:35:39, 13.84s/it]                                                     {'loss': 0.9388, 'learning_rate': 1.294871794871795e-05, 'epoch': 0.02}
  2%|â–         | 101/5198 [22:09<19:35:39, 13.84s/it]  2%|â–         | 102/5198 [22:20<18:28:00, 13.05s/it]                                                     {'loss': 1.0488, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.02}
  2%|â–         | 102/5198 [22:20<18:28:00, 13.05s/it]  2%|â–         | 103/5198 [22:34<18:44:30, 13.24s/it]                                                     {'loss': 0.98, 'learning_rate': 1.3205128205128207e-05, 'epoch': 0.02}
  2%|â–         | 103/5198 [22:34<18:44:30, 13.24s/it]  2%|â–         | 104/5198 [22:49<19:31:55, 13.80s/it]                                                     {'loss': 0.967, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}
  2%|â–         | 104/5198 [22:49<19:31:55, 13.80s/it]  2%|â–         | 105/5198 [23:06<20:58:27, 14.83s/it]                                                     {'loss': 0.2655, 'learning_rate': 1.3461538461538463e-05, 'epoch': 0.02}
  2%|â–         | 105/5198 [23:06<20:58:27, 14.83s/it]  2%|â–         | 106/5198 [23:18<19:43:36, 13.95s/it]                                                     {'loss': 0.9482, 'learning_rate': 1.3589743589743592e-05, 'epoch': 0.02}
  2%|â–         | 106/5198 [23:18<19:43:36, 13.95s/it]  2%|â–         | 107/5198 [23:29<18:40:05, 13.20s/it]                                                     {'loss': 1.0179, 'learning_rate': 1.3717948717948718e-05, 'epoch': 0.02}
  2%|â–         | 107/5198 [23:30<18:40:05, 13.20s/it]  2%|â–         | 108/5198 [23:41<18:06:46, 12.81s/it]                                                     {'loss': 0.9437, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.02}
  2%|â–         | 108/5198 [23:41<18:06:46, 12.81s/it]  2%|â–         | 109/5198 [23:53<17:32:34, 12.41s/it]                                                     {'loss': 0.9769, 'learning_rate': 1.3974358974358975e-05, 'epoch': 0.02}
  2%|â–         | 109/5198 [23:53<17:32:34, 12.41s/it]  2%|â–         | 110/5198 [24:05<17:19:36, 12.26s/it]                                                     {'loss': 0.966, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.02}
  2%|â–         | 110/5198 [24:05<17:19:36, 12.26s/it]  2%|â–         | 111/5198 [24:17<17:12:59, 12.18s/it]                                                     {'loss': 0.9476, 'learning_rate': 1.4230769230769232e-05, 'epoch': 0.02}
  2%|â–         | 111/5198 [24:17<17:12:59, 12.18s/it]  2%|â–         | 112/5198 [24:29<17:11:26, 12.17s/it]                                                     {'loss': 1.0301, 'learning_rate': 1.435897435897436e-05, 'epoch': 0.02}
  2%|â–         | 112/5198 [24:29<17:11:26, 12.17s/it]  2%|â–         | 113/5198 [24:41<17:19:51, 12.27s/it]                                                     {'loss': 0.9374, 'learning_rate': 1.4487179487179489e-05, 'epoch': 0.02}
  2%|â–         | 113/5198 [24:41<17:19:51, 12.27s/it]  2%|â–         | 114/5198 [24:53<17:07:40, 12.13s/it]                                                     {'loss': 0.9659, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.02}
  2%|â–         | 114/5198 [24:53<17:07:40, 12.13s/it]  2%|â–         | 115/5198 [25:06<17:16:13, 12.23s/it]                                                     {'loss': 0.9616, 'learning_rate': 1.4743589743589745e-05, 'epoch': 0.02}
  2%|â–         | 115/5198 [25:06<17:16:13, 12.23s/it]  2%|â–         | 116/5198 [25:22<18:50:56, 13.35s/it]                                                     {'loss': 0.2955, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.02}
  2%|â–         | 116/5198 [25:22<18:50:56, 13.35s/it]  2%|â–         | 117/5198 [25:34<18:38:03, 13.20s/it]                                                     {'loss': 0.9837, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.02}
  2%|â–         | 117/5198 [25:35<18:38:03, 13.20s/it]  2%|â–         | 118/5198 [25:46<17:57:51, 12.73s/it]                                                     {'loss': 0.9486, 'learning_rate': 1.5128205128205129e-05, 'epoch': 0.02}
  2%|â–         | 118/5198 [25:46<17:57:51, 12.73s/it]  2%|â–         | 119/5198 [25:58<17:32:26, 12.43s/it]                                                     {'loss': 1.0566, 'learning_rate': 1.5256410256410257e-05, 'epoch': 0.02}
  2%|â–         | 119/5198 [25:58<17:32:26, 12.43s/it]  2%|â–         | 120/5198 [26:12<18:05:32, 12.83s/it]                                                     {'loss': 0.9361, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.02}
  2%|â–         | 120/5198 [26:12<18:05:32, 12.83s/it]  2%|â–         | 121/5198 [26:25<18:12:53, 12.92s/it]                                                     {'loss': 0.9947, 'learning_rate': 1.5512820512820516e-05, 'epoch': 0.02}
  2%|â–         | 121/5198 [26:25<18:12:53, 12.92s/it]  2%|â–         | 122/5198 [26:38<18:16:23, 12.96s/it]                                                     {'loss': 1.0173, 'learning_rate': 1.5641025641025644e-05, 'epoch': 0.02}
  2%|â–         | 122/5198 [26:38<18:16:23, 12.96s/it]  2%|â–         | 123/5198 [26:51<18:23:54, 13.05s/it]                                                     {'loss': 0.9077, 'learning_rate': 1.576923076923077e-05, 'epoch': 0.02}
  2%|â–         | 123/5198 [26:51<18:23:54, 13.05s/it]  2%|â–         | 124/5198 [27:04<18:12:02, 12.91s/it]                                                     {'loss': 0.9464, 'learning_rate': 1.5897435897435897e-05, 'epoch': 0.02}
  2%|â–         | 124/5198 [27:04<18:12:02, 12.91s/it]  2%|â–         | 125/5198 [27:16<17:53:51, 12.70s/it]                                                     {'loss': 0.9686, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.02}
  2%|â–         | 125/5198 [27:16<17:53:51, 12.70s/it]  2%|â–         | 126/5198 [27:28<17:34:46, 12.48s/it]                                                     {'loss': 0.9514, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.02}
  2%|â–         | 126/5198 [27:28<17:34:46, 12.48s/it]  2%|â–         | 127/5198 [27:39<17:03:14, 12.11s/it]                                                     {'loss': 1.0012, 'learning_rate': 1.6282051282051282e-05, 'epoch': 0.02}
  2%|â–         | 127/5198 [27:39<17:03:14, 12.11s/it]  2%|â–         | 128/5198 [27:51<17:07:56, 12.17s/it]                                                     {'loss': 0.8572, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.02}
  2%|â–         | 128/5198 [27:51<17:07:56, 12.17s/it]  2%|â–         | 129/5198 [28:04<17:20:36, 12.32s/it]                                                     {'loss': 0.9287, 'learning_rate': 1.653846153846154e-05, 'epoch': 0.02}
  2%|â–         | 129/5198 [28:04<17:20:36, 12.32s/it]  3%|â–Ž         | 130/5198 [28:16<17:05:41, 12.14s/it]                                                     {'loss': 0.9538, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
  3%|â–Ž         | 130/5198 [28:16<17:05:41, 12.14s/it]  3%|â–Ž         | 131/5198 [28:28<17:01:56, 12.10s/it]                                                     {'loss': 0.9723, 'learning_rate': 1.6794871794871796e-05, 'epoch': 0.03}
  3%|â–Ž         | 131/5198 [28:28<17:01:56, 12.10s/it]  3%|â–Ž         | 132/5198 [28:41<17:38:02, 12.53s/it]                                                     {'loss': 0.9145, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.03}
  3%|â–Ž         | 132/5198 [28:41<17:38:02, 12.53s/it]  3%|â–Ž         | 133/5198 [28:54<17:44:22, 12.61s/it]                                                     {'loss': 0.9104, 'learning_rate': 1.7051282051282053e-05, 'epoch': 0.03}
  3%|â–Ž         | 133/5198 [28:54<17:44:22, 12.61s/it]  3%|â–Ž         | 134/5198 [29:06<17:28:51, 12.43s/it]                                                     {'loss': 0.9424, 'learning_rate': 1.717948717948718e-05, 'epoch': 0.03}
  3%|â–Ž         | 134/5198 [29:06<17:28:51, 12.43s/it]  3%|â–Ž         | 135/5198 [29:17<17:02:29, 12.12s/it]                                                     {'loss': 0.93, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.03}
  3%|â–Ž         | 135/5198 [29:18<17:02:29, 12.12s/it]  3%|â–Ž         | 136/5198 [29:32<18:09:43, 12.92s/it]                                                     {'loss': 0.9047, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.03}
  3%|â–Ž         | 136/5198 [29:32<18:09:43, 12.92s/it]  3%|â–Ž         | 137/5198 [29:44<17:51:47, 12.71s/it]                                                     {'loss': 0.9883, 'learning_rate': 1.7564102564102566e-05, 'epoch': 0.03}
  3%|â–Ž         | 137/5198 [29:45<17:51:47, 12.71s/it]  3%|â–Ž         | 138/5198 [29:57<17:42:14, 12.60s/it]                                                     {'loss': 1.0013, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.03}
  3%|â–Ž         | 138/5198 [29:57<17:42:14, 12.60s/it]  3%|â–Ž         | 139/5198 [30:09<17:31:02, 12.47s/it]                                                     {'loss': 0.9289, 'learning_rate': 1.7820512820512823e-05, 'epoch': 0.03}
  3%|â–Ž         | 139/5198 [30:09<17:31:02, 12.47s/it]  3%|â–Ž         | 140/5198 [30:21<17:08:06, 12.20s/it]                                                     {'loss': 1.0026, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.03}
  3%|â–Ž         | 140/5198 [30:21<17:08:06, 12.20s/it]  3%|â–Ž         | 141/5198 [30:33<17:18:39, 12.32s/it]                                                     {'loss': 0.9686, 'learning_rate': 1.807692307692308e-05, 'epoch': 0.03}
  3%|â–Ž         | 141/5198 [30:33<17:18:39, 12.32s/it]  3%|â–Ž         | 142/5198 [30:46<17:31:39, 12.48s/it]                                                     {'loss': 0.9698, 'learning_rate': 1.8205128205128208e-05, 'epoch': 0.03}
  3%|â–Ž         | 142/5198 [30:46<17:31:39, 12.48s/it]  3%|â–Ž         | 143/5198 [30:57<16:58:09, 12.08s/it]                                                     {'loss': 0.9957, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.03}
  3%|â–Ž         | 143/5198 [30:57<16:58:09, 12.08s/it]  3%|â–Ž         | 144/5198 [31:10<17:11:00, 12.24s/it]                                                     {'loss': 0.9759, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.03}
  3%|â–Ž         | 144/5198 [31:10<17:11:00, 12.24s/it]  3%|â–Ž         | 145/5198 [31:22<17:01:10, 12.13s/it]                                                     {'loss': 0.9558, 'learning_rate': 1.8589743589743593e-05, 'epoch': 0.03}
  3%|â–Ž         | 145/5198 [31:22<17:01:10, 12.13s/it]  3%|â–Ž         | 146/5198 [31:34<17:08:29, 12.21s/it]                                                     {'loss': 0.9599, 'learning_rate': 1.8717948717948718e-05, 'epoch': 0.03}
  3%|â–Ž         | 146/5198 [31:34<17:08:29, 12.21s/it]  3%|â–Ž         | 147/5198 [31:46<17:01:59, 12.14s/it]                                                     {'loss': 0.9257, 'learning_rate': 1.8846153846153846e-05, 'epoch': 0.03}
  3%|â–Ž         | 147/5198 [31:46<17:01:59, 12.14s/it]  3%|â–Ž         | 148/5198 [31:58<17:02:29, 12.15s/it]                                                     {'loss': 0.9332, 'learning_rate': 1.8974358974358975e-05, 'epoch': 0.03}
  3%|â–Ž         | 148/5198 [31:58<17:02:29, 12.15s/it]  3%|â–Ž         | 149/5198 [32:10<16:59:04, 12.11s/it]                                                     {'loss': 0.942, 'learning_rate': 1.9102564102564106e-05, 'epoch': 0.03}
  3%|â–Ž         | 149/5198 [32:10<16:59:04, 12.11s/it]  3%|â–Ž         | 150/5198 [32:22<16:54:41, 12.06s/it]                                                     {'loss': 0.9376, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.03}
  3%|â–Ž         | 150/5198 [32:22<16:54:41, 12.06s/it]  3%|â–Ž         | 151/5198 [32:36<17:33:41, 12.53s/it]                                                     {'loss': 0.9864, 'learning_rate': 1.935897435897436e-05, 'epoch': 0.03}
  3%|â–Ž         | 151/5198 [32:36<17:33:41, 12.53s/it]  3%|â–Ž         | 152/5198 [32:53<19:41:29, 14.05s/it]                                                     {'loss': 0.2928, 'learning_rate': 1.9487179487179488e-05, 'epoch': 0.03}
  3%|â–Ž         | 152/5198 [32:53<19:41:29, 14.05s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 2048). Running this sequence through the model will result in indexing errors
  3%|â–Ž         | 153/5198 [33:05<18:44:02, 13.37s/it]                                                     {'loss': 0.9871, 'learning_rate': 1.9615384615384617e-05, 'epoch': 0.03}
  3%|â–Ž         | 153/5198 [33:05<18:44:02, 13.37s/it]  3%|â–Ž         | 154/5198 [33:17<18:01:27, 12.86s/it]                                                     {'loss': 0.9034, 'learning_rate': 1.9743589743589745e-05, 'epoch': 0.03}
  3%|â–Ž         | 154/5198 [33:17<18:01:27, 12.86s/it]  3%|â–Ž         | 155/5198 [33:29<17:44:08, 12.66s/it]                                                     {'loss': 0.9026, 'learning_rate': 1.9871794871794873e-05, 'epoch': 0.03}
  3%|â–Ž         | 155/5198 [33:29<17:44:08, 12.66s/it]  3%|â–Ž         | 156/5198 [33:41<17:24:40, 12.43s/it]                                                     {'loss': 1.0158, 'learning_rate': 2e-05, 'epoch': 0.03}
  3%|â–Ž         | 156/5198 [33:41<17:24:40, 12.43s/it]  3%|â–Ž         | 157/5198 [33:53<17:04:47, 12.20s/it]                                                     {'loss': 0.9671, 'learning_rate': 1.9999998058827844e-05, 'epoch': 0.03}
  3%|â–Ž         | 157/5198 [33:53<17:04:47, 12.20s/it]  3%|â–Ž         | 158/5198 [34:05<16:58:05, 12.12s/it]                                                     {'loss': 0.9864, 'learning_rate': 1.9999992235312136e-05, 'epoch': 0.03}
  3%|â–Ž         | 158/5198 [34:05<16:58:05, 12.12s/it]  3%|â–Ž         | 159/5198 [34:17<17:17:38, 12.36s/it]                                                     {'loss': 0.9362, 'learning_rate': 1.9999982529455127e-05, 'epoch': 0.03}
  3%|â–Ž         | 159/5198 [34:17<17:17:38, 12.36s/it]  3%|â–Ž         | 160/5198 [34:30<17:14:16, 12.32s/it]                                                     {'loss': 0.9452, 'learning_rate': 1.9999968941260596e-05, 'epoch': 0.03}
  3%|â–Ž         | 160/5198 [34:30<17:14:16, 12.32s/it]  3%|â–Ž         | 161/5198 [34:42<17:09:51, 12.27s/it]                                                     {'loss': 0.9648, 'learning_rate': 1.9999951470733808e-05, 'epoch': 0.03}
  3%|â–Ž         | 161/5198 [34:42<17:09:51, 12.27s/it]  3%|â–Ž         | 162/5198 [34:57<18:19:01, 13.09s/it]                                                     {'loss': 0.9879, 'learning_rate': 1.9999930117881548e-05, 'epoch': 0.03}
  3%|â–Ž         | 162/5198 [34:57<18:19:01, 13.09s/it]  3%|â–Ž         | 163/5198 [35:10<18:12:42, 13.02s/it]                                                     {'loss': 0.9618, 'learning_rate': 1.9999904882712115e-05, 'epoch': 0.03}
  3%|â–Ž         | 163/5198 [35:10<18:12:42, 13.02s/it]  3%|â–Ž         | 164/5198 [35:27<20:04:52, 14.36s/it]                                                     {'loss': 0.3373, 'learning_rate': 1.99998757652353e-05, 'epoch': 0.03}
  3%|â–Ž         | 164/5198 [35:27<20:04:52, 14.36s/it]  3%|â–Ž         | 165/5198 [35:39<19:00:35, 13.60s/it]                                                     {'loss': 0.9582, 'learning_rate': 1.9999842765462403e-05, 'epoch': 0.03}
  3%|â–Ž         | 165/5198 [35:39<19:00:35, 13.60s/it]  3%|â–Ž         | 166/5198 [35:52<18:37:08, 13.32s/it]                                                     {'loss': 0.9661, 'learning_rate': 1.999980588340624e-05, 'epoch': 0.03}
  3%|â–Ž         | 166/5198 [35:52<18:37:08, 13.32s/it]  3%|â–Ž         | 167/5198 [36:04<18:04:14, 12.93s/it]                                                     {'loss': 0.9775, 'learning_rate': 1.9999765119081132e-05, 'epoch': 0.03}
  3%|â–Ž         | 167/5198 [36:04<18:04:14, 12.93s/it]  3%|â–Ž         | 168/5198 [36:17<18:05:51, 12.95s/it]                                                     {'loss': 0.9381, 'learning_rate': 1.9999720472502902e-05, 'epoch': 0.03}
  3%|â–Ž         | 168/5198 [36:17<18:05:51, 12.95s/it]  3%|â–Ž         | 169/5198 [36:30<18:10:27, 13.01s/it]                                                     {'loss': 0.9514, 'learning_rate': 1.9999671943688885e-05, 'epoch': 0.03}
  3%|â–Ž         | 169/5198 [36:30<18:10:27, 13.01s/it]  3%|â–Ž         | 170/5198 [36:42<17:51:09, 12.78s/it]                                                     {'loss': 0.9268, 'learning_rate': 1.9999619532657915e-05, 'epoch': 0.03}
  3%|â–Ž         | 170/5198 [36:42<17:51:09, 12.78s/it]  3%|â–Ž         | 171/5198 [36:54<17:19:32, 12.41s/it]                                                     {'loss': 0.8377, 'learning_rate': 1.9999563239430352e-05, 'epoch': 0.03}
  3%|â–Ž         | 171/5198 [36:54<17:19:32, 12.41s/it]  3%|â–Ž         | 172/5198 [37:06<17:15:37, 12.36s/it]                                                     {'loss': 0.9826, 'learning_rate': 1.9999503064028043e-05, 'epoch': 0.03}
  3%|â–Ž         | 172/5198 [37:06<17:15:37, 12.36s/it]  3%|â–Ž         | 173/5198 [37:18<17:11:45, 12.32s/it]                                                     {'loss': 0.937, 'learning_rate': 1.999943900647435e-05, 'epoch': 0.03}
  3%|â–Ž         | 173/5198 [37:18<17:11:45, 12.32s/it]  3%|â–Ž         | 174/5198 [37:31<17:15:15, 12.36s/it]                                                     {'loss': 0.9651, 'learning_rate': 1.9999371066794146e-05, 'epoch': 0.03}
  3%|â–Ž         | 174/5198 [37:31<17:15:15, 12.36s/it]  3%|â–Ž         | 175/5198 [37:42<16:53:26, 12.11s/it]                                                     {'loss': 0.967, 'learning_rate': 1.9999299245013805e-05, 'epoch': 0.03}
  3%|â–Ž         | 175/5198 [37:42<16:53:26, 12.11s/it]  3%|â–Ž         | 176/5198 [37:54<16:43:23, 11.99s/it]                                                     {'loss': 0.9328, 'learning_rate': 1.999922354116121e-05, 'epoch': 0.03}
  3%|â–Ž         | 176/5198 [37:54<16:43:23, 11.99s/it]  3%|â–Ž         | 177/5198 [38:06<16:54:23, 12.12s/it]                                                     {'loss': 0.9359, 'learning_rate': 1.999914395526575e-05, 'epoch': 0.03}
  3%|â–Ž         | 177/5198 [38:06<16:54:23, 12.12s/it]  3%|â–Ž         | 178/5198 [38:18<16:52:24, 12.10s/it]                                                     {'loss': 0.899, 'learning_rate': 1.9999060487358333e-05, 'epoch': 0.03}
  3%|â–Ž         | 178/5198 [38:18<16:52:24, 12.10s/it]  3%|â–Ž         | 179/5198 [38:30<16:39:39, 11.95s/it]                                                     {'loss': 0.9744, 'learning_rate': 1.9998973137471352e-05, 'epoch': 0.03}
  3%|â–Ž         | 179/5198 [38:30<16:39:39, 11.95s/it]  3%|â–Ž         | 180/5198 [38:47<18:42:13, 13.42s/it]                                                     {'loss': 0.3043, 'learning_rate': 1.9998881905638727e-05, 'epoch': 0.03}
  3%|â–Ž         | 180/5198 [38:47<18:42:13, 13.42s/it]  3%|â–Ž         | 181/5198 [39:00<18:29:40, 13.27s/it]                                                     {'loss': 0.9378, 'learning_rate': 1.9998786791895874e-05, 'epoch': 0.03}
  3%|â–Ž         | 181/5198 [39:00<18:29:40, 13.27s/it]  4%|â–Ž         | 182/5198 [39:12<18:17:42, 13.13s/it]                                                     {'loss': 1.0093, 'learning_rate': 1.999868779627972e-05, 'epoch': 0.04}
  4%|â–Ž         | 182/5198 [39:13<18:17:42, 13.13s/it]  4%|â–Ž         | 183/5198 [39:27<19:01:10, 13.65s/it]                                                     {'loss': 0.9305, 'learning_rate': 1.9998584918828695e-05, 'epoch': 0.04}
  4%|â–Ž         | 183/5198 [39:27<19:01:10, 13.65s/it]  4%|â–Ž         | 184/5198 [39:39<18:23:46, 13.21s/it]                                                     {'loss': 0.9356, 'learning_rate': 1.9998478159582747e-05, 'epoch': 0.04}
  4%|â–Ž         | 184/5198 [39:40<18:23:46, 13.21s/it]  4%|â–Ž         | 185/5198 [39:51<17:41:45, 12.71s/it]                                                     {'loss': 0.99, 'learning_rate': 1.999836751858332e-05, 'epoch': 0.04}
  4%|â–Ž         | 185/5198 [39:51<17:41:45, 12.71s/it]  4%|â–Ž         | 186/5198 [40:03<17:21:50, 12.47s/it]                                                     {'loss': 0.9725, 'learning_rate': 1.9998252995873367e-05, 'epoch': 0.04}
  4%|â–Ž         | 186/5198 [40:03<17:21:50, 12.47s/it]  4%|â–Ž         | 187/5198 [40:21<19:40:32, 14.14s/it]                                                     {'loss': 0.3367, 'learning_rate': 1.999813459149735e-05, 'epoch': 0.04}
  4%|â–Ž         | 187/5198 [40:21<19:40:32, 14.14s/it]  4%|â–Ž         | 188/5198 [40:33<18:45:36, 13.48s/it]                                                     {'loss': 0.9196, 'learning_rate': 1.9998012305501243e-05, 'epoch': 0.04}
  4%|â–Ž         | 188/5198 [40:33<18:45:36, 13.48s/it]  4%|â–Ž         | 189/5198 [40:46<18:36:50, 13.38s/it]                                                     {'loss': 0.8689, 'learning_rate': 1.999788613793251e-05, 'epoch': 0.04}
  4%|â–Ž         | 189/5198 [40:46<18:36:50, 13.38s/it]  4%|â–Ž         | 190/5198 [41:02<19:43:38, 14.18s/it]                                                     {'loss': 0.2969, 'learning_rate': 1.999775608884015e-05, 'epoch': 0.04}
  4%|â–Ž         | 190/5198 [41:02<19:43:38, 14.18s/it]  4%|â–Ž         | 191/5198 [41:15<18:59:21, 13.65s/it]                                                     {'loss': 0.9307, 'learning_rate': 1.9997622158274635e-05, 'epoch': 0.04}
  4%|â–Ž         | 191/5198 [41:15<18:59:21, 13.65s/it]  4%|â–Ž         | 192/5198 [41:26<18:06:48, 13.03s/it]                                                     {'loss': 0.9381, 'learning_rate': 1.9997484346287973e-05, 'epoch': 0.04}
  4%|â–Ž         | 192/5198 [41:26<18:06:48, 13.03s/it]  4%|â–Ž         | 193/5198 [41:38<17:38:06, 12.68s/it]                                                     {'loss': 1.0292, 'learning_rate': 1.9997342652933668e-05, 'epoch': 0.04}
  4%|â–Ž         | 193/5198 [41:38<17:38:06, 12.68s/it]  4%|â–Ž         | 194/5198 [41:52<18:07:12, 13.04s/it]                                                     {'loss': 0.9721, 'learning_rate': 1.9997197078266723e-05, 'epoch': 0.04}
  4%|â–Ž         | 194/5198 [41:52<18:07:12, 13.04s/it]  4%|â–         | 195/5198 [42:04<17:52:30, 12.86s/it]                                                     {'loss': 0.9125, 'learning_rate': 1.999704762234366e-05, 'epoch': 0.04}
  4%|â–         | 195/5198 [42:04<17:52:30, 12.86s/it]  4%|â–         | 196/5198 [42:19<18:26:56, 13.28s/it]                                                     {'loss': 0.9808, 'learning_rate': 1.99968942852225e-05, 'epoch': 0.04}
  4%|â–         | 196/5198 [42:19<18:26:56, 13.28s/it]  4%|â–         | 197/5198 [42:31<18:11:51, 13.10s/it]                                                     {'loss': 0.9883, 'learning_rate': 1.9996737066962778e-05, 'epoch': 0.04}
  4%|â–         | 197/5198 [42:31<18:11:51, 13.10s/it]  4%|â–         | 198/5198 [42:44<17:53:50, 12.89s/it]                                                     {'loss': 0.967, 'learning_rate': 1.9996575967625525e-05, 'epoch': 0.04}
  4%|â–         | 198/5198 [42:44<17:53:50, 12.89s/it]  4%|â–         | 199/5198 [42:55<17:20:54, 12.49s/it]                                                     {'loss': 0.9154, 'learning_rate': 1.999641098727329e-05, 'epoch': 0.04}
  4%|â–         | 199/5198 [42:55<17:20:54, 12.49s/it]  4%|â–         | 200/5198 [43:08<17:36:26, 12.68s/it]                                                     {'loss': 0.9416, 'learning_rate': 1.999624212597013e-05, 'epoch': 0.04}
  4%|â–         | 200/5198 [43:08<17:36:26, 12.68s/it]  4%|â–         | 201/5198 [43:20<17:20:10, 12.49s/it]                                                     {'loss': 0.9952, 'learning_rate': 1.9996069383781587e-05, 'epoch': 0.04}
  4%|â–         | 201/5198 [43:20<17:20:10, 12.49s/it]  4%|â–         | 202/5198 [43:32<17:01:22, 12.27s/it]                                                     {'loss': 0.9959, 'learning_rate': 1.9995892760774738e-05, 'epoch': 0.04}
  4%|â–         | 202/5198 [43:32<17:01:22, 12.27s/it]  4%|â–         | 203/5198 [43:44<16:44:59, 12.07s/it]                                                     {'loss': 0.975, 'learning_rate': 1.9995712257018153e-05, 'epoch': 0.04}
  4%|â–         | 203/5198 [43:44<16:44:59, 12.07s/it]  4%|â–         | 204/5198 [43:56<16:42:17, 12.04s/it]                                                     {'loss': 0.9134, 'learning_rate': 1.9995527872581903e-05, 'epoch': 0.04}
  4%|â–         | 204/5198 [43:56<16:42:17, 12.04s/it]  4%|â–         | 205/5198 [44:13<18:42:34, 13.49s/it]                                                     {'loss': 0.3353, 'learning_rate': 1.9995339607537578e-05, 'epoch': 0.04}
  4%|â–         | 205/5198 [44:13<18:42:34, 13.49s/it]  4%|â–         | 206/5198 [44:24<17:44:55, 12.80s/it]                                                     {'loss': 0.9346, 'learning_rate': 1.9995147461958267e-05, 'epoch': 0.04}
  4%|â–         | 206/5198 [44:24<17:44:55, 12.80s/it]  4%|â–         | 207/5198 [44:35<17:17:20, 12.47s/it]                                                     {'loss': 0.942, 'learning_rate': 1.999495143591857e-05, 'epoch': 0.04}
  4%|â–         | 207/5198 [44:36<17:17:20, 12.47s/it]  4%|â–         | 208/5198 [44:50<17:59:52, 12.98s/it]                                                     {'loss': 0.9444, 'learning_rate': 1.999475152949459e-05, 'epoch': 0.04}
  4%|â–         | 208/5198 [44:50<17:59:52, 12.98s/it]  4%|â–         | 209/5198 [45:02<17:56:28, 12.95s/it]                                                     {'loss': 0.9878, 'learning_rate': 1.9994547742763935e-05, 'epoch': 0.04}
  4%|â–         | 209/5198 [45:03<17:56:28, 12.95s/it]  4%|â–         | 210/5198 [45:16<18:08:57, 13.10s/it]                                                     {'loss': 0.9769, 'learning_rate': 1.9994340075805724e-05, 'epoch': 0.04}
  4%|â–         | 210/5198 [45:16<18:08:57, 13.10s/it]  4%|â–         | 211/5198 [45:28<17:43:37, 12.80s/it]                                                     {'loss': 0.9546, 'learning_rate': 1.9994128528700583e-05, 'epoch': 0.04}
  4%|â–         | 211/5198 [45:28<17:43:37, 12.80s/it]  4%|â–         | 212/5198 [45:40<17:28:33, 12.62s/it]                                                     {'loss': 0.8826, 'learning_rate': 1.9993913101530635e-05, 'epoch': 0.04}
  4%|â–         | 212/5198 [45:40<17:28:33, 12.62s/it]  4%|â–         | 213/5198 [45:52<17:07:32, 12.37s/it]                                                     {'loss': 0.9215, 'learning_rate': 1.9993693794379525e-05, 'epoch': 0.04}
  4%|â–         | 213/5198 [45:52<17:07:32, 12.37s/it]  4%|â–         | 214/5198 [46:04<16:59:44, 12.28s/it]                                                     {'loss': 0.9447, 'learning_rate': 1.9993470607332387e-05, 'epoch': 0.04}
  4%|â–         | 214/5198 [46:04<16:59:44, 12.28s/it]  4%|â–         | 215/5198 [46:16<16:49:17, 12.15s/it]                                                     {'loss': 0.9561, 'learning_rate': 1.999324354047588e-05, 'epoch': 0.04}
  4%|â–         | 215/5198 [46:16<16:49:17, 12.15s/it]  4%|â–         | 216/5198 [46:28<16:51:16, 12.18s/it]                                                     {'loss': 0.9691, 'learning_rate': 1.9993012593898146e-05, 'epoch': 0.04}
  4%|â–         | 216/5198 [46:28<16:51:16, 12.18s/it]  4%|â–         | 217/5198 [46:45<18:42:51, 13.53s/it]                                                     {'loss': 0.3087, 'learning_rate': 1.9992777767688857e-05, 'epoch': 0.04}
  4%|â–         | 217/5198 [46:45<18:42:51, 13.53s/it]  4%|â–         | 218/5198 [47:01<19:58:33, 14.44s/it]                                                     {'loss': 0.3359, 'learning_rate': 1.9992539061939175e-05, 'epoch': 0.04}
  4%|â–         | 218/5198 [47:01<19:58:33, 14.44s/it]  4%|â–         | 219/5198 [47:14<19:11:45, 13.88s/it]                                                     {'loss': 1.0012, 'learning_rate': 1.999229647674178e-05, 'epoch': 0.04}
  4%|â–         | 219/5198 [47:14<19:11:45, 13.88s/it]  4%|â–         | 220/5198 [47:30<20:14:23, 14.64s/it]                                                     {'loss': 0.299, 'learning_rate': 1.9992050012190845e-05, 'epoch': 0.04}
  4%|â–         | 220/5198 [47:31<20:14:23, 14.64s/it]  4%|â–         | 221/5198 [47:45<20:04:39, 14.52s/it]                                                     {'loss': 0.9492, 'learning_rate': 1.9991799668382058e-05, 'epoch': 0.04}
  4%|â–         | 221/5198 [47:45<20:04:39, 14.52s/it]  4%|â–         | 222/5198 [47:57<19:14:38, 13.92s/it]                                                     {'loss': 0.9444, 'learning_rate': 1.9991545445412614e-05, 'epoch': 0.04}
  4%|â–         | 222/5198 [47:57<19:14:38, 13.92s/it]  4%|â–         | 223/5198 [48:12<19:40:00, 14.23s/it]                                                     {'loss': 1.02, 'learning_rate': 1.9991287343381208e-05, 'epoch': 0.04}
  4%|â–         | 223/5198 [48:12<19:40:00, 14.23s/it]  4%|â–         | 224/5198 [48:24<18:29:39, 13.39s/it]                                                     {'loss': 0.9768, 'learning_rate': 1.9991025362388044e-05, 'epoch': 0.04}
  4%|â–         | 224/5198 [48:24<18:29:39, 13.39s/it]  4%|â–         | 225/5198 [48:35<17:45:49, 12.86s/it]                                                     {'loss': 0.9362, 'learning_rate': 1.9990759502534835e-05, 'epoch': 0.04}
  4%|â–         | 225/5198 [48:35<17:45:49, 12.86s/it]  4%|â–         | 226/5198 [48:52<19:18:50, 13.98s/it]                                                     {'loss': 0.2838, 'learning_rate': 1.9990489763924796e-05, 'epoch': 0.04}
  4%|â–         | 226/5198 [48:52<19:18:50, 13.98s/it]  4%|â–         | 227/5198 [49:03<18:19:36, 13.27s/it]                                                     {'loss': 0.905, 'learning_rate': 1.9990216146662648e-05, 'epoch': 0.04}
  4%|â–         | 227/5198 [49:03<18:19:36, 13.27s/it]  4%|â–         | 228/5198 [49:15<17:33:30, 12.72s/it]                                                     {'loss': 0.9789, 'learning_rate': 1.9989938650854618e-05, 'epoch': 0.04}
  4%|â–         | 228/5198 [49:15<17:33:30, 12.72s/it]  4%|â–         | 229/5198 [49:27<17:17:42, 12.53s/it]                                                     {'loss': 0.9194, 'learning_rate': 1.998965727660844e-05, 'epoch': 0.04}
  4%|â–         | 229/5198 [49:27<17:17:42, 12.53s/it]  4%|â–         | 230/5198 [49:39<17:02:10, 12.35s/it]                                                     {'loss': 0.9158, 'learning_rate': 1.9989372024033352e-05, 'epoch': 0.04}
  4%|â–         | 230/5198 [49:39<17:02:10, 12.35s/it]  4%|â–         | 231/5198 [49:50<16:36:56, 12.04s/it]                                                     {'loss': 0.9233, 'learning_rate': 1.99890828932401e-05, 'epoch': 0.04}
  4%|â–         | 231/5198 [49:50<16:36:56, 12.04s/it]  4%|â–         | 232/5198 [50:03<16:48:27, 12.18s/it]                                                     {'loss': 0.9235, 'learning_rate': 1.9988789884340938e-05, 'epoch': 0.04}
  4%|â–         | 232/5198 [50:03<16:48:27, 12.18s/it]  4%|â–         | 233/5198 [50:15<16:44:14, 12.14s/it]                                                     {'loss': 0.9462, 'learning_rate': 1.9988492997449615e-05, 'epoch': 0.04}
  4%|â–         | 233/5198 [50:15<16:44:14, 12.14s/it]  5%|â–         | 234/5198 [50:27<16:39:14, 12.08s/it]                                                     {'loss': 0.93, 'learning_rate': 1.9988192232681398e-05, 'epoch': 0.05}
  5%|â–         | 234/5198 [50:27<16:39:14, 12.08s/it]  5%|â–         | 235/5198 [50:38<16:20:00, 11.85s/it]                                                     {'loss': 0.9339, 'learning_rate': 1.9987887590153055e-05, 'epoch': 0.05}
  5%|â–         | 235/5198 [50:38<16:20:00, 11.85s/it]  5%|â–         | 236/5198 [50:51<17:01:39, 12.35s/it]                                                     {'loss': 0.993, 'learning_rate': 1.9987579069982856e-05, 'epoch': 0.05}
  5%|â–         | 236/5198 [50:52<17:01:39, 12.35s/it]  5%|â–         | 237/5198 [51:04<17:03:52, 12.38s/it]                                                     {'loss': 0.974, 'learning_rate': 1.9987266672290577e-05, 'epoch': 0.05}
  5%|â–         | 237/5198 [51:04<17:03:52, 12.38s/it]  5%|â–         | 238/5198 [51:16<16:52:42, 12.25s/it]                                                     {'loss': 0.9762, 'learning_rate': 1.9986950397197503e-05, 'epoch': 0.05}
  5%|â–         | 238/5198 [51:16<16:52:42, 12.25s/it]  5%|â–         | 239/5198 [51:29<17:09:17, 12.45s/it]                                                     {'loss': 0.9472, 'learning_rate': 1.9986630244826425e-05, 'epoch': 0.05}
  5%|â–         | 239/5198 [51:29<17:09:17, 12.45s/it]  5%|â–         | 240/5198 [51:40<16:48:53, 12.21s/it]                                                     {'loss': 0.9881, 'learning_rate': 1.998630621530164e-05, 'epoch': 0.05}
  5%|â–         | 240/5198 [51:41<16:48:53, 12.21s/it]  5%|â–         | 241/5198 [51:53<16:49:05, 12.21s/it]                                                     {'loss': 0.9605, 'learning_rate': 1.998597830874894e-05, 'epoch': 0.05}
  5%|â–         | 241/5198 [51:53<16:49:05, 12.21s/it]  5%|â–         | 242/5198 [52:04<16:35:14, 12.05s/it]                                                     {'loss': 0.8691, 'learning_rate': 1.9985646525295634e-05, 'epoch': 0.05}
  5%|â–         | 242/5198 [52:04<16:35:14, 12.05s/it]  5%|â–         | 243/5198 [52:16<16:32:45, 12.02s/it]                                                     {'loss': 0.9077, 'learning_rate': 1.998531086507053e-05, 'epoch': 0.05}
  5%|â–         | 243/5198 [52:16<16:32:45, 12.02s/it]  5%|â–         | 244/5198 [52:28<16:25:22, 11.93s/it]                                                     {'loss': 0.9321, 'learning_rate': 1.9984971328203945e-05, 'epoch': 0.05}
  5%|â–         | 244/5198 [52:28<16:25:22, 11.93s/it]  5%|â–         | 245/5198 [52:41<16:41:44, 12.13s/it]                                                     {'loss': 0.9463, 'learning_rate': 1.9984627914827698e-05, 'epoch': 0.05}
  5%|â–         | 245/5198 [52:41<16:41:44, 12.13s/it]  5%|â–         | 246/5198 [52:52<16:24:31, 11.93s/it]                                                     {'loss': 1.0008, 'learning_rate': 1.9984280625075115e-05, 'epoch': 0.05}
  5%|â–         | 246/5198 [52:52<16:24:31, 11.93s/it]  5%|â–         | 247/5198 [53:04<16:21:49, 11.90s/it]                                                     {'loss': 0.9338, 'learning_rate': 1.9983929459081022e-05, 'epoch': 0.05}
  5%|â–         | 247/5198 [53:04<16:21:49, 11.90s/it]  5%|â–         | 248/5198 [53:16<16:36:52, 12.08s/it]                                                     {'loss': 0.9416, 'learning_rate': 1.998357441698176e-05, 'epoch': 0.05}
  5%|â–         | 248/5198 [53:17<16:36:52, 12.08s/it]  5%|â–         | 249/5198 [53:30<17:22:06, 12.63s/it]                                                     {'loss': 0.9102, 'learning_rate': 1.998321549891516e-05, 'epoch': 0.05}
  5%|â–         | 249/5198 [53:30<17:22:06, 12.63s/it]  5%|â–         | 250/5198 [53:43<17:30:01, 12.73s/it]                                                     {'loss': 0.9005, 'learning_rate': 1.9982852705020572e-05, 'epoch': 0.05}
  5%|â–         | 250/5198 [53:43<17:30:01, 12.73s/it]  5%|â–         | 251/5198 [54:00<19:06:55, 13.91s/it]                                                     {'loss': 0.3204, 'learning_rate': 1.9982486035438848e-05, 'epoch': 0.05}
  5%|â–         | 251/5198 [54:00<19:06:55, 13.91s/it]  5%|â–         | 252/5198 [54:12<18:17:38, 13.32s/it]                                                     {'loss': 0.9384, 'learning_rate': 1.9982115490312334e-05, 'epoch': 0.05}
  5%|â–         | 252/5198 [54:12<18:17:38, 13.32s/it]  5%|â–         | 253/5198 [54:24<17:46:46, 12.94s/it]                                                     {'loss': 0.9469, 'learning_rate': 1.9981741069784894e-05, 'epoch': 0.05}
  5%|â–         | 253/5198 [54:24<17:46:46, 12.94s/it]  5%|â–         | 254/5198 [54:37<17:40:10, 12.87s/it]                                                     {'loss': 0.9309, 'learning_rate': 1.9981362774001886e-05, 'epoch': 0.05}
  5%|â–         | 254/5198 [54:37<17:40:10, 12.87s/it]  5%|â–         | 255/5198 [54:49<17:23:27, 12.67s/it]                                                     {'loss': 0.9687, 'learning_rate': 1.9980980603110185e-05, 'epoch': 0.05}
  5%|â–         | 255/5198 [54:49<17:23:27, 12.67s/it]  5%|â–         | 256/5198 [55:01<17:01:48, 12.41s/it]                                                     {'loss': 0.9011, 'learning_rate': 1.9980594557258158e-05, 'epoch': 0.05}
  5%|â–         | 256/5198 [55:01<17:01:48, 12.41s/it]  5%|â–         | 257/5198 [55:13<17:05:38, 12.45s/it]                                                     {'loss': 0.8675, 'learning_rate': 1.9980204636595682e-05, 'epoch': 0.05}
  5%|â–         | 257/5198 [55:13<17:05:38, 12.45s/it]  5%|â–         | 258/5198 [55:25<17:00:06, 12.39s/it]                                                     {'loss': 0.9477, 'learning_rate': 1.9979810841274135e-05, 'epoch': 0.05}
  5%|â–         | 258/5198 [55:26<17:00:06, 12.39s/it]  5%|â–         | 259/5198 [55:39<17:35:26, 12.82s/it]                                                     {'loss': 0.9813, 'learning_rate': 1.9979413171446403e-05, 'epoch': 0.05}
  5%|â–         | 259/5198 [55:39<17:35:26, 12.82s/it]  5%|â–Œ         | 260/5198 [55:51<17:15:46, 12.59s/it]                                                     {'loss': 0.9452, 'learning_rate': 1.9979011627266884e-05, 'epoch': 0.05}
  5%|â–Œ         | 260/5198 [55:51<17:15:46, 12.59s/it]  5%|â–Œ         | 261/5198 [56:03<16:49:09, 12.26s/it]                                                     {'loss': 0.9548, 'learning_rate': 1.997860620889146e-05, 'epoch': 0.05}
  5%|â–Œ         | 261/5198 [56:03<16:49:09, 12.26s/it]  5%|â–Œ         | 262/5198 [56:16<17:14:11, 12.57s/it]                                                     {'loss': 0.8105, 'learning_rate': 1.997819691647753e-05, 'epoch': 0.05}
  5%|â–Œ         | 262/5198 [56:16<17:14:11, 12.57s/it]  5%|â–Œ         | 263/5198 [56:28<16:59:18, 12.39s/it]                                                     {'loss': 0.9601, 'learning_rate': 1.9977783750184e-05, 'epoch': 0.05}
  5%|â–Œ         | 263/5198 [56:28<16:59:18, 12.39s/it]  5%|â–Œ         | 264/5198 [56:41<17:07:01, 12.49s/it]                                                     {'loss': 0.9403, 'learning_rate': 1.9977366710171274e-05, 'epoch': 0.05}
  5%|â–Œ         | 264/5198 [56:41<17:07:01, 12.49s/it]  5%|â–Œ         | 265/5198 [56:52<16:44:16, 12.22s/it]                                                     {'loss': 0.9429, 'learning_rate': 1.9976945796601258e-05, 'epoch': 0.05}
  5%|â–Œ         | 265/5198 [56:52<16:44:16, 12.22s/it]  5%|â–Œ         | 266/5198 [57:04<16:36:38, 12.12s/it]                                                     {'loss': 0.9377, 'learning_rate': 1.9976521009637366e-05, 'epoch': 0.05}
  5%|â–Œ         | 266/5198 [57:04<16:36:38, 12.12s/it]  5%|â–Œ         | 267/5198 [57:16<16:36:47, 12.13s/it]                                                     {'loss': 0.9438, 'learning_rate': 1.997609234944452e-05, 'epoch': 0.05}
  5%|â–Œ         | 267/5198 [57:17<16:36:47, 12.13s/it]  5%|â–Œ         | 268/5198 [57:28<16:31:39, 12.07s/it]                                                     {'loss': 1.0126, 'learning_rate': 1.9975659816189137e-05, 'epoch': 0.05}
  5%|â–Œ         | 268/5198 [57:28<16:31:39, 12.07s/it]  5%|â–Œ         | 269/5198 [57:43<17:41:11, 12.92s/it]                                                     {'loss': 0.8633, 'learning_rate': 1.997522341003914e-05, 'epoch': 0.05}
  5%|â–Œ         | 269/5198 [57:43<17:41:11, 12.92s/it]  5%|â–Œ         | 270/5198 [57:55<17:08:13, 12.52s/it]                                                     {'loss': 0.9296, 'learning_rate': 1.9974783131163957e-05, 'epoch': 0.05}
  5%|â–Œ         | 270/5198 [57:55<17:08:13, 12.52s/it]  5%|â–Œ         | 271/5198 [58:07<17:03:54, 12.47s/it]                                                     {'loss': 0.9499, 'learning_rate': 1.9974338979734523e-05, 'epoch': 0.05}
  5%|â–Œ         | 271/5198 [58:07<17:03:54, 12.47s/it]  5%|â–Œ         | 272/5198 [58:19<16:42:54, 12.22s/it]                                                     {'loss': 0.9683, 'learning_rate': 1.997389095592327e-05, 'epoch': 0.05}
  5%|â–Œ         | 272/5198 [58:19<16:42:54, 12.22s/it]  5%|â–Œ         | 273/5198 [58:30<16:21:38, 11.96s/it]                                                     {'loss': 0.9515, 'learning_rate': 1.9973439059904133e-05, 'epoch': 0.05}
  5%|â–Œ         | 273/5198 [58:30<16:21:38, 11.96s/it]  5%|â–Œ         | 274/5198 [58:43<16:41:03, 12.20s/it]                                                     {'loss': 0.9479, 'learning_rate': 1.9972983291852565e-05, 'epoch': 0.05}
  5%|â–Œ         | 274/5198 [58:43<16:41:03, 12.20s/it]  5%|â–Œ         | 275/5198 [58:55<16:36:16, 12.14s/it]                                                     {'loss': 0.9667, 'learning_rate': 1.9972523651945496e-05, 'epoch': 0.05}
  5%|â–Œ         | 275/5198 [58:55<16:36:16, 12.14s/it]  5%|â–Œ         | 276/5198 [59:07<16:22:40, 11.98s/it]                                                     {'loss': 0.9321, 'learning_rate': 1.9972060140361384e-05, 'epoch': 0.05}
  5%|â–Œ         | 276/5198 [59:07<16:22:40, 11.98s/it]  5%|â–Œ         | 277/5198 [59:19<16:22:19, 11.98s/it]                                                     {'loss': 0.9746, 'learning_rate': 1.997159275728018e-05, 'epoch': 0.05}
  5%|â–Œ         | 277/5198 [59:19<16:22:19, 11.98s/it]  5%|â–Œ         | 278/5198 [59:31<16:26:22, 12.03s/it]                                                     {'loss': 0.9605, 'learning_rate': 1.9971121502883332e-05, 'epoch': 0.05}
  5%|â–Œ         | 278/5198 [59:31<16:26:22, 12.03s/it]  5%|â–Œ         | 279/5198 [59:43<16:35:27, 12.14s/it]                                                     {'loss': 0.9615, 'learning_rate': 1.9970646377353802e-05, 'epoch': 0.05}
  5%|â–Œ         | 279/5198 [59:43<16:35:27, 12.14s/it]  5%|â–Œ         | 280/5198 [59:55<16:22:53, 11.99s/it]                                                     {'loss': 0.9627, 'learning_rate': 1.997016738087605e-05, 'epoch': 0.05}
  5%|â–Œ         | 280/5198 [59:55<16:22:53, 11.99s/it]  5%|â–Œ         | 281/5198 [1:00:07<16:20:51, 11.97s/it]                                                       {'loss': 0.9355, 'learning_rate': 1.9969684513636035e-05, 'epoch': 0.05}
  5%|â–Œ         | 281/5198 [1:00:07<16:20:51, 11.97s/it]  5%|â–Œ         | 282/5198 [1:00:20<16:53:37, 12.37s/it]                                                       {'loss': 0.9349, 'learning_rate': 1.9969197775821227e-05, 'epoch': 0.05}
  5%|â–Œ         | 282/5198 [1:00:20<16:53:37, 12.37s/it]  5%|â–Œ         | 283/5198 [1:00:32<16:49:05, 12.32s/it]                                                       {'loss': 0.9224, 'learning_rate': 1.9968707167620593e-05, 'epoch': 0.05}
  5%|â–Œ         | 283/5198 [1:00:32<16:49:05, 12.32s/it]  5%|â–Œ         | 284/5198 [1:00:45<16:55:23, 12.40s/it]                                                       {'loss': 0.9773, 'learning_rate': 1.9968212689224603e-05, 'epoch': 0.05}
  5%|â–Œ         | 284/5198 [1:00:45<16:55:23, 12.40s/it]  5%|â–Œ         | 285/5198 [1:00:57<16:44:26, 12.27s/it]                                                       {'loss': 0.8673, 'learning_rate': 1.996771434082523e-05, 'epoch': 0.05}
  5%|â–Œ         | 285/5198 [1:00:57<16:44:26, 12.27s/it]  6%|â–Œ         | 286/5198 [1:01:09<16:44:24, 12.27s/it]                                                       {'loss': 0.926, 'learning_rate': 1.9967212122615958e-05, 'epoch': 0.06}
  6%|â–Œ         | 286/5198 [1:01:09<16:44:24, 12.27s/it]  6%|â–Œ         | 287/5198 [1:01:21<16:39:35, 12.21s/it]                                                       {'loss': 0.8449, 'learning_rate': 1.9966706034791752e-05, 'epoch': 0.06}
  6%|â–Œ         | 287/5198 [1:01:21<16:39:35, 12.21s/it]  6%|â–Œ         | 288/5198 [1:01:33<16:39:21, 12.21s/it]                                                       {'loss': 0.8912, 'learning_rate': 1.9966196077549106e-05, 'epoch': 0.06}
  6%|â–Œ         | 288/5198 [1:01:33<16:39:21, 12.21s/it]  6%|â–Œ         | 289/5198 [1:01:45<16:39:55, 12.22s/it]                                                       {'loss': 0.9538, 'learning_rate': 1.996568225108599e-05, 'epoch': 0.06}
  6%|â–Œ         | 289/5198 [1:01:46<16:39:55, 12.22s/it]  6%|â–Œ         | 290/5198 [1:01:58<16:39:31, 12.22s/it]                                                       {'loss': 0.9341, 'learning_rate': 1.99651645556019e-05, 'epoch': 0.06}
  6%|â–Œ         | 290/5198 [1:01:58<16:39:31, 12.22s/it]  6%|â–Œ         | 291/5198 [1:02:09<16:23:01, 12.02s/it]                                                       {'loss': 0.9649, 'learning_rate': 1.9964642991297817e-05, 'epoch': 0.06}
  6%|â–Œ         | 291/5198 [1:02:09<16:23:01, 12.02s/it]  6%|â–Œ         | 292/5198 [1:02:21<16:06:22, 11.82s/it]                                                       {'loss': 0.9152, 'learning_rate': 1.996411755837623e-05, 'epoch': 0.06}
  6%|â–Œ         | 292/5198 [1:02:21<16:06:22, 11.82s/it]  6%|â–Œ         | 293/5198 [1:02:34<16:39:19, 12.22s/it]                                                       {'loss': 0.9102, 'learning_rate': 1.9963588257041137e-05, 'epoch': 0.06}
  6%|â–Œ         | 293/5198 [1:02:34<16:39:19, 12.22s/it]  6%|â–Œ         | 294/5198 [1:02:46<16:35:47, 12.18s/it]                                                       {'loss': 0.9716, 'learning_rate': 1.996305508749802e-05, 'epoch': 0.06}
  6%|â–Œ         | 294/5198 [1:02:46<16:35:47, 12.18s/it]  6%|â–Œ         | 295/5198 [1:02:59<17:02:18, 12.51s/it]                                                       {'loss': 0.9117, 'learning_rate': 1.9962518049953887e-05, 'epoch': 0.06}
  6%|â–Œ         | 295/5198 [1:02:59<17:02:18, 12.51s/it]  6%|â–Œ         | 296/5198 [1:03:11<16:38:09, 12.22s/it]                                                       {'loss': 0.9695, 'learning_rate': 1.9961977144617225e-05, 'epoch': 0.06}
  6%|â–Œ         | 296/5198 [1:03:11<16:38:09, 12.22s/it][2024-03-23 16:53:55,982] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  6%|â–Œ         | 297/5198 [1:03:28<18:34:50, 13.65s/it]                                                       {'loss': 0.3346, 'learning_rate': 1.996143237169803e-05, 'epoch': 0.06}
  6%|â–Œ         | 297/5198 [1:03:28<18:34:50, 13.65s/it]  6%|â–Œ         | 298/5198 [1:03:40<18:05:36, 13.29s/it]                                                       {'loss': 0.9301, 'learning_rate': 1.996088373140781e-05, 'epoch': 0.06}
  6%|â–Œ         | 298/5198 [1:03:40<18:05:36, 13.29s/it]  6%|â–Œ         | 299/5198 [1:03:51<17:15:10, 12.68s/it]                                                       {'loss': 0.9515, 'learning_rate': 1.9960331223959564e-05, 'epoch': 0.06}
  6%|â–Œ         | 299/5198 [1:03:51<17:15:10, 12.68s/it]  6%|â–Œ         | 300/5198 [1:04:03<16:59:11, 12.48s/it]                                                       {'loss': 0.8998, 'learning_rate': 1.995977484956779e-05, 'epoch': 0.06}
  6%|â–Œ         | 300/5198 [1:04:04<16:59:11, 12.48s/it]  6%|â–Œ         | 301/5198 [1:04:17<17:26:45, 12.83s/it]                                                       {'loss': 0.972, 'learning_rate': 1.9959214608448495e-05, 'epoch': 0.06}
  6%|â–Œ         | 301/5198 [1:04:17<17:26:45, 12.83s/it]  6%|â–Œ         | 302/5198 [1:04:30<17:28:10, 12.85s/it]                                                       {'loss': 0.9936, 'learning_rate': 1.9958650500819183e-05, 'epoch': 0.06}
  6%|â–Œ         | 302/5198 [1:04:30<17:28:10, 12.85s/it]  6%|â–Œ         | 303/5198 [1:04:41<16:56:46, 12.46s/it]                                                       {'loss': 0.9135, 'learning_rate': 1.995808252689886e-05, 'epoch': 0.06}
  6%|â–Œ         | 303/5198 [1:04:42<16:56:46, 12.46s/it]  6%|â–Œ         | 304/5198 [1:04:54<17:08:03, 12.60s/it]                                                       {'loss': 0.8864, 'learning_rate': 1.9957510686908034e-05, 'epoch': 0.06}
  6%|â–Œ         | 304/5198 [1:04:55<17:08:03, 12.60s/it]  6%|â–Œ         | 305/5198 [1:05:07<17:04:39, 12.56s/it]                                                       {'loss': 0.9459, 'learning_rate': 1.9956934981068713e-05, 'epoch': 0.06}
  6%|â–Œ         | 305/5198 [1:05:07<17:04:39, 12.56s/it]  6%|â–Œ         | 306/5198 [1:05:18<16:39:22, 12.26s/it]                                                       {'loss': 0.8798, 'learning_rate': 1.9956355409604402e-05, 'epoch': 0.06}
  6%|â–Œ         | 306/5198 [1:05:18<16:39:22, 12.26s/it]  6%|â–Œ         | 307/5198 [1:05:30<16:15:28, 11.97s/it]                                                       {'loss': 0.9756, 'learning_rate': 1.9955771972740118e-05, 'epoch': 0.06}
  6%|â–Œ         | 307/5198 [1:05:30<16:15:28, 11.97s/it]  6%|â–Œ         | 308/5198 [1:05:42<16:27:28, 12.12s/it]                                                       {'loss': 0.89, 'learning_rate': 1.9955184670702363e-05, 'epoch': 0.06}
  6%|â–Œ         | 308/5198 [1:05:42<16:27:28, 12.12s/it]  6%|â–Œ         | 309/5198 [1:05:54<16:11:49, 11.93s/it]                                                       {'loss': 0.9229, 'learning_rate': 1.995459350371915e-05, 'epoch': 0.06}
  6%|â–Œ         | 309/5198 [1:05:54<16:11:49, 11.93s/it]  6%|â–Œ         | 310/5198 [1:06:05<16:00:35, 11.79s/it]                                                       {'loss': 0.9386, 'learning_rate': 1.9953998472019996e-05, 'epoch': 0.06}
  6%|â–Œ         | 310/5198 [1:06:05<16:00:35, 11.79s/it]  6%|â–Œ         | 311/5198 [1:06:18<16:25:08, 12.09s/it]                                                       {'loss': 0.9153, 'learning_rate': 1.995339957583591e-05, 'epoch': 0.06}
  6%|â–Œ         | 311/5198 [1:06:18<16:25:08, 12.09s/it]  6%|â–Œ         | 312/5198 [1:06:31<16:38:37, 12.26s/it]                                                       {'loss': 0.869, 'learning_rate': 1.9952796815399403e-05, 'epoch': 0.06}
  6%|â–Œ         | 312/5198 [1:06:31<16:38:37, 12.26s/it]  6%|â–Œ         | 313/5198 [1:06:42<16:07:12, 11.88s/it]                                                       {'loss': 0.9663, 'learning_rate': 1.9952190190944484e-05, 'epoch': 0.06}
  6%|â–Œ         | 313/5198 [1:06:42<16:07:12, 11.88s/it]  6%|â–Œ         | 314/5198 [1:06:53<16:00:18, 11.80s/it]                                                       {'loss': 0.9965, 'learning_rate': 1.9951579702706668e-05, 'epoch': 0.06}
  6%|â–Œ         | 314/5198 [1:06:53<16:00:18, 11.80s/it]  6%|â–Œ         | 315/5198 [1:07:05<16:03:44, 11.84s/it]                                                       {'loss': 0.8769, 'learning_rate': 1.9950965350922975e-05, 'epoch': 0.06}
  6%|â–Œ         | 315/5198 [1:07:05<16:03:44, 11.84s/it]  6%|â–Œ         | 316/5198 [1:07:18<16:19:03, 12.03s/it]                                                       {'loss': 0.9374, 'learning_rate': 1.9950347135831907e-05, 'epoch': 0.06}
  6%|â–Œ         | 316/5198 [1:07:18<16:19:03, 12.03s/it]  6%|â–Œ         | 317/5198 [1:07:30<16:25:48, 12.12s/it]                                                       {'loss': 0.9568, 'learning_rate': 1.994972505767348e-05, 'epoch': 0.06}
  6%|â–Œ         | 317/5198 [1:07:30<16:25:48, 12.12s/it]  6%|â–Œ         | 318/5198 [1:07:42<16:16:46, 12.01s/it]                                                       {'loss': 0.9421, 'learning_rate': 1.994909911668921e-05, 'epoch': 0.06}
  6%|â–Œ         | 318/5198 [1:07:42<16:16:46, 12.01s/it]  6%|â–Œ         | 319/5198 [1:07:54<16:15:57, 12.00s/it]                                                       {'loss': 0.9295, 'learning_rate': 1.99484693131221e-05, 'epoch': 0.06}
  6%|â–Œ         | 319/5198 [1:07:54<16:15:57, 12.00s/it]  6%|â–Œ         | 320/5198 [1:08:07<16:56:03, 12.50s/it]                                                       {'loss': 0.9115, 'learning_rate': 1.994783564721667e-05, 'epoch': 0.06}
  6%|â–Œ         | 320/5198 [1:08:07<16:56:03, 12.50s/it]  6%|â–Œ         | 321/5198 [1:08:20<16:49:32, 12.42s/it]                                                       {'loss': 0.9022, 'learning_rate': 1.9947198119218924e-05, 'epoch': 0.06}
  6%|â–Œ         | 321/5198 [1:08:20<16:49:32, 12.42s/it]  6%|â–Œ         | 322/5198 [1:08:38<19:15:48, 14.22s/it]                                                       {'loss': 0.2805, 'learning_rate': 1.994655672937638e-05, 'epoch': 0.06}
  6%|â–Œ         | 322/5198 [1:08:38<19:15:48, 14.22s/it]  6%|â–Œ         | 323/5198 [1:08:51<18:35:47, 13.73s/it]                                                       {'loss': 1.0148, 'learning_rate': 1.9945911477938044e-05, 'epoch': 0.06}
  6%|â–Œ         | 323/5198 [1:08:51<18:35:47, 13.73s/it]  6%|â–Œ         | 324/5198 [1:09:02<17:42:13, 13.08s/it]                                                       {'loss': 0.9498, 'learning_rate': 1.994526236515442e-05, 'epoch': 0.06}
  6%|â–Œ         | 324/5198 [1:09:02<17:42:13, 13.08s/it]  6%|â–‹         | 325/5198 [1:09:14<17:03:00, 12.60s/it]                                                       {'loss': 0.9924, 'learning_rate': 1.994460939127753e-05, 'epoch': 0.06}
  6%|â–‹         | 325/5198 [1:09:14<17:03:00, 12.60s/it]  6%|â–‹         | 326/5198 [1:09:26<16:46:46, 12.40s/it]                                                       {'loss': 0.875, 'learning_rate': 1.9943952556560863e-05, 'epoch': 0.06}
  6%|â–‹         | 326/5198 [1:09:26<16:46:46, 12.40s/it]  6%|â–‹         | 327/5198 [1:09:37<16:34:02, 12.24s/it]                                                       {'loss': 0.9845, 'learning_rate': 1.9943291861259433e-05, 'epoch': 0.06}
  6%|â–‹         | 327/5198 [1:09:38<16:34:02, 12.24s/it]  6%|â–‹         | 328/5198 [1:09:52<17:27:01, 12.90s/it]                                                       {'loss': 0.9215, 'learning_rate': 1.9942627305629747e-05, 'epoch': 0.06}
  6%|â–‹         | 328/5198 [1:09:52<17:27:01, 12.90s/it]  6%|â–‹         | 329/5198 [1:10:03<16:48:48, 12.43s/it]                                                       {'loss': 0.9227, 'learning_rate': 1.9941958889929808e-05, 'epoch': 0.06}
  6%|â–‹         | 329/5198 [1:10:03<16:48:48, 12.43s/it]  6%|â–‹         | 330/5198 [1:10:16<17:03:36, 12.62s/it]                                                       {'loss': 0.8874, 'learning_rate': 1.9941286614419113e-05, 'epoch': 0.06}
  6%|â–‹         | 330/5198 [1:10:16<17:03:36, 12.62s/it]  6%|â–‹         | 331/5198 [1:10:29<17:08:34, 12.68s/it]                                                       {'loss': 0.9528, 'learning_rate': 1.994061047935867e-05, 'epoch': 0.06}
  6%|â–‹         | 331/5198 [1:10:29<17:08:34, 12.68s/it]  6%|â–‹         | 332/5198 [1:10:41<17:00:18, 12.58s/it]                                                       {'loss': 0.9335, 'learning_rate': 1.9939930485010968e-05, 'epoch': 0.06}
  6%|â–‹         | 332/5198 [1:10:41<17:00:18, 12.58s/it]  6%|â–‹         | 333/5198 [1:10:53<16:40:46, 12.34s/it]                                                       {'loss': 0.9213, 'learning_rate': 1.9939246631640014e-05, 'epoch': 0.06}
  6%|â–‹         | 333/5198 [1:10:53<16:40:46, 12.34s/it]  6%|â–‹         | 334/5198 [1:11:05<16:32:33, 12.24s/it]                                                       {'loss': 0.8656, 'learning_rate': 1.99385589195113e-05, 'epoch': 0.06}
  6%|â–‹         | 334/5198 [1:11:05<16:32:33, 12.24s/it]  6%|â–‹         | 335/5198 [1:11:17<16:15:16, 12.03s/it]                                                       {'loss': 0.9419, 'learning_rate': 1.9937867348891815e-05, 'epoch': 0.06}
  6%|â–‹         | 335/5198 [1:11:17<16:15:16, 12.03s/it]  6%|â–‹         | 336/5198 [1:11:30<16:37:36, 12.31s/it]                                                       {'loss': 0.9438, 'learning_rate': 1.9937171920050057e-05, 'epoch': 0.06}
  6%|â–‹         | 336/5198 [1:11:30<16:37:36, 12.31s/it]  6%|â–‹         | 337/5198 [1:11:41<16:16:01, 12.05s/it]                                                       {'loss': 0.918, 'learning_rate': 1.9936472633256012e-05, 'epoch': 0.06}
  6%|â–‹         | 337/5198 [1:11:41<16:16:01, 12.05s/it]  7%|â–‹         | 338/5198 [1:11:53<16:14:27, 12.03s/it]                                                       {'loss': 0.944, 'learning_rate': 1.9935769488781167e-05, 'epoch': 0.07}
  7%|â–‹         | 338/5198 [1:11:53<16:14:27, 12.03s/it]  7%|â–‹         | 339/5198 [1:12:04<15:57:17, 11.82s/it]                                                       {'loss': 0.9629, 'learning_rate': 1.993506248689851e-05, 'epoch': 0.07}
  7%|â–‹         | 339/5198 [1:12:05<15:57:17, 11.82s/it]  7%|â–‹         | 340/5198 [1:12:17<16:25:29, 12.17s/it]                                                       {'loss': 0.9233, 'learning_rate': 1.993435162788252e-05, 'epoch': 0.07}
  7%|â–‹         | 340/5198 [1:12:18<16:25:29, 12.17s/it]  7%|â–‹         | 341/5198 [1:12:29<16:12:16, 12.01s/it]                                                       {'loss': 0.9569, 'learning_rate': 1.993363691200918e-05, 'epoch': 0.07}
  7%|â–‹         | 341/5198 [1:12:29<16:12:16, 12.01s/it]  7%|â–‹         | 342/5198 [1:12:43<16:57:57, 12.58s/it]                                                       {'loss': 0.8741, 'learning_rate': 1.9932918339555965e-05, 'epoch': 0.07}
  7%|â–‹         | 342/5198 [1:12:43<16:57:57, 12.58s/it]  7%|â–‹         | 343/5198 [1:12:54<16:28:47, 12.22s/it]                                                       {'loss': 0.9788, 'learning_rate': 1.9932195910801848e-05, 'epoch': 0.07}
  7%|â–‹         | 343/5198 [1:12:54<16:28:47, 12.22s/it]  7%|â–‹         | 344/5198 [1:13:06<16:19:04, 12.10s/it]                                                       {'loss': 0.9107, 'learning_rate': 1.9931469626027305e-05, 'epoch': 0.07}
  7%|â–‹         | 344/5198 [1:13:06<16:19:04, 12.10s/it]  7%|â–‹         | 345/5198 [1:13:18<16:10:41, 12.00s/it]                                                       {'loss': 0.9166, 'learning_rate': 1.9930739485514304e-05, 'epoch': 0.07}
  7%|â–‹         | 345/5198 [1:13:18<16:10:41, 12.00s/it]  7%|â–‹         | 346/5198 [1:13:30<16:12:32, 12.03s/it]                                                       {'loss': 0.931, 'learning_rate': 1.9930005489546308e-05, 'epoch': 0.07}
  7%|â–‹         | 346/5198 [1:13:30<16:12:32, 12.03s/it]  7%|â–‹         | 347/5198 [1:13:42<16:09:26, 11.99s/it]                                                       {'loss': 0.9633, 'learning_rate': 1.9929267638408277e-05, 'epoch': 0.07}
  7%|â–‹         | 347/5198 [1:13:42<16:09:26, 11.99s/it]  7%|â–‹         | 348/5198 [1:13:53<15:57:33, 11.85s/it]                                                       {'loss': 0.9272, 'learning_rate': 1.9928525932386678e-05, 'epoch': 0.07}
  7%|â–‹         | 348/5198 [1:13:54<15:57:33, 11.85s/it]  7%|â–‹         | 349/5198 [1:14:06<16:22:27, 12.16s/it]                                                       {'loss': 0.9508, 'learning_rate': 1.9927780371769463e-05, 'epoch': 0.07}
  7%|â–‹         | 349/5198 [1:14:06<16:22:27, 12.16s/it]  7%|â–‹         | 350/5198 [1:14:19<16:41:07, 12.39s/it]                                                       {'loss': 0.88, 'learning_rate': 1.9927030956846083e-05, 'epoch': 0.07}
  7%|â–‹         | 350/5198 [1:14:19<16:41:07, 12.39s/it]  7%|â–‹         | 351/5198 [1:14:31<16:22:47, 12.17s/it]                                                       {'loss': 0.9213, 'learning_rate': 1.992627768790749e-05, 'epoch': 0.07}
  7%|â–‹         | 351/5198 [1:14:31<16:22:47, 12.17s/it]  7%|â–‹         | 352/5198 [1:14:48<18:15:48, 13.57s/it]                                                       {'loss': 0.3238, 'learning_rate': 1.9925520565246125e-05, 'epoch': 0.07}
  7%|â–‹         | 352/5198 [1:14:48<18:15:48, 13.57s/it]  7%|â–‹         | 353/5198 [1:15:00<17:47:29, 13.22s/it]                                                       {'loss': 0.9049, 'learning_rate': 1.9924759589155932e-05, 'epoch': 0.07}
  7%|â–‹         | 353/5198 [1:15:00<17:47:29, 13.22s/it]  7%|â–‹         | 354/5198 [1:15:12<17:23:01, 12.92s/it]                                                       {'loss': 0.9769, 'learning_rate': 1.9923994759932344e-05, 'epoch': 0.07}
  7%|â–‹         | 354/5198 [1:15:13<17:23:01, 12.92s/it]  7%|â–‹         | 355/5198 [1:15:24<16:50:40, 12.52s/it]                                                       {'loss': 0.906, 'learning_rate': 1.9923226077872296e-05, 'epoch': 0.07}
  7%|â–‹         | 355/5198 [1:15:24<16:50:40, 12.52s/it]  7%|â–‹         | 356/5198 [1:15:37<17:08:25, 12.74s/it]                                                       {'loss': 0.9141, 'learning_rate': 1.9922453543274223e-05, 'epoch': 0.07}
  7%|â–‹         | 356/5198 [1:15:37<17:08:25, 12.74s/it]  7%|â–‹         | 357/5198 [1:15:50<17:01:39, 12.66s/it]                                                       {'loss': 0.9155, 'learning_rate': 1.9921677156438044e-05, 'epoch': 0.07}
  7%|â–‹         | 357/5198 [1:15:50<17:01:39, 12.66s/it]  7%|â–‹         | 358/5198 [1:16:03<17:14:02, 12.82s/it]                                                       {'loss': 0.9836, 'learning_rate': 1.9920896917665178e-05, 'epoch': 0.07}
  7%|â–‹         | 358/5198 [1:16:03<17:14:02, 12.82s/it]  7%|â–‹         | 359/5198 [1:16:15<16:54:20, 12.58s/it]                                                       {'loss': 0.9896, 'learning_rate': 1.992011282725854e-05, 'epoch': 0.07}
  7%|â–‹         | 359/5198 [1:16:15<16:54:20, 12.58s/it]  7%|â–‹         | 360/5198 [1:16:27<16:34:21, 12.33s/it]                                                       {'loss': 0.9294, 'learning_rate': 1.9919324885522548e-05, 'epoch': 0.07}
  7%|â–‹         | 360/5198 [1:16:27<16:34:21, 12.33s/it]  7%|â–‹         | 361/5198 [1:16:39<16:37:55, 12.38s/it]                                                       {'loss': 0.9307, 'learning_rate': 1.99185330927631e-05, 'epoch': 0.07}
  7%|â–‹         | 361/5198 [1:16:39<16:37:55, 12.38s/it]  7%|â–‹         | 362/5198 [1:16:51<16:31:26, 12.30s/it]                                                       {'loss': 0.8997, 'learning_rate': 1.99177374492876e-05, 'epoch': 0.07}
  7%|â–‹         | 362/5198 [1:16:51<16:31:26, 12.30s/it]  7%|â–‹         | 363/5198 [1:17:03<16:10:25, 12.04s/it]                                                       {'loss': 0.9275, 'learning_rate': 1.991693795540494e-05, 'epoch': 0.07}
  7%|â–‹         | 363/5198 [1:17:03<16:10:25, 12.04s/it]  7%|â–‹         | 364/5198 [1:17:17<17:06:11, 12.74s/it]                                                       {'loss': 0.9073, 'learning_rate': 1.9916134611425522e-05, 'epoch': 0.07}
  7%|â–‹         | 364/5198 [1:17:17<17:06:11, 12.74s/it]  7%|â–‹         | 365/5198 [1:17:31<17:28:48, 13.02s/it]                                                       {'loss': 0.908, 'learning_rate': 1.9915327417661226e-05, 'epoch': 0.07}
  7%|â–‹         | 365/5198 [1:17:31<17:28:48, 13.02s/it]  7%|â–‹         | 366/5198 [1:17:43<16:58:49, 12.65s/it]                                                       {'loss': 0.9393, 'learning_rate': 1.991451637442543e-05, 'epoch': 0.07}
  7%|â–‹         | 366/5198 [1:17:43<16:58:49, 12.65s/it]  7%|â–‹         | 367/5198 [1:17:58<17:58:18, 13.39s/it]                                                       {'loss': 0.9582, 'learning_rate': 1.9913701482033008e-05, 'epoch': 0.07}
  7%|â–‹         | 367/5198 [1:17:58<17:58:18, 13.39s/it]  7%|â–‹         | 368/5198 [1:18:10<17:40:36, 13.18s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.9912882740800336e-05, 'epoch': 0.07}
  7%|â–‹         | 368/5198 [1:18:10<17:40:36, 13.18s/it]  7%|â–‹         | 369/5198 [1:18:23<17:30:51, 13.06s/it]                                                       {'loss': 0.9269, 'learning_rate': 1.9912060151045273e-05, 'epoch': 0.07}
  7%|â–‹         | 369/5198 [1:18:23<17:30:51, 13.06s/it]  7%|â–‹         | 370/5198 [1:18:37<17:51:28, 13.32s/it]                                                       {'loss': 0.9646, 'learning_rate': 1.9911233713087172e-05, 'epoch': 0.07}
  7%|â–‹         | 370/5198 [1:18:37<17:51:28, 13.32s/it]  7%|â–‹         | 371/5198 [1:18:50<17:43:28, 13.22s/it]                                                       {'loss': 0.9365, 'learning_rate': 1.9910403427246895e-05, 'epoch': 0.07}
  7%|â–‹         | 371/5198 [1:18:50<17:43:28, 13.22s/it]  7%|â–‹         | 372/5198 [1:19:02<17:08:23, 12.79s/it]                                                       {'loss': 0.9339, 'learning_rate': 1.990956929384678e-05, 'epoch': 0.07}
  7%|â–‹         | 372/5198 [1:19:02<17:08:23, 12.79s/it]  7%|â–‹         | 373/5198 [1:19:14<16:48:50, 12.55s/it]                                                       {'loss': 0.9083, 'learning_rate': 1.990873131321067e-05, 'epoch': 0.07}
  7%|â–‹         | 373/5198 [1:19:14<16:48:50, 12.55s/it]  7%|â–‹         | 374/5198 [1:19:27<16:54:17, 12.62s/it]                                                       {'loss': 0.9452, 'learning_rate': 1.9907889485663897e-05, 'epoch': 0.07}
  7%|â–‹         | 374/5198 [1:19:27<16:54:17, 12.62s/it]  7%|â–‹         | 375/5198 [1:19:39<16:57:20, 12.66s/it]                                                       {'loss': 0.9064, 'learning_rate': 1.9907043811533283e-05, 'epoch': 0.07}
  7%|â–‹         | 375/5198 [1:19:39<16:57:20, 12.66s/it]  7%|â–‹         | 376/5198 [1:19:51<16:38:12, 12.42s/it]                                                       {'loss': 0.8983, 'learning_rate': 1.9906194291147155e-05, 'epoch': 0.07}
  7%|â–‹         | 376/5198 [1:19:51<16:38:12, 12.42s/it]  7%|â–‹         | 377/5198 [1:20:03<16:14:35, 12.13s/it]                                                       {'loss': 0.973, 'learning_rate': 1.9905340924835322e-05, 'epoch': 0.07}
  7%|â–‹         | 377/5198 [1:20:03<16:14:35, 12.13s/it]  7%|â–‹         | 378/5198 [1:20:15<16:13:28, 12.12s/it]                                                       {'loss': 0.8877, 'learning_rate': 1.9904483712929094e-05, 'epoch': 0.07}
  7%|â–‹         | 378/5198 [1:20:15<16:13:28, 12.12s/it]  7%|â–‹         | 379/5198 [1:20:27<16:15:32, 12.15s/it]                                                       {'loss': 0.9208, 'learning_rate': 1.9903622655761267e-05, 'epoch': 0.07}
  7%|â–‹         | 379/5198 [1:20:27<16:15:32, 12.15s/it]  7%|â–‹         | 380/5198 [1:20:39<16:01:52, 11.98s/it]                                                       {'loss': 0.9096, 'learning_rate': 1.990275775366613e-05, 'epoch': 0.07}
  7%|â–‹         | 380/5198 [1:20:39<16:01:52, 11.98s/it]  7%|â–‹         | 381/5198 [1:20:50<15:49:14, 11.82s/it]                                                       {'loss': 0.9334, 'learning_rate': 1.9901889006979473e-05, 'epoch': 0.07}
  7%|â–‹         | 381/5198 [1:20:50<15:49:14, 11.82s/it]  7%|â–‹         | 382/5198 [1:21:01<15:40:59, 11.72s/it]                                                       {'loss': 0.9104, 'learning_rate': 1.990101641603857e-05, 'epoch': 0.07}
  7%|â–‹         | 382/5198 [1:21:02<15:40:59, 11.72s/it]  7%|â–‹         | 383/5198 [1:21:15<16:18:02, 12.19s/it]                                                       {'loss': 0.913, 'learning_rate': 1.9900139981182193e-05, 'epoch': 0.07}
  7%|â–‹         | 383/5198 [1:21:15<16:18:02, 12.19s/it]  7%|â–‹         | 384/5198 [1:21:26<16:05:20, 12.03s/it]                                                       {'loss': 0.9012, 'learning_rate': 1.9899259702750604e-05, 'epoch': 0.07}
  7%|â–‹         | 384/5198 [1:21:27<16:05:20, 12.03s/it]  7%|â–‹         | 385/5198 [1:21:39<16:07:49, 12.07s/it]                                                       {'loss': 0.914, 'learning_rate': 1.9898375581085555e-05, 'epoch': 0.07}
  7%|â–‹         | 385/5198 [1:21:39<16:07:49, 12.07s/it]  7%|â–‹         | 386/5198 [1:21:51<16:14:38, 12.15s/it]                                                       {'loss': 0.9366, 'learning_rate': 1.9897487616530296e-05, 'epoch': 0.07}
  7%|â–‹         | 386/5198 [1:21:51<16:14:38, 12.15s/it]  7%|â–‹         | 387/5198 [1:22:03<16:07:42, 12.07s/it]                                                       {'loss': 0.9397, 'learning_rate': 1.9896595809429565e-05, 'epoch': 0.07}
  7%|â–‹         | 387/5198 [1:22:03<16:07:42, 12.07s/it]  7%|â–‹         | 388/5198 [1:22:14<15:49:23, 11.84s/it]                                                       {'loss': 0.8955, 'learning_rate': 1.9895700160129593e-05, 'epoch': 0.07}
  7%|â–‹         | 388/5198 [1:22:14<15:49:23, 11.84s/it]  7%|â–‹         | 389/5198 [1:22:26<15:38:27, 11.71s/it]                                                       {'loss': 0.9404, 'learning_rate': 1.9894800668978095e-05, 'epoch': 0.07}
  7%|â–‹         | 389/5198 [1:22:26<15:38:27, 11.71s/it]  8%|â–Š         | 390/5198 [1:22:38<15:44:46, 11.79s/it]                                                       {'loss': 0.9409, 'learning_rate': 1.9893897336324292e-05, 'epoch': 0.08}
  8%|â–Š         | 390/5198 [1:22:38<15:44:46, 11.79s/it]  8%|â–Š         | 391/5198 [1:22:50<15:58:13, 11.96s/it]                                                       {'loss': 0.9459, 'learning_rate': 1.9892990162518884e-05, 'epoch': 0.08}
  8%|â–Š         | 391/5198 [1:22:50<15:58:13, 11.96s/it]  8%|â–Š         | 392/5198 [1:23:05<17:05:20, 12.80s/it]                                                       {'loss': 0.9678, 'learning_rate': 1.9892079147914072e-05, 'epoch': 0.08}
  8%|â–Š         | 392/5198 [1:23:05<17:05:20, 12.80s/it]  8%|â–Š         | 393/5198 [1:23:20<17:55:28, 13.43s/it]                                                       {'loss': 0.9204, 'learning_rate': 1.9891164292863537e-05, 'epoch': 0.08}
  8%|â–Š         | 393/5198 [1:23:20<17:55:28, 13.43s/it]  8%|â–Š         | 394/5198 [1:23:32<17:26:40, 13.07s/it]                                                       {'loss': 0.9586, 'learning_rate': 1.9890245597722465e-05, 'epoch': 0.08}
  8%|â–Š         | 394/5198 [1:23:32<17:26:40, 13.07s/it]  8%|â–Š         | 395/5198 [1:23:45<17:32:39, 13.15s/it]                                                       {'loss': 0.9297, 'learning_rate': 1.9889323062847516e-05, 'epoch': 0.08}
  8%|â–Š         | 395/5198 [1:23:45<17:32:39, 13.15s/it]  8%|â–Š         | 396/5198 [1:23:57<16:56:52, 12.71s/it]                                                       {'loss': 0.9629, 'learning_rate': 1.988839668859686e-05, 'epoch': 0.08}
  8%|â–Š         | 396/5198 [1:23:57<16:56:52, 12.71s/it]  8%|â–Š         | 397/5198 [1:24:09<16:39:53, 12.50s/it]                                                       {'loss': 0.8943, 'learning_rate': 1.988746647533014e-05, 'epoch': 0.08}
  8%|â–Š         | 397/5198 [1:24:09<16:39:53, 12.50s/it]  8%|â–Š         | 398/5198 [1:24:21<16:26:45, 12.33s/it]                                                       {'loss': 0.9646, 'learning_rate': 1.9886532423408495e-05, 'epoch': 0.08}
  8%|â–Š         | 398/5198 [1:24:21<16:26:45, 12.33s/it]  8%|â–Š         | 399/5198 [1:24:33<16:25:44, 12.32s/it]                                                       {'loss': 0.9431, 'learning_rate': 1.9885594533194564e-05, 'epoch': 0.08}
  8%|â–Š         | 399/5198 [1:24:33<16:25:44, 12.32s/it]  8%|â–Š         | 400/5198 [1:24:45<16:17:07, 12.22s/it]                                                       {'loss': 0.8803, 'learning_rate': 1.9884652805052465e-05, 'epoch': 0.08}
  8%|â–Š         | 400/5198 [1:24:45<16:17:07, 12.22s/it]  8%|â–Š         | 401/5198 [1:24:56<15:57:29, 11.98s/it]                                                       {'loss': 0.9005, 'learning_rate': 1.9883707239347804e-05, 'epoch': 0.08}
  8%|â–Š         | 401/5198 [1:24:56<15:57:29, 11.98s/it]  8%|â–Š         | 402/5198 [1:25:09<16:17:09, 12.22s/it]                                                       {'loss': 0.9208, 'learning_rate': 1.988275783644769e-05, 'epoch': 0.08}
  8%|â–Š         | 402/5198 [1:25:09<16:17:09, 12.22s/it]  8%|â–Š         | 403/5198 [1:25:21<16:10:20, 12.14s/it]                                                       {'loss': 0.9514, 'learning_rate': 1.988180459672071e-05, 'epoch': 0.08}
  8%|â–Š         | 403/5198 [1:25:21<16:10:20, 12.14s/it]  8%|â–Š         | 404/5198 [1:25:33<15:57:37, 11.99s/it]                                                       {'loss': 0.9384, 'learning_rate': 1.988084752053695e-05, 'epoch': 0.08}
  8%|â–Š         | 404/5198 [1:25:33<15:57:37, 11.99s/it]  8%|â–Š         | 405/5198 [1:25:45<16:09:02, 12.13s/it]                                                       {'loss': 0.9535, 'learning_rate': 1.9879886608267967e-05, 'epoch': 0.08}
  8%|â–Š         | 405/5198 [1:25:45<16:09:02, 12.13s/it]  8%|â–Š         | 406/5198 [1:25:57<16:02:28, 12.05s/it]                                                       {'loss': 0.9627, 'learning_rate': 1.9878921860286832e-05, 'epoch': 0.08}
  8%|â–Š         | 406/5198 [1:25:57<16:02:28, 12.05s/it]  8%|â–Š         | 407/5198 [1:26:09<15:56:14, 11.98s/it]                                                       {'loss': 0.9068, 'learning_rate': 1.9877953276968088e-05, 'epoch': 0.08}
  8%|â–Š         | 407/5198 [1:26:09<15:56:14, 11.98s/it]  8%|â–Š         | 408/5198 [1:26:21<16:02:49, 12.06s/it]                                                       {'loss': 0.8982, 'learning_rate': 1.9876980858687777e-05, 'epoch': 0.08}
  8%|â–Š         | 408/5198 [1:26:21<16:02:49, 12.06s/it]  8%|â–Š         | 409/5198 [1:26:38<17:46:23, 13.36s/it]                                                       {'loss': 0.2942, 'learning_rate': 1.9876004605823417e-05, 'epoch': 0.08}
  8%|â–Š         | 409/5198 [1:26:38<17:46:23, 13.36s/it]  8%|â–Š         | 410/5198 [1:26:54<19:05:41, 14.36s/it]                                                       {'loss': 0.3068, 'learning_rate': 1.987502451875403e-05, 'epoch': 0.08}
  8%|â–Š         | 410/5198 [1:26:54<19:05:41, 14.36s/it]  8%|â–Š         | 411/5198 [1:27:06<18:04:09, 13.59s/it]                                                       {'loss': 0.9017, 'learning_rate': 1.987404059786012e-05, 'epoch': 0.08}
  8%|â–Š         | 411/5198 [1:27:06<18:04:09, 13.59s/it]  8%|â–Š         | 412/5198 [1:27:18<17:27:45, 13.14s/it]                                                       {'loss': 0.9283, 'learning_rate': 1.9873052843523676e-05, 'epoch': 0.08}
  8%|â–Š         | 412/5198 [1:27:18<17:27:45, 13.14s/it]  8%|â–Š         | 413/5198 [1:27:30<16:50:47, 12.67s/it]                                                       {'loss': 0.9215, 'learning_rate': 1.987206125612818e-05, 'epoch': 0.08}
  8%|â–Š         | 413/5198 [1:27:30<16:50:47, 12.67s/it]  8%|â–Š         | 414/5198 [1:27:42<16:31:29, 12.44s/it]                                                       {'loss': 0.9304, 'learning_rate': 1.98710658360586e-05, 'epoch': 0.08}
  8%|â–Š         | 414/5198 [1:27:42<16:31:29, 12.44s/it]  8%|â–Š         | 415/5198 [1:27:53<16:17:28, 12.26s/it]                                                       {'loss': 0.9015, 'learning_rate': 1.987006658370139e-05, 'epoch': 0.08}
  8%|â–Š         | 415/5198 [1:27:54<16:17:28, 12.26s/it]  8%|â–Š         | 416/5198 [1:28:05<16:11:56, 12.20s/it]                                                       {'loss': 0.9526, 'learning_rate': 1.9869063499444495e-05, 'epoch': 0.08}
  8%|â–Š         | 416/5198 [1:28:06<16:11:56, 12.20s/it]  8%|â–Š         | 417/5198 [1:28:20<17:09:30, 12.92s/it]                                                       {'loss': 0.9591, 'learning_rate': 1.9868056583677346e-05, 'epoch': 0.08}
  8%|â–Š         | 417/5198 [1:28:20<17:09:30, 12.92s/it]  8%|â–Š         | 418/5198 [1:28:33<17:03:34, 12.85s/it]                                                       {'loss': 0.9033, 'learning_rate': 1.9867045836790867e-05, 'epoch': 0.08}
  8%|â–Š         | 418/5198 [1:28:33<17:03:34, 12.85s/it]  8%|â–Š         | 419/5198 [1:28:46<17:03:42, 12.85s/it]                                                       {'loss': 0.9467, 'learning_rate': 1.9866031259177463e-05, 'epoch': 0.08}
  8%|â–Š         | 419/5198 [1:28:46<17:03:42, 12.85s/it]  8%|â–Š         | 420/5198 [1:28:57<16:36:55, 12.52s/it]                                                       {'loss': 0.9435, 'learning_rate': 1.9865012851231022e-05, 'epoch': 0.08}
  8%|â–Š         | 420/5198 [1:28:57<16:36:55, 12.52s/it]  8%|â–Š         | 421/5198 [1:29:12<17:33:57, 13.24s/it]                                                       {'loss': 0.9628, 'learning_rate': 1.9863990613346936e-05, 'epoch': 0.08}
  8%|â–Š         | 421/5198 [1:29:12<17:33:57, 13.24s/it]  8%|â–Š         | 422/5198 [1:29:25<17:19:36, 13.06s/it]                                                       {'loss': 0.9278, 'learning_rate': 1.986296454592206e-05, 'epoch': 0.08}
  8%|â–Š         | 422/5198 [1:29:25<17:19:36, 13.06s/it]  8%|â–Š         | 423/5198 [1:29:37<16:54:54, 12.75s/it]                                                       {'loss': 0.9603, 'learning_rate': 1.9861934649354763e-05, 'epoch': 0.08}
  8%|â–Š         | 423/5198 [1:29:37<16:54:54, 12.75s/it]  8%|â–Š         | 424/5198 [1:29:51<17:30:10, 13.20s/it]                                                       {'loss': 0.9171, 'learning_rate': 1.9860900924044873e-05, 'epoch': 0.08}
  8%|â–Š         | 424/5198 [1:29:51<17:30:10, 13.20s/it]  8%|â–Š         | 425/5198 [1:30:03<16:52:20, 12.73s/it]                                                       {'loss': 0.8382, 'learning_rate': 1.9859863370393726e-05, 'epoch': 0.08}
  8%|â–Š         | 425/5198 [1:30:03<16:52:20, 12.73s/it]  8%|â–Š         | 426/5198 [1:30:14<16:12:46, 12.23s/it]                                                       {'loss': 0.9469, 'learning_rate': 1.9858821988804132e-05, 'epoch': 0.08}
  8%|â–Š         | 426/5198 [1:30:14<16:12:46, 12.23s/it]  8%|â–Š         | 427/5198 [1:30:27<16:25:07, 12.39s/it]                                                       {'loss': 0.9001, 'learning_rate': 1.9857776779680393e-05, 'epoch': 0.08}
  8%|â–Š         | 427/5198 [1:30:27<16:25:07, 12.39s/it]  8%|â–Š         | 428/5198 [1:30:40<16:53:51, 12.75s/it]                                                       {'loss': 0.9333, 'learning_rate': 1.98567277434283e-05, 'epoch': 0.08}
  8%|â–Š         | 428/5198 [1:30:40<16:53:51, 12.75s/it]  8%|â–Š         | 429/5198 [1:30:54<17:11:22, 12.98s/it]                                                       {'loss': 0.9189, 'learning_rate': 1.9855674880455115e-05, 'epoch': 0.08}
  8%|â–Š         | 429/5198 [1:30:54<17:11:22, 12.98s/it]  8%|â–Š         | 430/5198 [1:31:06<16:43:32, 12.63s/it]                                                       {'loss': 0.9776, 'learning_rate': 1.98546181911696e-05, 'epoch': 0.08}
  8%|â–Š         | 430/5198 [1:31:06<16:43:32, 12.63s/it]  8%|â–Š         | 431/5198 [1:31:18<16:42:53, 12.62s/it]                                                       {'loss': 0.9548, 'learning_rate': 1.9853557675982e-05, 'epoch': 0.08}
  8%|â–Š         | 431/5198 [1:31:18<16:42:53, 12.62s/it]  8%|â–Š         | 432/5198 [1:31:30<16:28:36, 12.45s/it]                                                       {'loss': 0.8772, 'learning_rate': 1.985249333530404e-05, 'epoch': 0.08}
  8%|â–Š         | 432/5198 [1:31:30<16:28:36, 12.45s/it]  8%|â–Š         | 433/5198 [1:31:45<17:28:03, 13.20s/it]                                                       {'loss': 0.8741, 'learning_rate': 1.9851425169548938e-05, 'epoch': 0.08}
  8%|â–Š         | 433/5198 [1:31:45<17:28:03, 13.20s/it]  8%|â–Š         | 434/5198 [1:32:02<18:56:56, 14.32s/it]                                                       {'loss': 0.3152, 'learning_rate': 1.9850353179131392e-05, 'epoch': 0.08}
  8%|â–Š         | 434/5198 [1:32:02<18:56:56, 14.32s/it]  8%|â–Š         | 435/5198 [1:32:18<19:33:09, 14.78s/it]                                                       {'loss': 0.3262, 'learning_rate': 1.9849277364467585e-05, 'epoch': 0.08}
  8%|â–Š         | 435/5198 [1:32:18<19:33:09, 14.78s/it]  8%|â–Š         | 436/5198 [1:32:29<18:12:03, 13.76s/it]                                                       {'loss': 0.9004, 'learning_rate': 1.984819772597518e-05, 'epoch': 0.08}
  8%|â–Š         | 436/5198 [1:32:29<18:12:03, 13.76s/it]  8%|â–Š         | 437/5198 [1:32:42<17:34:53, 13.29s/it]                                                       {'loss': 0.9249, 'learning_rate': 1.9847114264073336e-05, 'epoch': 0.08}
  8%|â–Š         | 437/5198 [1:32:42<17:34:53, 13.29s/it]  8%|â–Š         | 438/5198 [1:32:55<17:36:09, 13.31s/it]                                                       {'loss': 0.9363, 'learning_rate': 1.984602697918269e-05, 'epoch': 0.08}
  8%|â–Š         | 438/5198 [1:32:55<17:36:09, 13.31s/it]  8%|â–Š         | 439/5198 [1:33:06<16:49:48, 12.73s/it]                                                       {'loss': 0.9139, 'learning_rate': 1.9844935871725363e-05, 'epoch': 0.08}
  8%|â–Š         | 439/5198 [1:33:06<16:49:48, 12.73s/it]  8%|â–Š         | 440/5198 [1:33:18<16:34:48, 12.54s/it]                                                       {'loss': 0.8913, 'learning_rate': 1.9843840942124956e-05, 'epoch': 0.08}
  8%|â–Š         | 440/5198 [1:33:18<16:34:48, 12.54s/it]  8%|â–Š         | 441/5198 [1:33:30<16:20:37, 12.37s/it]                                                       {'loss': 0.9765, 'learning_rate': 1.9842742190806566e-05, 'epoch': 0.08}
  8%|â–Š         | 441/5198 [1:33:30<16:20:37, 12.37s/it]  9%|â–Š         | 442/5198 [1:33:42<16:08:53, 12.22s/it]                                                       {'loss': 0.9085, 'learning_rate': 1.984163961819676e-05, 'epoch': 0.09}
  9%|â–Š         | 442/5198 [1:33:42<16:08:53, 12.22s/it]  9%|â–Š         | 443/5198 [1:33:55<16:24:54, 12.43s/it]                                                       {'loss': 0.9262, 'learning_rate': 1.9840533224723595e-05, 'epoch': 0.09}
  9%|â–Š         | 443/5198 [1:33:55<16:24:54, 12.43s/it]  9%|â–Š         | 444/5198 [1:34:07<16:19:37, 12.36s/it]                                                       {'loss': 0.9238, 'learning_rate': 1.9839423010816616e-05, 'epoch': 0.09}
  9%|â–Š         | 444/5198 [1:34:07<16:19:37, 12.36s/it]  9%|â–Š         | 445/5198 [1:34:20<16:24:21, 12.43s/it]                                                       {'loss': 0.9325, 'learning_rate': 1.983830897690684e-05, 'epoch': 0.09}
  9%|â–Š         | 445/5198 [1:34:20<16:24:21, 12.43s/it]  9%|â–Š         | 446/5198 [1:34:33<16:41:55, 12.65s/it]                                                       {'loss': 0.9304, 'learning_rate': 1.9837191123426777e-05, 'epoch': 0.09}
  9%|â–Š         | 446/5198 [1:34:33<16:41:55, 12.65s/it]  9%|â–Š         | 447/5198 [1:34:45<16:27:38, 12.47s/it]                                                       {'loss': 0.946, 'learning_rate': 1.983606945081042e-05, 'epoch': 0.09}
  9%|â–Š         | 447/5198 [1:34:45<16:27:38, 12.47s/it]  9%|â–Š         | 448/5198 [1:34:58<16:24:58, 12.44s/it]                                                       {'loss': 0.9306, 'learning_rate': 1.983494395949323e-05, 'epoch': 0.09}
  9%|â–Š         | 448/5198 [1:34:58<16:24:58, 12.44s/it]  9%|â–Š         | 449/5198 [1:35:10<16:34:33, 12.57s/it]                                                       {'loss': 0.9329, 'learning_rate': 1.983381464991217e-05, 'epoch': 0.09}
  9%|â–Š         | 449/5198 [1:35:10<16:34:33, 12.57s/it]  9%|â–Š         | 450/5198 [1:35:23<16:26:13, 12.46s/it]                                                       {'loss': 0.865, 'learning_rate': 1.9832681522505676e-05, 'epoch': 0.09}
  9%|â–Š         | 450/5198 [1:35:23<16:26:13, 12.46s/it]  9%|â–Š         | 451/5198 [1:35:34<16:00:46, 12.14s/it]                                                       {'loss': 0.9816, 'learning_rate': 1.9831544577713663e-05, 'epoch': 0.09}
  9%|â–Š         | 451/5198 [1:35:34<16:00:46, 12.14s/it]  9%|â–Š         | 452/5198 [1:35:46<16:01:53, 12.16s/it]                                                       {'loss': 0.9471, 'learning_rate': 1.983040381597754e-05, 'epoch': 0.09}
  9%|â–Š         | 452/5198 [1:35:46<16:01:53, 12.16s/it]  9%|â–Š         | 453/5198 [1:35:58<15:50:24, 12.02s/it]                                                       {'loss': 0.8631, 'learning_rate': 1.982925923774018e-05, 'epoch': 0.09}
  9%|â–Š         | 453/5198 [1:35:58<15:50:24, 12.02s/it]  9%|â–Š         | 454/5198 [1:36:10<15:44:53, 11.95s/it]                                                       {'loss': 0.8883, 'learning_rate': 1.9828110843445954e-05, 'epoch': 0.09}
  9%|â–Š         | 454/5198 [1:36:10<15:44:53, 11.95s/it]  9%|â–‰         | 455/5198 [1:36:22<15:44:30, 11.95s/it]                                                       {'loss': 0.909, 'learning_rate': 1.982695863354071e-05, 'epoch': 0.09}
  9%|â–‰         | 455/5198 [1:36:22<15:44:30, 11.95s/it]  9%|â–‰         | 456/5198 [1:36:34<15:55:08, 12.09s/it]                                                       {'loss': 0.8891, 'learning_rate': 1.9825802608471767e-05, 'epoch': 0.09}
  9%|â–‰         | 456/5198 [1:36:34<15:55:08, 12.09s/it]  9%|â–‰         | 457/5198 [1:36:46<15:53:00, 12.06s/it]                                                       {'loss': 0.9588, 'learning_rate': 1.982464276868794e-05, 'epoch': 0.09}
  9%|â–‰         | 457/5198 [1:36:46<15:53:00, 12.06s/it]  9%|â–‰         | 458/5198 [1:36:59<16:23:07, 12.44s/it]                                                       {'loss': 0.9441, 'learning_rate': 1.982347911463952e-05, 'epoch': 0.09}
  9%|â–‰         | 458/5198 [1:36:59<16:23:07, 12.44s/it]  9%|â–‰         | 459/5198 [1:37:13<16:48:42, 12.77s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.9822311646778277e-05, 'epoch': 0.09}
  9%|â–‰         | 459/5198 [1:37:13<16:48:42, 12.77s/it]  9%|â–‰         | 460/5198 [1:37:26<16:53:09, 12.83s/it]                                                       {'loss': 0.9122, 'learning_rate': 1.982114036555746e-05, 'epoch': 0.09}
  9%|â–‰         | 460/5198 [1:37:26<16:53:09, 12.83s/it]  9%|â–‰         | 461/5198 [1:37:38<16:34:18, 12.59s/it]                                                       {'loss': 0.8874, 'learning_rate': 1.9819965271431797e-05, 'epoch': 0.09}
  9%|â–‰         | 461/5198 [1:37:38<16:34:18, 12.59s/it]WARNING: tokenization mismatch: 1 vs. 70. (ignored)
  9%|â–‰         | 462/5198 [1:37:49<16:09:29, 12.28s/it]                                                       {'loss': 0.9192, 'learning_rate': 1.9818786364857506e-05, 'epoch': 0.09}
  9%|â–‰         | 462/5198 [1:37:50<16:09:29, 12.28s/it]  9%|â–‰         | 463/5198 [1:38:02<16:20:15, 12.42s/it]                                                       {'loss': 0.9343, 'learning_rate': 1.9817603646292278e-05, 'epoch': 0.09}
  9%|â–‰         | 463/5198 [1:38:02<16:20:15, 12.42s/it]  9%|â–‰         | 464/5198 [1:38:16<16:49:40, 12.80s/it]                                                       {'loss': 0.9004, 'learning_rate': 1.9816417116195287e-05, 'epoch': 0.09}
  9%|â–‰         | 464/5198 [1:38:16<16:49:40, 12.80s/it]  9%|â–‰         | 465/5198 [1:38:31<17:36:58, 13.40s/it]                                                       {'loss': 0.9272, 'learning_rate': 1.9815226775027182e-05, 'epoch': 0.09}
  9%|â–‰         | 465/5198 [1:38:31<17:36:58, 13.40s/it]  9%|â–‰         | 466/5198 [1:38:43<16:59:29, 12.93s/it]                                                       {'loss': 0.9878, 'learning_rate': 1.9814032623250093e-05, 'epoch': 0.09}
  9%|â–‰         | 466/5198 [1:38:43<16:59:29, 12.93s/it]  9%|â–‰         | 467/5198 [1:38:57<17:30:24, 13.32s/it]                                                       {'loss': 0.9002, 'learning_rate': 1.9812834661327632e-05, 'epoch': 0.09}
  9%|â–‰         | 467/5198 [1:38:57<17:30:24, 13.32s/it]  9%|â–‰         | 468/5198 [1:39:09<16:55:05, 12.88s/it]                                                       {'loss': 0.8682, 'learning_rate': 1.9811632889724888e-05, 'epoch': 0.09}
  9%|â–‰         | 468/5198 [1:39:09<16:55:05, 12.88s/it]  9%|â–‰         | 469/5198 [1:39:22<17:18:04, 13.17s/it]                                                       {'loss': 0.8455, 'learning_rate': 1.9810427308908437e-05, 'epoch': 0.09}
  9%|â–‰         | 469/5198 [1:39:23<17:18:04, 13.17s/it]  9%|â–‰         | 470/5198 [1:39:34<16:47:52, 12.79s/it]                                                       {'loss': 0.8479, 'learning_rate': 1.9809217919346318e-05, 'epoch': 0.09}
  9%|â–‰         | 470/5198 [1:39:34<16:47:52, 12.79s/it]  9%|â–‰         | 471/5198 [1:39:46<16:26:42, 12.52s/it]                                                       {'loss': 0.9833, 'learning_rate': 1.980800472150806e-05, 'epoch': 0.09}
  9%|â–‰         | 471/5198 [1:39:46<16:26:42, 12.52s/it]  9%|â–‰         | 472/5198 [1:39:58<15:59:34, 12.18s/it]                                                       {'loss': 0.9233, 'learning_rate': 1.9806787715864674e-05, 'epoch': 0.09}
  9%|â–‰         | 472/5198 [1:39:58<15:59:34, 12.18s/it]  9%|â–‰         | 473/5198 [1:40:09<15:42:34, 11.97s/it]                                                       {'loss': 0.9618, 'learning_rate': 1.9805566902888637e-05, 'epoch': 0.09}
  9%|â–‰         | 473/5198 [1:40:09<15:42:34, 11.97s/it]  9%|â–‰         | 474/5198 [1:40:21<15:48:55, 12.05s/it]                                                       {'loss': 0.9409, 'learning_rate': 1.9804342283053916e-05, 'epoch': 0.09}
  9%|â–‰         | 474/5198 [1:40:21<15:48:55, 12.05s/it]  9%|â–‰         | 475/5198 [1:40:33<15:43:09, 11.98s/it]                                                       {'loss': 0.9872, 'learning_rate': 1.980311385683594e-05, 'epoch': 0.09}
  9%|â–‰         | 475/5198 [1:40:33<15:43:09, 11.98s/it]  9%|â–‰         | 476/5198 [1:40:47<16:17:10, 12.42s/it]                                                       {'loss': 0.9394, 'learning_rate': 1.980188162471164e-05, 'epoch': 0.09}
  9%|â–‰         | 476/5198 [1:40:47<16:17:10, 12.42s/it]  9%|â–‰         | 477/5198 [1:40:58<15:54:16, 12.13s/it]                                                       {'loss': 0.9264, 'learning_rate': 1.98006455871594e-05, 'epoch': 0.09}
  9%|â–‰         | 477/5198 [1:40:58<15:54:16, 12.13s/it]  9%|â–‰         | 478/5198 [1:41:10<15:55:35, 12.15s/it]                                                       {'loss': 0.8727, 'learning_rate': 1.97994057446591e-05, 'epoch': 0.09}
  9%|â–‰         | 478/5198 [1:41:10<15:55:35, 12.15s/it]  9%|â–‰         | 479/5198 [1:41:23<16:00:57, 12.22s/it]                                                       {'loss': 0.9152, 'learning_rate': 1.979816209769209e-05, 'epoch': 0.09}
  9%|â–‰         | 479/5198 [1:41:23<16:00:57, 12.22s/it]  9%|â–‰         | 480/5198 [1:41:35<15:53:05, 12.12s/it]                                                       {'loss': 0.8649, 'learning_rate': 1.9796914646741187e-05, 'epoch': 0.09}
  9%|â–‰         | 480/5198 [1:41:35<15:53:05, 12.12s/it]  9%|â–‰         | 481/5198 [1:41:46<15:36:19, 11.91s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.9795663392290702e-05, 'epoch': 0.09}
  9%|â–‰         | 481/5198 [1:41:46<15:36:19, 11.91s/it]  9%|â–‰         | 482/5198 [1:41:58<15:41:41, 11.98s/it]                                                       {'loss': 0.8576, 'learning_rate': 1.9794408334826415e-05, 'epoch': 0.09}
  9%|â–‰         | 482/5198 [1:41:58<15:41:41, 11.98s/it]  9%|â–‰         | 483/5198 [1:42:10<15:36:51, 11.92s/it]                                                       {'loss': 0.9252, 'learning_rate': 1.979314947483558e-05, 'epoch': 0.09}
  9%|â–‰         | 483/5198 [1:42:10<15:36:51, 11.92s/it]  9%|â–‰         | 484/5198 [1:42:22<15:29:29, 11.83s/it]                                                       {'loss': 0.9709, 'learning_rate': 1.9791886812806932e-05, 'epoch': 0.09}
  9%|â–‰         | 484/5198 [1:42:22<15:29:29, 11.83s/it]  9%|â–‰         | 485/5198 [1:42:33<15:22:41, 11.75s/it]                                                       {'loss': 0.8779, 'learning_rate': 1.9790620349230676e-05, 'epoch': 0.09}
  9%|â–‰         | 485/5198 [1:42:33<15:22:41, 11.75s/it]  9%|â–‰         | 486/5198 [1:42:46<15:49:16, 12.09s/it]                                                       {'loss': 0.9237, 'learning_rate': 1.9789350084598504e-05, 'epoch': 0.09}
  9%|â–‰         | 486/5198 [1:42:46<15:49:16, 12.09s/it]  9%|â–‰         | 487/5198 [1:42:57<15:24:35, 11.78s/it]                                                       {'loss': 0.8687, 'learning_rate': 1.9788076019403565e-05, 'epoch': 0.09}
  9%|â–‰         | 487/5198 [1:42:57<15:24:35, 11.78s/it]  9%|â–‰         | 488/5198 [1:43:09<15:26:06, 11.80s/it]                                                       {'loss': 0.9582, 'learning_rate': 1.9786798154140507e-05, 'epoch': 0.09}
  9%|â–‰         | 488/5198 [1:43:09<15:26:06, 11.80s/it]  9%|â–‰         | 489/5198 [1:43:26<17:20:27, 13.26s/it]                                                       {'loss': 0.3709, 'learning_rate': 1.9785516489305437e-05, 'epoch': 0.09}
  9%|â–‰         | 489/5198 [1:43:26<17:20:27, 13.26s/it]  9%|â–‰         | 490/5198 [1:43:38<16:50:34, 12.88s/it]                                                       {'loss': 0.9286, 'learning_rate': 1.9784231025395936e-05, 'epoch': 0.09}
  9%|â–‰         | 490/5198 [1:43:38<16:50:34, 12.88s/it]  9%|â–‰         | 491/5198 [1:43:50<16:44:24, 12.80s/it]                                                       {'loss': 0.9314, 'learning_rate': 1.9782941762911075e-05, 'epoch': 0.09}
  9%|â–‰         | 491/5198 [1:43:50<16:44:24, 12.80s/it]  9%|â–‰         | 492/5198 [1:44:03<16:41:24, 12.77s/it]                                                       {'loss': 0.938, 'learning_rate': 1.9781648702351383e-05, 'epoch': 0.09}
  9%|â–‰         | 492/5198 [1:44:03<16:41:24, 12.77s/it]  9%|â–‰         | 493/5198 [1:44:17<17:21:12, 13.28s/it]                                                       {'loss': 0.9388, 'learning_rate': 1.9780351844218874e-05, 'epoch': 0.09}
  9%|â–‰         | 493/5198 [1:44:17<17:21:12, 13.28s/it] 10%|â–‰         | 494/5198 [1:44:30<16:56:26, 12.96s/it]                                                       {'loss': 0.9058, 'learning_rate': 1.977905118901703e-05, 'epoch': 0.1}
 10%|â–‰         | 494/5198 [1:44:30<16:56:26, 12.96s/it] 10%|â–‰         | 495/5198 [1:44:41<16:28:04, 12.61s/it]                                                       {'loss': 0.888, 'learning_rate': 1.977774673725081e-05, 'epoch': 0.1}
 10%|â–‰         | 495/5198 [1:44:41<16:28:04, 12.61s/it] 10%|â–‰         | 496/5198 [1:44:59<18:26:34, 14.12s/it]                                                       {'loss': 0.3337, 'learning_rate': 1.977643848942665e-05, 'epoch': 0.1}
 10%|â–‰         | 496/5198 [1:44:59<18:26:34, 14.12s/it] 10%|â–‰         | 497/5198 [1:45:11<17:47:21, 13.62s/it]                                                       {'loss': 0.8936, 'learning_rate': 1.977512644605246e-05, 'epoch': 0.1}
 10%|â–‰         | 497/5198 [1:45:12<17:47:21, 13.62s/it] 10%|â–‰         | 498/5198 [1:45:23<17:05:01, 13.09s/it]                                                       {'loss': 0.8827, 'learning_rate': 1.9773810607637612e-05, 'epoch': 0.1}
 10%|â–‰         | 498/5198 [1:45:23<17:05:01, 13.09s/it] 10%|â–‰         | 499/5198 [1:45:35<16:32:35, 12.67s/it]                                                       {'loss': 0.9245, 'learning_rate': 1.9772490974692962e-05, 'epoch': 0.1}
 10%|â–‰         | 499/5198 [1:45:35<16:32:35, 12.67s/it] 10%|â–‰         | 500/5198 [1:45:47<16:22:35, 12.55s/it]                                                       {'loss': 0.9533, 'learning_rate': 1.9771167547730844e-05, 'epoch': 0.1}
 10%|â–‰         | 500/5198 [1:45:47<16:22:35, 12.55s/it] 10%|â–‰         | 501/5198 [1:45:59<16:13:53, 12.44s/it]                                                       {'loss': 0.9578, 'learning_rate': 1.976984032726505e-05, 'epoch': 0.1}
 10%|â–‰         | 501/5198 [1:45:59<16:13:53, 12.44s/it] 10%|â–‰         | 502/5198 [1:46:11<15:59:41, 12.26s/it]                                                       {'loss': 0.9514, 'learning_rate': 1.976850931381086e-05, 'epoch': 0.1}
 10%|â–‰         | 502/5198 [1:46:11<15:59:41, 12.26s/it] 10%|â–‰         | 503/5198 [1:46:22<15:29:00, 11.87s/it]                                                       {'loss': 0.9026, 'learning_rate': 1.976717450788501e-05, 'epoch': 0.1}
 10%|â–‰         | 503/5198 [1:46:22<15:29:00, 11.87s/it] 10%|â–‰         | 504/5198 [1:46:34<15:31:17, 11.90s/it]                                                       {'loss': 0.8795, 'learning_rate': 1.9765835910005726e-05, 'epoch': 0.1}
 10%|â–‰         | 504/5198 [1:46:34<15:31:17, 11.90s/it] 10%|â–‰         | 505/5198 [1:46:47<15:55:39, 12.22s/it]                                                       {'loss': 0.876, 'learning_rate': 1.9764493520692685e-05, 'epoch': 0.1}
 10%|â–‰         | 505/5198 [1:46:47<15:55:39, 12.22s/it] 10%|â–‰         | 506/5198 [1:46:59<15:41:29, 12.04s/it]                                                       {'loss': 0.9991, 'learning_rate': 1.9763147340467067e-05, 'epoch': 0.1}
 10%|â–‰         | 506/5198 [1:46:59<15:41:29, 12.04s/it] 10%|â–‰         | 507/5198 [1:47:10<15:30:15, 11.90s/it]                                                       {'loss': 0.873, 'learning_rate': 1.9761797369851498e-05, 'epoch': 0.1}
 10%|â–‰         | 507/5198 [1:47:10<15:30:15, 11.90s/it] 10%|â–‰         | 508/5198 [1:47:23<15:59:24, 12.27s/it]                                                       {'loss': 0.8956, 'learning_rate': 1.9760443609370074e-05, 'epoch': 0.1}
 10%|â–‰         | 508/5198 [1:47:24<15:59:24, 12.27s/it] 10%|â–‰         | 509/5198 [1:47:35<15:52:59, 12.19s/it]                                                       {'loss': 0.9119, 'learning_rate': 1.975908605954838e-05, 'epoch': 0.1}
 10%|â–‰         | 509/5198 [1:47:36<15:52:59, 12.19s/it] 10%|â–‰         | 510/5198 [1:47:48<15:56:47, 12.25s/it]                                                       {'loss': 0.9454, 'learning_rate': 1.9757724720913466e-05, 'epoch': 0.1}
 10%|â–‰         | 510/5198 [1:47:48<15:56:47, 12.25s/it] 10%|â–‰         | 511/5198 [1:47:59<15:41:31, 12.05s/it]                                                       {'loss': 0.9151, 'learning_rate': 1.9756359593993845e-05, 'epoch': 0.1}
 10%|â–‰         | 511/5198 [1:48:00<15:41:31, 12.05s/it] 10%|â–‰         | 512/5198 [1:48:16<17:19:44, 13.31s/it]                                                       {'loss': 0.3012, 'learning_rate': 1.975499067931951e-05, 'epoch': 0.1}
 10%|â–‰         | 512/5198 [1:48:16<17:19:44, 13.31s/it] 10%|â–‰         | 513/5198 [1:48:27<16:28:09, 12.66s/it]                                                       {'loss': 0.959, 'learning_rate': 1.975361797742192e-05, 'epoch': 0.1}
 10%|â–‰         | 513/5198 [1:48:27<16:28:09, 12.66s/it] 10%|â–‰         | 514/5198 [1:48:40<16:45:18, 12.88s/it]                                                       {'loss': 0.9331, 'learning_rate': 1.9752241488834002e-05, 'epoch': 0.1}
 10%|â–‰         | 514/5198 [1:48:40<16:45:18, 12.88s/it] 10%|â–‰         | 515/5198 [1:48:52<16:23:53, 12.61s/it]                                                       {'loss': 0.9247, 'learning_rate': 1.975086121409016e-05, 'epoch': 0.1}
 10%|â–‰         | 515/5198 [1:48:52<16:23:53, 12.61s/it] 10%|â–‰         | 516/5198 [1:49:06<16:43:52, 12.86s/it]                                                       {'loss': 0.8741, 'learning_rate': 1.974947715372626e-05, 'epoch': 0.1}
 10%|â–‰         | 516/5198 [1:49:06<16:43:52, 12.86s/it] 10%|â–‰         | 517/5198 [1:49:19<16:55:05, 13.01s/it]                                                       {'loss': 0.8651, 'learning_rate': 1.974808930827965e-05, 'epoch': 0.1}
 10%|â–‰         | 517/5198 [1:49:19<16:55:05, 13.01s/it] 10%|â–‰         | 518/5198 [1:49:31<16:22:21, 12.59s/it]                                                       {'loss': 0.9011, 'learning_rate': 1.9746697678289128e-05, 'epoch': 0.1}
 10%|â–‰         | 518/5198 [1:49:31<16:22:21, 12.59s/it] 10%|â–‰         | 519/5198 [1:49:43<16:13:09, 12.48s/it]                                                       {'loss': 0.9128, 'learning_rate': 1.9745302264294982e-05, 'epoch': 0.1}
 10%|â–‰         | 519/5198 [1:49:43<16:13:09, 12.48s/it] 10%|â–ˆ         | 520/5198 [1:49:55<15:56:47, 12.27s/it]                                                       {'loss': 0.9175, 'learning_rate': 1.9743903066838954e-05, 'epoch': 0.1}
 10%|â–ˆ         | 520/5198 [1:49:55<15:56:47, 12.27s/it] 10%|â–ˆ         | 521/5198 [1:50:07<16:00:08, 12.32s/it]                                                       {'loss': 0.9374, 'learning_rate': 1.9742500086464266e-05, 'epoch': 0.1}
 10%|â–ˆ         | 521/5198 [1:50:07<16:00:08, 12.32s/it] 10%|â–ˆ         | 522/5198 [1:50:23<17:29:51, 13.47s/it]                                                       {'loss': 0.3244, 'learning_rate': 1.9741093323715597e-05, 'epoch': 0.1}
 10%|â–ˆ         | 522/5198 [1:50:23<17:29:51, 13.47s/it] 10%|â–ˆ         | 523/5198 [1:50:35<16:50:28, 12.97s/it]                                                       {'loss': 0.9386, 'learning_rate': 1.9739682779139107e-05, 'epoch': 0.1}
 10%|â–ˆ         | 523/5198 [1:50:35<16:50:28, 12.97s/it] 10%|â–ˆ         | 524/5198 [1:50:47<16:35:16, 12.78s/it]                                                       {'loss': 0.9106, 'learning_rate': 1.9738268453282414e-05, 'epoch': 0.1}
 10%|â–ˆ         | 524/5198 [1:50:47<16:35:16, 12.78s/it] 10%|â–ˆ         | 525/5198 [1:50:59<16:05:02, 12.39s/it]                                                       {'loss': 0.934, 'learning_rate': 1.9736850346694608e-05, 'epoch': 0.1}
 10%|â–ˆ         | 525/5198 [1:50:59<16:05:02, 12.39s/it] 10%|â–ˆ         | 526/5198 [1:51:11<15:49:03, 12.19s/it]                                                       {'loss': 0.9475, 'learning_rate': 1.973542845992625e-05, 'epoch': 0.1}
 10%|â–ˆ         | 526/5198 [1:51:11<15:49:03, 12.19s/it] 10%|â–ˆ         | 527/5198 [1:51:23<15:47:26, 12.17s/it]                                                       {'loss': 0.8821, 'learning_rate': 1.9734002793529362e-05, 'epoch': 0.1}
 10%|â–ˆ         | 527/5198 [1:51:23<15:47:26, 12.17s/it] 10%|â–ˆ         | 528/5198 [1:51:37<16:47:29, 12.94s/it]                                                       {'loss': 0.8888, 'learning_rate': 1.9732573348057437e-05, 'epoch': 0.1}
 10%|â–ˆ         | 528/5198 [1:51:37<16:47:29, 12.94s/it] 10%|â–ˆ         | 529/5198 [1:51:49<16:21:04, 12.61s/it]                                                       {'loss': 0.9651, 'learning_rate': 1.973114012406544e-05, 'epoch': 0.1}
 10%|â–ˆ         | 529/5198 [1:51:49<16:21:04, 12.61s/it] 10%|â–ˆ         | 530/5198 [1:52:02<16:17:15, 12.56s/it]                                                       {'loss': 0.9137, 'learning_rate': 1.9729703122109788e-05, 'epoch': 0.1}
 10%|â–ˆ         | 530/5198 [1:52:02<16:17:15, 12.56s/it] 10%|â–ˆ         | 531/5198 [1:52:13<15:52:25, 12.24s/it]                                                       {'loss': 0.8637, 'learning_rate': 1.9728262342748384e-05, 'epoch': 0.1}
 10%|â–ˆ         | 531/5198 [1:52:13<15:52:25, 12.24s/it] 10%|â–ˆ         | 532/5198 [1:52:25<15:32:22, 11.99s/it]                                                       {'loss': 0.9281, 'learning_rate': 1.9726817786540584e-05, 'epoch': 0.1}
 10%|â–ˆ         | 532/5198 [1:52:25<15:32:22, 11.99s/it] 10%|â–ˆ         | 533/5198 [1:52:37<15:30:14, 11.96s/it]                                                       {'loss': 0.9315, 'learning_rate': 1.9725369454047215e-05, 'epoch': 0.1}
 10%|â–ˆ         | 533/5198 [1:52:37<15:30:14, 11.96s/it] 10%|â–ˆ         | 534/5198 [1:52:49<15:32:58, 12.00s/it]                                                       {'loss': 0.9606, 'learning_rate': 1.9723917345830568e-05, 'epoch': 0.1}
 10%|â–ˆ         | 534/5198 [1:52:49<15:32:58, 12.00s/it] 10%|â–ˆ         | 535/5198 [1:53:02<16:11:04, 12.49s/it]                                                       {'loss': 0.898, 'learning_rate': 1.9722461462454405e-05, 'epoch': 0.1}
 10%|â–ˆ         | 535/5198 [1:53:02<16:11:04, 12.49s/it] 10%|â–ˆ         | 536/5198 [1:53:15<16:14:11, 12.54s/it]                                                       {'loss': 0.8966, 'learning_rate': 1.9721001804483947e-05, 'epoch': 0.1}
 10%|â–ˆ         | 536/5198 [1:53:15<16:14:11, 12.54s/it] 10%|â–ˆ         | 537/5198 [1:53:27<16:03:03, 12.40s/it]                                                       {'loss': 0.9885, 'learning_rate': 1.9719538372485887e-05, 'epoch': 0.1}
 10%|â–ˆ         | 537/5198 [1:53:27<16:03:03, 12.40s/it] 10%|â–ˆ         | 538/5198 [1:53:39<15:52:08, 12.26s/it]                                                       {'loss': 0.8772, 'learning_rate': 1.9718071167028376e-05, 'epoch': 0.1}
 10%|â–ˆ         | 538/5198 [1:53:39<15:52:08, 12.26s/it] 10%|â–ˆ         | 539/5198 [1:53:50<15:32:30, 12.01s/it]                                                       {'loss': 0.9013, 'learning_rate': 1.9716600188681038e-05, 'epoch': 0.1}
 10%|â–ˆ         | 539/5198 [1:53:50<15:32:30, 12.01s/it] 10%|â–ˆ         | 540/5198 [1:54:04<16:06:20, 12.45s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.971512543801495e-05, 'epoch': 0.1}
 10%|â–ˆ         | 540/5198 [1:54:04<16:06:20, 12.45s/it] 10%|â–ˆ         | 541/5198 [1:54:16<15:54:01, 12.29s/it]                                                       {'loss': 0.9317, 'learning_rate': 1.9713646915602663e-05, 'epoch': 0.1}
 10%|â–ˆ         | 541/5198 [1:54:16<15:54:01, 12.29s/it] 10%|â–ˆ         | 542/5198 [1:54:31<16:51:52, 13.04s/it]                                                       {'loss': 0.9137, 'learning_rate': 1.9712164622018197e-05, 'epoch': 0.1}
 10%|â–ˆ         | 542/5198 [1:54:31<16:51:52, 13.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2316 > 2048). Running this sequence through the model will result in indexing errors
 10%|â–ˆ         | 543/5198 [1:54:43<16:34:37, 12.82s/it]                                                       {'loss': 0.8729, 'learning_rate': 1.9710678557837024e-05, 'epoch': 0.1}
 10%|â–ˆ         | 543/5198 [1:54:43<16:34:37, 12.82s/it] 10%|â–ˆ         | 544/5198 [1:54:54<15:58:43, 12.36s/it]                                                       {'loss': 0.9092, 'learning_rate': 1.9709188723636088e-05, 'epoch': 0.1}
 10%|â–ˆ         | 544/5198 [1:54:54<15:58:43, 12.36s/it] 10%|â–ˆ         | 545/5198 [1:55:07<16:21:06, 12.65s/it]                                                       {'loss': 0.9111, 'learning_rate': 1.970769511999379e-05, 'epoch': 0.1}
 10%|â–ˆ         | 545/5198 [1:55:08<16:21:06, 12.65s/it] 11%|â–ˆ         | 546/5198 [1:55:19<16:02:31, 12.41s/it]                                                       {'loss': 0.8986, 'learning_rate': 1.9706197747490004e-05, 'epoch': 0.11}
 11%|â–ˆ         | 546/5198 [1:55:19<16:02:31, 12.41s/it] 11%|â–ˆ         | 547/5198 [1:55:33<16:21:15, 12.66s/it]                                                       {'loss': 0.8986, 'learning_rate': 1.9704696606706055e-05, 'epoch': 0.11}
 11%|â–ˆ         | 547/5198 [1:55:33<16:21:15, 12.66s/it] 11%|â–ˆ         | 548/5198 [1:55:47<17:06:47, 13.25s/it]                                                       {'loss': 0.9389, 'learning_rate': 1.9703191698224742e-05, 'epoch': 0.11}
 11%|â–ˆ         | 548/5198 [1:55:47<17:06:47, 13.25s/it] 11%|â–ˆ         | 549/5198 [1:55:59<16:39:25, 12.90s/it]                                                       {'loss': 0.9414, 'learning_rate': 1.9701683022630323e-05, 'epoch': 0.11}
 11%|â–ˆ         | 549/5198 [1:55:59<16:39:25, 12.90s/it] 11%|â–ˆ         | 550/5198 [1:56:11<16:02:39, 12.43s/it]                                                       {'loss': 0.9558, 'learning_rate': 1.9700170580508514e-05, 'epoch': 0.11}
 11%|â–ˆ         | 550/5198 [1:56:11<16:02:39, 12.43s/it] 11%|â–ˆ         | 551/5198 [1:56:22<15:48:31, 12.25s/it]                                                       {'loss': 0.9278, 'learning_rate': 1.9698654372446495e-05, 'epoch': 0.11}
 11%|â–ˆ         | 551/5198 [1:56:22<15:48:31, 12.25s/it] 11%|â–ˆ         | 552/5198 [1:56:37<16:49:56, 13.04s/it]                                                       {'loss': 0.9141, 'learning_rate': 1.969713439903292e-05, 'epoch': 0.11}
 11%|â–ˆ         | 552/5198 [1:56:37<16:49:56, 13.04s/it] 11%|â–ˆ         | 553/5198 [1:56:49<16:26:16, 12.74s/it]                                                       {'loss': 0.9025, 'learning_rate': 1.9695610660857886e-05, 'epoch': 0.11}
 11%|â–ˆ         | 553/5198 [1:56:49<16:26:16, 12.74s/it] 11%|â–ˆ         | 554/5198 [1:57:01<16:04:08, 12.46s/it]                                                       {'loss': 0.9513, 'learning_rate': 1.9694083158512965e-05, 'epoch': 0.11}
 11%|â–ˆ         | 554/5198 [1:57:01<16:04:08, 12.46s/it] 11%|â–ˆ         | 555/5198 [1:57:14<16:14:00, 12.59s/it]                                                       {'loss': 0.9548, 'learning_rate': 1.9692551892591185e-05, 'epoch': 0.11}
 11%|â–ˆ         | 555/5198 [1:57:14<16:14:00, 12.59s/it] 11%|â–ˆ         | 556/5198 [1:57:26<16:06:44, 12.50s/it]                                                       {'loss': 0.9466, 'learning_rate': 1.9691016863687037e-05, 'epoch': 0.11}
 11%|â–ˆ         | 556/5198 [1:57:26<16:06:44, 12.50s/it] 11%|â–ˆ         | 557/5198 [1:57:39<16:01:27, 12.43s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.968947807239647e-05, 'epoch': 0.11}
 11%|â–ˆ         | 557/5198 [1:57:39<16:01:27, 12.43s/it] 11%|â–ˆ         | 558/5198 [1:57:50<15:43:54, 12.21s/it]                                                       {'loss': 0.8873, 'learning_rate': 1.9687935519316897e-05, 'epoch': 0.11}
 11%|â–ˆ         | 558/5198 [1:57:50<15:43:54, 12.21s/it] 11%|â–ˆ         | 559/5198 [1:58:03<16:01:49, 12.44s/it]                                                       {'loss': 0.8965, 'learning_rate': 1.9686389205047186e-05, 'epoch': 0.11}
 11%|â–ˆ         | 559/5198 [1:58:03<16:01:49, 12.44s/it] 11%|â–ˆ         | 560/5198 [1:58:15<15:48:07, 12.27s/it]                                                       {'loss': 0.9403, 'learning_rate': 1.9684839130187678e-05, 'epoch': 0.11}
 11%|â–ˆ         | 560/5198 [1:58:15<15:48:07, 12.27s/it] 11%|â–ˆ         | 561/5198 [1:58:27<15:41:16, 12.18s/it]                                                       {'loss': 0.888, 'learning_rate': 1.968328529534016e-05, 'epoch': 0.11}
 11%|â–ˆ         | 561/5198 [1:58:27<15:41:16, 12.18s/it] 11%|â–ˆ         | 562/5198 [1:58:39<15:30:56, 12.05s/it]                                                       {'loss': 0.9014, 'learning_rate': 1.9681727701107885e-05, 'epoch': 0.11}
 11%|â–ˆ         | 562/5198 [1:58:39<15:30:56, 12.05s/it] 11%|â–ˆ         | 563/5198 [1:58:52<15:48:51, 12.28s/it]                                                       {'loss': 0.88, 'learning_rate': 1.9680166348095568e-05, 'epoch': 0.11}
 11%|â–ˆ         | 563/5198 [1:58:52<15:48:51, 12.28s/it] 11%|â–ˆ         | 564/5198 [1:59:04<15:59:32, 12.42s/it]                                                       {'loss': 0.8665, 'learning_rate': 1.967860123690937e-05, 'epoch': 0.11}
 11%|â–ˆ         | 564/5198 [1:59:04<15:59:32, 12.42s/it] 11%|â–ˆ         | 565/5198 [1:59:17<16:06:56, 12.52s/it]                                                       {'loss': 0.8895, 'learning_rate': 1.9677032368156934e-05, 'epoch': 0.11}
 11%|â–ˆ         | 565/5198 [1:59:17<16:06:56, 12.52s/it] 11%|â–ˆ         | 566/5198 [1:59:30<16:19:06, 12.68s/it]                                                       {'loss': 0.8927, 'learning_rate': 1.967545974244734e-05, 'epoch': 0.11}
 11%|â–ˆ         | 566/5198 [1:59:30<16:19:06, 12.68s/it] 11%|â–ˆ         | 567/5198 [1:59:42<15:55:23, 12.38s/it]                                                       {'loss': 0.9491, 'learning_rate': 1.9673883360391138e-05, 'epoch': 0.11}
 11%|â–ˆ         | 567/5198 [1:59:42<15:55:23, 12.38s/it] 11%|â–ˆ         | 568/5198 [1:59:56<16:32:03, 12.86s/it]                                                       {'loss': 0.929, 'learning_rate': 1.9672303222600333e-05, 'epoch': 0.11}
 11%|â–ˆ         | 568/5198 [1:59:56<16:32:03, 12.86s/it] 11%|â–ˆ         | 569/5198 [2:00:07<16:02:59, 12.48s/it]                                                       {'loss': 0.9468, 'learning_rate': 1.967071932968839e-05, 'epoch': 0.11}
 11%|â–ˆ         | 569/5198 [2:00:07<16:02:59, 12.48s/it] 11%|â–ˆ         | 570/5198 [2:00:22<17:01:17, 13.24s/it]                                                       {'loss': 0.8459, 'learning_rate': 1.9669131682270232e-05, 'epoch': 0.11}
 11%|â–ˆ         | 570/5198 [2:00:23<17:01:17, 13.24s/it] 11%|â–ˆ         | 571/5198 [2:00:35<16:37:55, 12.94s/it]                                                       {'loss': 0.8471, 'learning_rate': 1.9667540280962235e-05, 'epoch': 0.11}
 11%|â–ˆ         | 571/5198 [2:00:35<16:37:55, 12.94s/it] 11%|â–ˆ         | 572/5198 [2:00:47<16:13:23, 12.63s/it]                                                       {'loss': 0.9266, 'learning_rate': 1.966594512638224e-05, 'epoch': 0.11}
 11%|â–ˆ         | 572/5198 [2:00:47<16:13:23, 12.63s/it] 11%|â–ˆ         | 573/5198 [2:00:58<15:47:33, 12.29s/it]                                                       {'loss': 0.9179, 'learning_rate': 1.9664346219149538e-05, 'epoch': 0.11}
 11%|â–ˆ         | 573/5198 [2:00:58<15:47:33, 12.29s/it] 11%|â–ˆ         | 574/5198 [2:01:10<15:34:32, 12.13s/it]                                                       {'loss': 0.8575, 'learning_rate': 1.966274355988488e-05, 'epoch': 0.11}
 11%|â–ˆ         | 574/5198 [2:01:10<15:34:32, 12.13s/it] 11%|â–ˆ         | 575/5198 [2:01:23<16:04:26, 12.52s/it]                                                       {'loss': 0.9172, 'learning_rate': 1.9661137149210473e-05, 'epoch': 0.11}
 11%|â–ˆ         | 575/5198 [2:01:23<16:04:26, 12.52s/it] 11%|â–ˆ         | 576/5198 [2:01:39<17:20:09, 13.50s/it]                                                       {'loss': 0.3111, 'learning_rate': 1.9659526987749987e-05, 'epoch': 0.11}
 11%|â–ˆ         | 576/5198 [2:01:39<17:20:09, 13.50s/it][2024-03-23 17:52:24,535] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
 11%|â–ˆ         | 577/5198 [2:01:56<18:44:24, 14.60s/it]                                                       {'loss': 0.3643, 'learning_rate': 1.9657913076128532e-05, 'epoch': 0.11}
 11%|â–ˆ         | 577/5198 [2:01:56<18:44:24, 14.60s/it] 11%|â–ˆ         | 578/5198 [2:02:08<17:49:34, 13.89s/it]                                                       {'loss': 0.8924, 'learning_rate': 1.965629541497269e-05, 'epoch': 0.11}
 11%|â–ˆ         | 578/5198 [2:02:09<17:49:34, 13.89s/it] 11%|â–ˆ         | 579/5198 [2:02:23<18:08:35, 14.14s/it]                                                       {'loss': 0.9014, 'learning_rate': 1.9654674004910493e-05, 'epoch': 0.11}
 11%|â–ˆ         | 579/5198 [2:02:23<18:08:35, 14.14s/it] 11%|â–ˆ         | 580/5198 [2:02:35<17:10:53, 13.39s/it]                                                       {'loss': 0.9381, 'learning_rate': 1.9653048846571427e-05, 'epoch': 0.11}
 11%|â–ˆ         | 580/5198 [2:02:35<17:10:53, 13.39s/it] 11%|â–ˆ         | 581/5198 [2:02:47<16:45:04, 13.06s/it]                                                       {'loss': 0.8923, 'learning_rate': 1.9651419940586437e-05, 'epoch': 0.11}
 11%|â–ˆ         | 581/5198 [2:02:47<16:45:04, 13.06s/it] 11%|â–ˆ         | 582/5198 [2:02:59<16:27:44, 12.84s/it]                                                       {'loss': 0.937, 'learning_rate': 1.964978728758791e-05, 'epoch': 0.11}
 11%|â–ˆ         | 582/5198 [2:03:00<16:27:44, 12.84s/it] 11%|â–ˆ         | 583/5198 [2:03:11<16:08:49, 12.60s/it]                                                       {'loss': 0.9493, 'learning_rate': 1.9648150888209715e-05, 'epoch': 0.11}
 11%|â–ˆ         | 583/5198 [2:03:12<16:08:49, 12.60s/it] 11%|â–ˆ         | 584/5198 [2:03:23<15:54:37, 12.41s/it]                                                       {'loss': 0.9451, 'learning_rate': 1.9646510743087144e-05, 'epoch': 0.11}
 11%|â–ˆ         | 584/5198 [2:03:24<15:54:37, 12.41s/it] 11%|â–ˆâ–        | 585/5198 [2:03:36<15:52:19, 12.39s/it]                                                       {'loss': 0.8897, 'learning_rate': 1.964486685285697e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 585/5198 [2:03:36<15:52:19, 12.39s/it] 11%|â–ˆâ–        | 586/5198 [2:03:48<15:37:00, 12.19s/it]                                                       {'loss': 0.9046, 'learning_rate': 1.9643219218157395e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 586/5198 [2:03:48<15:37:00, 12.19s/it] 11%|â–ˆâ–        | 587/5198 [2:04:01<16:01:59, 12.52s/it]                                                       {'loss': 0.9086, 'learning_rate': 1.9641567839628092e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 587/5198 [2:04:01<16:01:59, 12.52s/it] 11%|â–ˆâ–        | 588/5198 [2:04:12<15:38:11, 12.21s/it]                                                       {'loss': 0.9108, 'learning_rate': 1.963991271791019e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 588/5198 [2:04:12<15:38:11, 12.21s/it] 11%|â–ˆâ–        | 589/5198 [2:04:24<15:36:49, 12.20s/it]                                                       {'loss': 0.871, 'learning_rate': 1.9638253853646255e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 589/5198 [2:04:25<15:36:49, 12.20s/it] 11%|â–ˆâ–        | 590/5198 [2:04:36<15:25:54, 12.06s/it]                                                       {'loss': 0.9272, 'learning_rate': 1.9636591247480323e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 590/5198 [2:04:36<15:25:54, 12.06s/it] 11%|â–ˆâ–        | 591/5198 [2:04:53<17:06:00, 13.36s/it]                                                       {'loss': 0.3741, 'learning_rate': 1.9634924900057867e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 591/5198 [2:04:53<17:06:00, 13.36s/it] 11%|â–ˆâ–        | 592/5198 [2:05:07<17:23:29, 13.59s/it]                                                       {'loss': 0.9101, 'learning_rate': 1.963325481202583e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 592/5198 [2:05:07<17:23:29, 13.59s/it] 11%|â–ˆâ–        | 593/5198 [2:05:18<16:35:54, 12.98s/it]                                                       {'loss': 0.8969, 'learning_rate': 1.963158098403259e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 593/5198 [2:05:18<16:35:54, 12.98s/it] 11%|â–ˆâ–        | 594/5198 [2:05:30<16:07:52, 12.61s/it]                                                       {'loss': 0.868, 'learning_rate': 1.9629903416727987e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 594/5198 [2:05:30<16:07:52, 12.61s/it] 11%|â–ˆâ–        | 595/5198 [2:05:45<17:04:23, 13.35s/it]                                                       {'loss': 0.8716, 'learning_rate': 1.962822211076331e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 595/5198 [2:05:45<17:04:23, 13.35s/it] 11%|â–ˆâ–        | 596/5198 [2:05:57<16:35:20, 12.98s/it]                                                       {'loss': 0.9168, 'learning_rate': 1.96265370667913e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 596/5198 [2:05:57<16:35:20, 12.98s/it] 11%|â–ˆâ–        | 597/5198 [2:06:09<15:57:51, 12.49s/it]                                                       {'loss': 0.8733, 'learning_rate': 1.9624848285466146e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 597/5198 [2:06:09<15:57:51, 12.49s/it] 12%|â–ˆâ–        | 598/5198 [2:06:20<15:30:47, 12.14s/it]                                                       {'loss': 0.8877, 'learning_rate': 1.9623155767443498e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 598/5198 [2:06:20<15:30:47, 12.14s/it] 12%|â–ˆâ–        | 599/5198 [2:06:32<15:30:42, 12.14s/it]                                                       {'loss': 0.8893, 'learning_rate': 1.9621459513380445e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 599/5198 [2:06:32<15:30:42, 12.14s/it] 12%|â–ˆâ–        | 600/5198 [2:06:44<15:27:30, 12.10s/it]                                                       {'loss': 0.9537, 'learning_rate': 1.9619759523935532e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 600/5198 [2:06:44<15:27:30, 12.10s/it] 12%|â–ˆâ–        | 601/5198 [2:06:56<15:16:59, 11.97s/it]                                                       {'loss': 0.8436, 'learning_rate': 1.9618055799768757e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 601/5198 [2:06:56<15:16:59, 11.97s/it] 12%|â–ˆâ–        | 602/5198 [2:07:07<15:10:42, 11.89s/it]                                                       {'loss': 0.8928, 'learning_rate': 1.961634834154156e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 602/5198 [2:07:07<15:10:42, 11.89s/it] 12%|â–ˆâ–        | 603/5198 [2:07:20<15:16:05, 11.96s/it]                                                       {'loss': 0.9072, 'learning_rate': 1.9614637149916834e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 603/5198 [2:07:20<15:16:05, 11.96s/it] 12%|â–ˆâ–        | 604/5198 [2:07:32<15:22:10, 12.04s/it]                                                       {'loss': 0.9155, 'learning_rate': 1.9612922225558924e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 604/5198 [2:07:32<15:22:10, 12.04s/it] 12%|â–ˆâ–        | 605/5198 [2:07:45<15:52:21, 12.44s/it]                                                       {'loss': 0.8983, 'learning_rate': 1.961120356913363e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 605/5198 [2:07:45<15:52:21, 12.44s/it] 12%|â–ˆâ–        | 606/5198 [2:07:57<15:49:43, 12.41s/it]                                                       {'loss': 0.9427, 'learning_rate': 1.960948118130818e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 606/5198 [2:07:58<15:49:43, 12.41s/it] 12%|â–ˆâ–        | 607/5198 [2:08:09<15:38:36, 12.27s/it]                                                       {'loss': 0.9045, 'learning_rate': 1.9607755062751273e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 607/5198 [2:08:09<15:38:36, 12.27s/it] 12%|â–ˆâ–        | 608/5198 [2:08:25<17:05:48, 13.41s/it]                                                       {'loss': 0.3301, 'learning_rate': 1.9606025214133046e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 608/5198 [2:08:26<17:05:48, 13.41s/it] 12%|â–ˆâ–        | 609/5198 [2:08:41<17:58:34, 14.10s/it]                                                       {'loss': 0.3203, 'learning_rate': 1.9604291636125084e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 609/5198 [2:08:41<17:58:34, 14.10s/it] 12%|â–ˆâ–        | 610/5198 [2:08:54<17:25:22, 13.67s/it]                                                       {'loss': 0.8597, 'learning_rate': 1.960255432940043e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 610/5198 [2:08:54<17:25:22, 13.67s/it] 12%|â–ˆâ–        | 611/5198 [2:09:09<17:57:56, 14.10s/it]                                                       {'loss': 0.8801, 'learning_rate': 1.9600813294633552e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 611/5198 [2:09:09<17:57:56, 14.10s/it] 12%|â–ˆâ–        | 612/5198 [2:09:22<17:26:41, 13.69s/it]                                                       {'loss': 0.8753, 'learning_rate': 1.9599068532500394e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 612/5198 [2:09:22<17:26:41, 13.69s/it] 12%|â–ˆâ–        | 613/5198 [2:09:33<16:38:47, 13.07s/it]                                                       {'loss': 0.9249, 'learning_rate': 1.9597320043678322e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 613/5198 [2:09:33<16:38:47, 13.07s/it] 12%|â–ˆâ–        | 614/5198 [2:09:45<16:15:16, 12.77s/it]                                                       {'loss': 0.881, 'learning_rate': 1.9595567828846166e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 614/5198 [2:09:46<16:15:16, 12.77s/it] 12%|â–ˆâ–        | 615/5198 [2:09:59<16:36:50, 13.05s/it]                                                       {'loss': 0.9152, 'learning_rate': 1.9593811888684192e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 615/5198 [2:09:59<16:36:50, 13.05s/it] 12%|â–ˆâ–        | 616/5198 [2:10:12<16:32:32, 13.00s/it]                                                       {'loss': 0.8757, 'learning_rate': 1.9592052223874115e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 616/5198 [2:10:12<16:32:32, 13.00s/it] 12%|â–ˆâ–        | 617/5198 [2:10:24<16:11:39, 12.73s/it]                                                       {'loss': 0.8935, 'learning_rate': 1.959028883509911e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 617/5198 [2:10:24<16:11:39, 12.73s/it] 12%|â–ˆâ–        | 618/5198 [2:10:36<15:47:19, 12.41s/it]                                                       {'loss': 0.8872, 'learning_rate': 1.9588521723043764e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 618/5198 [2:10:36<15:47:19, 12.41s/it] 12%|â–ˆâ–        | 619/5198 [2:10:48<15:38:10, 12.29s/it]                                                       {'loss': 0.9109, 'learning_rate': 1.958675088839415e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 619/5198 [2:10:48<15:38:10, 12.29s/it] 12%|â–ˆâ–        | 620/5198 [2:11:00<15:29:43, 12.19s/it]                                                       {'loss': 0.8932, 'learning_rate': 1.9584976331837758e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 620/5198 [2:11:00<15:29:43, 12.19s/it] 12%|â–ˆâ–        | 621/5198 [2:11:12<15:28:18, 12.17s/it]                                                       {'loss': 0.9229, 'learning_rate': 1.9583198054063535e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 621/5198 [2:11:12<15:28:18, 12.17s/it] 12%|â–ˆâ–        | 622/5198 [2:11:24<15:19:25, 12.06s/it]                                                       {'loss': 0.9014, 'learning_rate': 1.9581416055761865e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 622/5198 [2:11:24<15:19:25, 12.06s/it] 12%|â–ˆâ–        | 623/5198 [2:11:36<15:24:48, 12.13s/it]                                                       {'loss': 0.9666, 'learning_rate': 1.9579630337624585e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 623/5198 [2:11:36<15:24:48, 12.13s/it] 12%|â–ˆâ–        | 624/5198 [2:11:48<15:27:18, 12.16s/it]                                                       {'loss': 0.9377, 'learning_rate': 1.9577840900344974e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 624/5198 [2:11:48<15:27:18, 12.16s/it] 12%|â–ˆâ–        | 625/5198 [2:12:01<15:35:40, 12.28s/it]                                                       {'loss': 0.8937, 'learning_rate': 1.9576047744617752e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 625/5198 [2:12:01<15:35:40, 12.28s/it] 12%|â–ˆâ–        | 626/5198 [2:12:14<15:51:46, 12.49s/it]                                                       {'loss': 0.8497, 'learning_rate': 1.957425087113908e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 626/5198 [2:12:14<15:51:46, 12.49s/it] 12%|â–ˆâ–        | 627/5198 [2:12:26<15:41:43, 12.36s/it]                                                       {'loss': 0.9461, 'learning_rate': 1.9572450280606568e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 627/5198 [2:12:26<15:41:43, 12.36s/it] 12%|â–ˆâ–        | 628/5198 [2:12:38<15:44:46, 12.40s/it]                                                       {'loss': 0.8895, 'learning_rate': 1.9570645973719273e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 628/5198 [2:12:38<15:44:46, 12.40s/it] 12%|â–ˆâ–        | 629/5198 [2:12:50<15:26:08, 12.16s/it]                                                       {'loss': 0.8794, 'learning_rate': 1.9568837951177677e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 629/5198 [2:12:50<15:26:08, 12.16s/it] 12%|â–ˆâ–        | 630/5198 [2:13:04<16:09:42, 12.74s/it]                                                       {'loss': 0.916, 'learning_rate': 1.9567026213683728e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 630/5198 [2:13:04<16:09:42, 12.74s/it] 12%|â–ˆâ–        | 631/5198 [2:13:16<15:53:28, 12.53s/it]                                                       {'loss': 0.9291, 'learning_rate': 1.9565210761940798e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 631/5198 [2:13:16<15:53:28, 12.53s/it] 12%|â–ˆâ–        | 632/5198 [2:13:28<15:45:09, 12.42s/it]                                                       {'loss': 0.9384, 'learning_rate': 1.956339159665371e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 632/5198 [2:13:28<15:45:09, 12.42s/it] 12%|â–ˆâ–        | 633/5198 [2:13:40<15:35:18, 12.29s/it]                                                       {'loss': 0.9175, 'learning_rate': 1.956156871852873e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 633/5198 [2:13:40<15:35:18, 12.29s/it] 12%|â–ˆâ–        | 634/5198 [2:13:52<15:30:24, 12.23s/it]                                                       {'loss': 0.9123, 'learning_rate': 1.9559742128273558e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 634/5198 [2:13:52<15:30:24, 12.23s/it] 12%|â–ˆâ–        | 635/5198 [2:14:04<15:22:04, 12.12s/it]                                                       {'loss': 0.8812, 'learning_rate': 1.9557911826597337e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 635/5198 [2:14:04<15:22:04, 12.12s/it] 12%|â–ˆâ–        | 636/5198 [2:14:17<15:33:27, 12.28s/it]                                                       {'loss': 0.8977, 'learning_rate': 1.9556077814210662e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 636/5198 [2:14:17<15:33:27, 12.28s/it] 12%|â–ˆâ–        | 637/5198 [2:14:29<15:24:30, 12.16s/it]                                                       {'loss': 0.8796, 'learning_rate': 1.955424009182555e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 637/5198 [2:14:29<15:24:30, 12.16s/it] 12%|â–ˆâ–        | 638/5198 [2:14:42<15:50:04, 12.50s/it]                                                       {'loss': 0.8326, 'learning_rate': 1.955239866015547e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 638/5198 [2:14:42<15:50:04, 12.50s/it] 12%|â–ˆâ–        | 639/5198 [2:14:56<16:34:46, 13.09s/it]                                                       {'loss': 0.8901, 'learning_rate': 1.9550553519915335e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 639/5198 [2:14:56<16:34:46, 13.09s/it] 12%|â–ˆâ–        | 640/5198 [2:15:08<16:05:54, 12.71s/it]                                                       {'loss': 0.9183, 'learning_rate': 1.954870467182149e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 640/5198 [2:15:08<16:05:54, 12.71s/it] 12%|â–ˆâ–        | 641/5198 [2:15:20<15:47:56, 12.48s/it]                                                       {'loss': 0.8803, 'learning_rate': 1.954685211659172e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 641/5198 [2:15:20<15:47:56, 12.48s/it] 12%|â–ˆâ–        | 642/5198 [2:15:33<15:54:09, 12.57s/it]                                                       {'loss': 0.9242, 'learning_rate': 1.9544995854945248e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 642/5198 [2:15:33<15:54:09, 12.57s/it] 12%|â–ˆâ–        | 643/5198 [2:15:45<15:37:55, 12.35s/it]                                                       {'loss': 0.9025, 'learning_rate': 1.954313588760274e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 643/5198 [2:15:45<15:37:55, 12.35s/it] 12%|â–ˆâ–        | 644/5198 [2:15:58<15:52:13, 12.55s/it]                                                       {'loss': 0.8395, 'learning_rate': 1.9541272215286304e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 644/5198 [2:15:58<15:52:13, 12.55s/it] 12%|â–ˆâ–        | 645/5198 [2:16:10<15:33:20, 12.30s/it]                                                       {'loss': 0.8766, 'learning_rate': 1.9539404838719477e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 645/5198 [2:16:10<15:33:20, 12.30s/it] 12%|â–ˆâ–        | 646/5198 [2:16:21<15:11:35, 12.02s/it]                                                       {'loss': 0.8551, 'learning_rate': 1.9537533758627242e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 646/5198 [2:16:21<15:11:35, 12.02s/it] 12%|â–ˆâ–        | 647/5198 [2:16:32<15:02:12, 11.89s/it]                                                       {'loss': 0.9241, 'learning_rate': 1.953565897573601e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 647/5198 [2:16:33<15:02:12, 11.89s/it] 12%|â–ˆâ–        | 648/5198 [2:16:44<15:03:06, 11.91s/it]                                                       {'loss': 0.8554, 'learning_rate': 1.9533780490773645e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 648/5198 [2:16:44<15:03:06, 11.91s/it] 12%|â–ˆâ–        | 649/5198 [2:16:59<16:05:52, 12.74s/it]                                                       {'loss': 0.8389, 'learning_rate': 1.9531898304469435e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 649/5198 [2:16:59<16:05:52, 12.74s/it] 13%|â–ˆâ–Ž        | 650/5198 [2:17:11<15:49:08, 12.52s/it]                                                       {'loss': 0.8952, 'learning_rate': 1.953001241755411e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 650/5198 [2:17:11<15:49:08, 12.52s/it] 13%|â–ˆâ–Ž        | 651/5198 [2:17:24<15:47:41, 12.51s/it]                                                       {'loss': 0.9283, 'learning_rate': 1.952812283075984e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 651/5198 [2:17:24<15:47:41, 12.51s/it] 13%|â–ˆâ–Ž        | 652/5198 [2:17:35<15:28:15, 12.25s/it]                                                       {'loss': 0.8958, 'learning_rate': 1.952622954482022e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 652/5198 [2:17:35<15:28:15, 12.25s/it] 13%|â–ˆâ–Ž        | 653/5198 [2:17:48<15:42:47, 12.45s/it]                                                       {'loss': 0.9621, 'learning_rate': 1.9524332560470293e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 653/5198 [2:17:48<15:42:47, 12.45s/it] 13%|â–ˆâ–Ž        | 654/5198 [2:18:00<15:23:27, 12.19s/it]                                                       {'loss': 0.9007, 'learning_rate': 1.9522431878446536e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 654/5198 [2:18:00<15:23:27, 12.19s/it] 13%|â–ˆâ–Ž        | 655/5198 [2:18:12<15:23:34, 12.20s/it]                                                       {'loss': 0.9684, 'learning_rate': 1.9520527499486856e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 655/5198 [2:18:12<15:23:34, 12.20s/it] 13%|â–ˆâ–Ž        | 656/5198 [2:18:28<16:53:37, 13.39s/it]                                                       {'loss': 0.3817, 'learning_rate': 1.95186194243306e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 656/5198 [2:18:28<16:53:37, 13.39s/it] 13%|â–ˆâ–Ž        | 657/5198 [2:18:40<16:16:29, 12.90s/it]                                                       {'loss': 0.884, 'learning_rate': 1.9516707653718546e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 657/5198 [2:18:40<16:16:29, 12.90s/it] 13%|â–ˆâ–Ž        | 658/5198 [2:18:52<15:56:41, 12.64s/it]                                                       {'loss': 0.84, 'learning_rate': 1.9514792188392914e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 658/5198 [2:18:52<15:56:41, 12.64s/it] 13%|â–ˆâ–Ž        | 659/5198 [2:19:04<15:41:48, 12.45s/it]                                                       {'loss': 0.8887, 'learning_rate': 1.9512873029097347e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 659/5198 [2:19:04<15:41:48, 12.45s/it] 13%|â–ˆâ–Ž        | 660/5198 [2:19:15<15:20:31, 12.17s/it]                                                       {'loss': 0.8768, 'learning_rate': 1.9510950176576933e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 660/5198 [2:19:15<15:20:31, 12.17s/it] 13%|â–ˆâ–Ž        | 661/5198 [2:19:27<15:06:42, 11.99s/it]                                                       {'loss': 0.8954, 'learning_rate': 1.950902363157819e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 661/5198 [2:19:27<15:06:42, 11.99s/it] 13%|â–ˆâ–Ž        | 662/5198 [2:19:39<15:16:13, 12.12s/it]                                                       {'loss': 0.8682, 'learning_rate': 1.950709339484907e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 662/5198 [2:19:40<15:16:13, 12.12s/it] 13%|â–ˆâ–Ž        | 663/5198 [2:19:51<15:13:28, 12.09s/it]                                                       {'loss': 0.9322, 'learning_rate': 1.9505159467138954e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 663/5198 [2:19:52<15:13:28, 12.09s/it] 13%|â–ˆâ–Ž        | 664/5198 [2:20:03<15:04:14, 11.97s/it]                                                       {'loss': 0.8625, 'learning_rate': 1.9503221849198655e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 664/5198 [2:20:03<15:04:14, 11.97s/it] 13%|â–ˆâ–Ž        | 665/5198 [2:20:15<14:58:18, 11.89s/it]                                                       {'loss': 0.8998, 'learning_rate': 1.9501280541780435e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 665/5198 [2:20:15<14:58:18, 11.89s/it] 13%|â–ˆâ–Ž        | 666/5198 [2:20:27<15:01:50, 11.94s/it]                                                       {'loss': 0.9078, 'learning_rate': 1.9499335545637968e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 666/5198 [2:20:27<15:01:50, 11.94s/it] 13%|â–ˆâ–Ž        | 667/5198 [2:20:40<15:17:54, 12.16s/it]                                                       {'loss': 0.9388, 'learning_rate': 1.949738686152637e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 667/5198 [2:20:40<15:17:54, 12.16s/it] 13%|â–ˆâ–Ž        | 668/5198 [2:20:53<15:54:32, 12.64s/it]                                                       {'loss': 0.8729, 'learning_rate': 1.9495434490202188e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 668/5198 [2:20:53<15:54:32, 12.64s/it] 13%|â–ˆâ–Ž        | 669/5198 [2:21:05<15:33:59, 12.37s/it]                                                       {'loss': 0.928, 'learning_rate': 1.94934784324234e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 669/5198 [2:21:05<15:33:59, 12.37s/it] 13%|â–ˆâ–Ž        | 670/5198 [2:21:19<16:09:35, 12.85s/it]                                                       {'loss': 0.8482, 'learning_rate': 1.9491518688949417e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 670/5198 [2:21:19<16:09:35, 12.85s/it] 13%|â–ˆâ–Ž        | 671/5198 [2:21:31<15:38:42, 12.44s/it]                                                       {'loss': 0.8633, 'learning_rate': 1.9489555260541074e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 671/5198 [2:21:31<15:38:42, 12.44s/it] 13%|â–ˆâ–Ž        | 672/5198 [2:21:43<15:40:32, 12.47s/it]                                                       {'loss': 0.9144, 'learning_rate': 1.948758814796064e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 672/5198 [2:21:43<15:40:32, 12.47s/it] 13%|â–ˆâ–Ž        | 673/5198 [2:21:59<17:06:58, 13.62s/it]                                                       {'loss': 0.3691, 'learning_rate': 1.9485617351971827e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 673/5198 [2:21:59<17:06:58, 13.62s/it] 13%|â–ˆâ–Ž        | 674/5198 [2:22:11<16:21:48, 13.02s/it]                                                       {'loss': 0.8289, 'learning_rate': 1.9483642873339753e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 674/5198 [2:22:11<16:21:48, 13.02s/it] 13%|â–ˆâ–Ž        | 675/5198 [2:22:24<16:12:37, 12.90s/it]                                                       {'loss': 0.8841, 'learning_rate': 1.9481664712830987e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 675/5198 [2:22:24<16:12:37, 12.90s/it] 13%|â–ˆâ–Ž        | 676/5198 [2:22:42<18:09:45, 14.46s/it]                                                       {'loss': 0.3715, 'learning_rate': 1.9479682871213515e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 676/5198 [2:22:42<18:09:45, 14.46s/it] 13%|â–ˆâ–Ž        | 677/5198 [2:22:53<17:02:01, 13.56s/it]                                                       {'loss': 0.9144, 'learning_rate': 1.9477697349256756e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 677/5198 [2:22:53<17:02:01, 13.56s/it] 13%|â–ˆâ–Ž        | 678/5198 [2:23:07<17:03:28, 13.59s/it]                                                       {'loss': 0.8702, 'learning_rate': 1.947570814773156e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 678/5198 [2:23:07<17:03:28, 13.59s/it] 13%|â–ˆâ–Ž        | 679/5198 [2:23:23<18:02:30, 14.37s/it]                                                       {'loss': 0.3445, 'learning_rate': 1.9473715267410206e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 679/5198 [2:23:23<18:02:30, 14.37s/it] 13%|â–ˆâ–Ž        | 680/5198 [2:23:35<17:00:40, 13.55s/it]                                                       {'loss': 0.9405, 'learning_rate': 1.9471718709066392e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 680/5198 [2:23:35<17:00:40, 13.55s/it] 13%|â–ˆâ–Ž        | 681/5198 [2:23:46<16:16:37, 12.97s/it]                                                       {'loss': 0.9412, 'learning_rate': 1.9469718473475256e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 681/5198 [2:23:46<16:16:37, 12.97s/it] 13%|â–ˆâ–Ž        | 682/5198 [2:23:57<15:31:20, 12.37s/it]                                                       {'loss': 0.9406, 'learning_rate': 1.9467714561413358e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 682/5198 [2:23:57<15:31:20, 12.37s/it] 13%|â–ˆâ–Ž        | 683/5198 [2:24:09<15:26:36, 12.31s/it]                                                       {'loss': 0.9354, 'learning_rate': 1.9465706973658683e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 683/5198 [2:24:09<15:26:36, 12.31s/it] 13%|â–ˆâ–Ž        | 684/5198 [2:24:22<15:26:57, 12.32s/it]                                                       {'loss': 0.9009, 'learning_rate': 1.9463695710990648e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 684/5198 [2:24:22<15:26:57, 12.32s/it] 13%|â–ˆâ–Ž        | 685/5198 [2:24:33<15:08:13, 12.07s/it]                                                       {'loss': 0.8951, 'learning_rate': 1.946168077419009e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 685/5198 [2:24:33<15:08:13, 12.07s/it] 13%|â–ˆâ–Ž        | 686/5198 [2:24:46<15:23:55, 12.29s/it]                                                       {'loss': 0.9079, 'learning_rate': 1.9459662164039283e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 686/5198 [2:24:46<15:23:55, 12.29s/it] 13%|â–ˆâ–Ž        | 687/5198 [2:24:58<15:26:39, 12.33s/it]                                                       {'loss': 0.9168, 'learning_rate': 1.9457639881321917e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 687/5198 [2:24:59<15:26:39, 12.33s/it] 13%|â–ˆâ–Ž        | 688/5198 [2:25:10<15:06:56, 12.07s/it]                                                       {'loss': 0.9278, 'learning_rate': 1.9455613926823115e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 688/5198 [2:25:10<15:06:56, 12.07s/it] 13%|â–ˆâ–Ž        | 689/5198 [2:25:22<15:09:18, 12.10s/it]                                                       {'loss': 0.9031, 'learning_rate': 1.945358430132942e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 689/5198 [2:25:22<15:09:18, 12.10s/it] 13%|â–ˆâ–Ž        | 690/5198 [2:25:35<15:24:32, 12.31s/it]                                                       {'loss': 0.9342, 'learning_rate': 1.9451551005628803e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 690/5198 [2:25:35<15:24:32, 12.31s/it] 13%|â–ˆâ–Ž        | 691/5198 [2:25:51<16:53:45, 13.50s/it]                                                       {'loss': 0.3326, 'learning_rate': 1.9449514040510654e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 691/5198 [2:25:51<16:53:45, 13.50s/it] 13%|â–ˆâ–Ž        | 692/5198 [2:26:03<16:25:32, 13.12s/it]                                                       {'loss': 0.8867, 'learning_rate': 1.9447473406765803e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 692/5198 [2:26:04<16:25:32, 13.12s/it] 13%|â–ˆâ–Ž        | 693/5198 [2:26:16<16:12:12, 12.95s/it]                                                       {'loss': 0.8673, 'learning_rate': 1.9445429105186487e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 693/5198 [2:26:16<16:12:12, 12.95s/it] 13%|â–ˆâ–Ž        | 694/5198 [2:26:28<15:48:23, 12.63s/it]                                                       {'loss': 0.8752, 'learning_rate': 1.9443381136566382e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 694/5198 [2:26:28<15:48:23, 12.63s/it] 13%|â–ˆâ–Ž        | 695/5198 [2:26:41<15:58:29, 12.77s/it]                                                       {'loss': 0.8731, 'learning_rate': 1.9441329501700568e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 695/5198 [2:26:41<15:58:29, 12.77s/it] 13%|â–ˆâ–Ž        | 696/5198 [2:26:53<15:46:17, 12.61s/it]                                                       {'loss': 0.8718, 'learning_rate': 1.943927420138557e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 696/5198 [2:26:53<15:46:17, 12.61s/it] 13%|â–ˆâ–Ž        | 697/5198 [2:27:06<15:47:04, 12.62s/it]                                                       {'loss': 0.9097, 'learning_rate': 1.9437215236419322e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 697/5198 [2:27:06<15:47:04, 12.62s/it] 13%|â–ˆâ–Ž        | 698/5198 [2:27:20<16:11:57, 12.96s/it]                                                       {'loss': 0.8912, 'learning_rate': 1.9435152607601187e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 698/5198 [2:27:20<16:11:57, 12.96s/it] 13%|â–ˆâ–Ž        | 699/5198 [2:27:31<15:41:05, 12.55s/it]                                                       {'loss': 0.8869, 'learning_rate': 1.943308631573195e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 699/5198 [2:27:31<15:41:05, 12.55s/it] 13%|â–ˆâ–Ž        | 700/5198 [2:27:43<15:23:52, 12.32s/it]                                                       {'loss': 0.8911, 'learning_rate': 1.9431016361613816e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 700/5198 [2:27:43<15:23:52, 12.32s/it] 13%|â–ˆâ–Ž        | 701/5198 [2:27:55<15:27:51, 12.38s/it]                                                       {'loss': 0.9123, 'learning_rate': 1.9428942746050406e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 701/5198 [2:27:56<15:27:51, 12.38s/it] 14%|â–ˆâ–Ž        | 702/5198 [2:28:12<17:09:39, 13.74s/it]                                                       {'loss': 0.3195, 'learning_rate': 1.9426865469846773e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 702/5198 [2:28:12<17:09:39, 13.74s/it] 14%|â–ˆâ–Ž        | 703/5198 [2:28:27<17:21:26, 13.90s/it]                                                       {'loss': 0.9227, 'learning_rate': 1.9424784533809393e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 703/5198 [2:28:27<17:21:26, 13.90s/it] 14%|â–ˆâ–Ž        | 704/5198 [2:28:39<16:38:43, 13.33s/it]                                                       {'loss': 0.9156, 'learning_rate': 1.942269993874615e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 704/5198 [2:28:39<16:38:43, 13.33s/it] 14%|â–ˆâ–Ž        | 705/5198 [2:28:51<16:12:47, 12.99s/it]                                                       {'loss': 0.9535, 'learning_rate': 1.9420611685466358e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 705/5198 [2:28:51<16:12:47, 12.99s/it] 14%|â–ˆâ–Ž        | 706/5198 [2:29:04<16:11:20, 12.97s/it]                                                       {'loss': 0.8649, 'learning_rate': 1.9418519774780748e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 706/5198 [2:29:04<16:11:20, 12.97s/it] 14%|â–ˆâ–Ž        | 707/5198 [2:29:18<16:39:53, 13.36s/it]                                                       {'loss': 0.883, 'learning_rate': 1.9416424207501474e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 707/5198 [2:29:18<16:39:53, 13.36s/it] 14%|â–ˆâ–Ž        | 708/5198 [2:29:31<16:29:12, 13.22s/it]                                                       {'loss': 0.8665, 'learning_rate': 1.9414324984442102e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 708/5198 [2:29:31<16:29:12, 13.22s/it] 14%|â–ˆâ–Ž        | 709/5198 [2:29:46<17:10:11, 13.77s/it]                                                       {'loss': 0.8597, 'learning_rate': 1.9412222106417632e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 709/5198 [2:29:46<17:10:11, 13.77s/it] 14%|â–ˆâ–Ž        | 710/5198 [2:30:01<17:36:50, 14.13s/it]                                                       {'loss': 0.9292, 'learning_rate': 1.9410115574244462e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 710/5198 [2:30:01<17:36:50, 14.13s/it] 14%|â–ˆâ–Ž        | 711/5198 [2:30:14<17:08:31, 13.75s/it]                                                       {'loss': 0.8867, 'learning_rate': 1.9408005388740433e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 711/5198 [2:30:14<17:08:31, 13.75s/it] 14%|â–ˆâ–Ž        | 712/5198 [2:30:26<16:21:39, 13.13s/it]                                                       {'loss': 0.9312, 'learning_rate': 1.9405891550724778e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 712/5198 [2:30:26<16:21:39, 13.13s/it] 14%|â–ˆâ–Ž        | 713/5198 [2:30:40<16:58:21, 13.62s/it]                                                       {'loss': 0.921, 'learning_rate': 1.940377406101817e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 713/5198 [2:30:40<16:58:21, 13.62s/it] 14%|â–ˆâ–Ž        | 714/5198 [2:30:52<16:10:10, 12.98s/it]                                                       {'loss': 0.9007, 'learning_rate': 1.9401652920442694e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 714/5198 [2:30:52<16:10:10, 12.98s/it] 14%|â–ˆâ–        | 715/5198 [2:31:05<16:13:19, 13.03s/it]                                                       {'loss': 0.9818, 'learning_rate': 1.9399528129821842e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 715/5198 [2:31:05<16:13:19, 13.03s/it] 14%|â–ˆâ–        | 716/5198 [2:31:17<15:47:43, 12.69s/it]                                                       {'loss': 0.9029, 'learning_rate': 1.939739968998054e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 716/5198 [2:31:17<15:47:43, 12.69s/it] 14%|â–ˆâ–        | 717/5198 [2:31:29<15:30:01, 12.45s/it]                                                       {'loss': 0.9489, 'learning_rate': 1.939526760174511e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 717/5198 [2:31:29<15:30:01, 12.45s/it] 14%|â–ˆâ–        | 718/5198 [2:31:41<15:22:36, 12.36s/it]                                                       {'loss': 0.9539, 'learning_rate': 1.939313186594331e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 718/5198 [2:31:41<15:22:36, 12.36s/it] 14%|â–ˆâ–        | 719/5198 [2:31:54<15:28:51, 12.44s/it]                                                       {'loss': 0.8578, 'learning_rate': 1.9390992483404308e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 719/5198 [2:31:54<15:28:51, 12.44s/it] 14%|â–ˆâ–        | 720/5198 [2:32:05<15:14:10, 12.25s/it]                                                       {'loss': 0.9154, 'learning_rate': 1.938884945495868e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 720/5198 [2:32:05<15:14:10, 12.25s/it] 14%|â–ˆâ–        | 721/5198 [2:32:18<15:13:41, 12.25s/it]                                                       {'loss': 0.9085, 'learning_rate': 1.9386702781438425e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 721/5198 [2:32:18<15:13:41, 12.25s/it] 14%|â–ˆâ–        | 722/5198 [2:32:30<15:09:39, 12.19s/it]                                                       {'loss': 0.9412, 'learning_rate': 1.938455246367696e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 722/5198 [2:32:30<15:09:39, 12.19s/it] 14%|â–ˆâ–        | 723/5198 [2:32:42<15:24:16, 12.39s/it]                                                       {'loss': 0.8749, 'learning_rate': 1.9382398502509107e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 723/5198 [2:32:43<15:24:16, 12.39s/it] 14%|â–ˆâ–        | 724/5198 [2:32:55<15:26:48, 12.43s/it]                                                       {'loss': 0.8948, 'learning_rate': 1.938024089877111e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 724/5198 [2:32:55<15:26:48, 12.43s/it] 14%|â–ˆâ–        | 725/5198 [2:33:07<15:07:46, 12.18s/it]                                                       {'loss': 0.9069, 'learning_rate': 1.9378079653300624e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 725/5198 [2:33:07<15:07:46, 12.18s/it] 14%|â–ˆâ–        | 726/5198 [2:33:18<15:01:09, 12.09s/it]                                                       {'loss': 0.8934, 'learning_rate': 1.9375914766936723e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 726/5198 [2:33:19<15:01:09, 12.09s/it] 14%|â–ˆâ–        | 727/5198 [2:33:30<14:59:13, 12.07s/it]                                                       {'loss': 0.9275, 'learning_rate': 1.9373746240519884e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 727/5198 [2:33:31<14:59:13, 12.07s/it] 14%|â–ˆâ–        | 728/5198 [2:33:44<15:24:06, 12.40s/it]                                                       {'loss': 0.9217, 'learning_rate': 1.937157407489201e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 728/5198 [2:33:44<15:24:06, 12.40s/it] 14%|â–ˆâ–        | 729/5198 [2:33:56<15:32:13, 12.52s/it]                                                       {'loss': 0.8893, 'learning_rate': 1.9369398270896403e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 729/5198 [2:33:57<15:32:13, 12.52s/it] 14%|â–ˆâ–        | 730/5198 [2:34:14<17:35:36, 14.18s/it]                                                       {'loss': 0.3111, 'learning_rate': 1.936721882937779e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 730/5198 [2:34:15<17:35:36, 14.18s/it] 14%|â–ˆâ–        | 731/5198 [2:34:28<17:25:14, 14.04s/it]                                                       {'loss': 0.9035, 'learning_rate': 1.9365035751182307e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 731/5198 [2:34:28<17:25:14, 14.04s/it] 14%|â–ˆâ–        | 732/5198 [2:34:40<16:31:36, 13.32s/it]                                                       {'loss': 0.8963, 'learning_rate': 1.93628490371575e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 732/5198 [2:34:40<16:31:36, 13.32s/it] 14%|â–ˆâ–        | 733/5198 [2:34:52<16:08:10, 13.01s/it]                                                       {'loss': 0.9163, 'learning_rate': 1.9360658688152322e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 733/5198 [2:34:52<16:08:10, 13.01s/it] 14%|â–ˆâ–        | 734/5198 [2:35:04<15:44:34, 12.70s/it]                                                       {'loss': 0.8717, 'learning_rate': 1.9358464705017143e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 734/5198 [2:35:04<15:44:34, 12.70s/it] 14%|â–ˆâ–        | 735/5198 [2:35:16<15:17:01, 12.33s/it]                                                       {'loss': 0.9296, 'learning_rate': 1.9356267088603745e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 735/5198 [2:35:16<15:17:01, 12.33s/it] 14%|â–ˆâ–        | 736/5198 [2:35:28<15:14:51, 12.30s/it]                                                       {'loss': 0.8462, 'learning_rate': 1.9354065839765316e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 736/5198 [2:35:28<15:14:51, 12.30s/it] 14%|â–ˆâ–        | 737/5198 [2:35:40<15:10:45, 12.25s/it]                                                       {'loss': 0.917, 'learning_rate': 1.9351860959356462e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 737/5198 [2:35:40<15:10:45, 12.25s/it] 14%|â–ˆâ–        | 738/5198 [2:35:52<15:03:15, 12.15s/it]                                                       {'loss': 0.8689, 'learning_rate': 1.9349652448233187e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 738/5198 [2:35:52<15:03:15, 12.15s/it] 14%|â–ˆâ–        | 739/5198 [2:36:03<14:39:52, 11.84s/it]                                                       {'loss': 0.8942, 'learning_rate': 1.934744030725291e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 739/5198 [2:36:03<14:39:52, 11.84s/it] 14%|â–ˆâ–        | 740/5198 [2:36:15<14:43:28, 11.89s/it]                                                       {'loss': 0.8745, 'learning_rate': 1.934522453727447e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 740/5198 [2:36:15<14:43:28, 11.89s/it] 14%|â–ˆâ–        | 741/5198 [2:36:27<14:49:02, 11.97s/it]                                                       {'loss': 0.8752, 'learning_rate': 1.93430051391581e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 741/5198 [2:36:27<14:49:02, 11.97s/it] 14%|â–ˆâ–        | 742/5198 [2:36:40<15:03:42, 12.17s/it]                                                       {'loss': 0.9002, 'learning_rate': 1.934078211376544e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 742/5198 [2:36:40<15:03:42, 12.17s/it] 14%|â–ˆâ–        | 743/5198 [2:36:51<14:49:08, 11.97s/it]                                                       {'loss': 0.9029, 'learning_rate': 1.9338555461959554e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 743/5198 [2:36:51<14:49:08, 11.97s/it] 14%|â–ˆâ–        | 744/5198 [2:37:03<14:40:49, 11.87s/it]                                                       {'loss': 0.9058, 'learning_rate': 1.93363251846049e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 744/5198 [2:37:03<14:40:49, 11.87s/it] 14%|â–ˆâ–        | 745/5198 [2:37:16<15:03:43, 12.18s/it]                                                       {'loss': 0.8877, 'learning_rate': 1.9334091282567352e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 745/5198 [2:37:16<15:03:43, 12.18s/it] 14%|â–ˆâ–        | 746/5198 [2:37:28<15:00:38, 12.14s/it]                                                       {'loss': 0.9164, 'learning_rate': 1.9331853756714185e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 746/5198 [2:37:28<15:00:38, 12.14s/it] 14%|â–ˆâ–        | 747/5198 [2:37:40<14:51:19, 12.02s/it]                                                       {'loss': 0.8943, 'learning_rate': 1.9329612607914088e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 747/5198 [2:37:40<14:51:19, 12.02s/it] 14%|â–ˆâ–        | 748/5198 [2:37:57<16:40:51, 13.49s/it]                                                       {'loss': 0.337, 'learning_rate': 1.9327367837037142e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 748/5198 [2:37:57<16:40:51, 13.49s/it] 14%|â–ˆâ–        | 749/5198 [2:38:13<17:36:07, 14.24s/it]                                                       {'loss': 0.3142, 'learning_rate': 1.9325119444954855e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 749/5198 [2:38:13<17:36:07, 14.24s/it] 14%|â–ˆâ–        | 750/5198 [2:38:25<16:57:13, 13.72s/it]                                                       {'loss': 0.9141, 'learning_rate': 1.9322867432540126e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 750/5198 [2:38:25<16:57:13, 13.72s/it] 14%|â–ˆâ–        | 751/5198 [2:38:37<16:14:39, 13.15s/it]                                                       {'loss': 0.9388, 'learning_rate': 1.9320611800667268e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 751/5198 [2:38:37<16:14:39, 13.15s/it] 14%|â–ˆâ–        | 752/5198 [2:38:50<16:19:14, 13.22s/it]                                                       {'loss': 0.9113, 'learning_rate': 1.9318352550211986e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 752/5198 [2:38:50<16:19:14, 13.22s/it] 14%|â–ˆâ–        | 753/5198 [2:39:02<15:44:03, 12.74s/it]                                                       {'loss': 0.8611, 'learning_rate': 1.9316089682051403e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 753/5198 [2:39:02<15:44:03, 12.74s/it] 15%|â–ˆâ–        | 754/5198 [2:39:13<15:16:10, 12.37s/it]                                                       {'loss': 0.8924, 'learning_rate': 1.9313823197064042e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 754/5198 [2:39:13<15:16:10, 12.37s/it] 15%|â–ˆâ–        | 755/5198 [2:39:25<14:52:37, 12.05s/it]                                                       {'loss': 0.8897, 'learning_rate': 1.9311553096129835e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 755/5198 [2:39:25<14:52:37, 12.05s/it] 15%|â–ˆâ–        | 756/5198 [2:39:37<14:56:40, 12.11s/it]                                                       {'loss': 0.9004, 'learning_rate': 1.9309279380130112e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 756/5198 [2:39:37<14:56:40, 12.11s/it] 15%|â–ˆâ–        | 757/5198 [2:39:48<14:44:44, 11.95s/it]                                                       {'loss': 0.9725, 'learning_rate': 1.93070020499476e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 757/5198 [2:39:49<14:44:44, 11.95s/it] 15%|â–ˆâ–        | 758/5198 [2:40:01<14:46:36, 11.98s/it]                                                       {'loss': 0.9546, 'learning_rate': 1.930472110646645e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 758/5198 [2:40:01<14:46:36, 11.98s/it] 15%|â–ˆâ–        | 759/5198 [2:40:13<14:53:55, 12.08s/it]                                                       {'loss': 0.9009, 'learning_rate': 1.9302436550572187e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 759/5198 [2:40:13<14:53:55, 12.08s/it] 15%|â–ˆâ–        | 760/5198 [2:40:25<14:53:54, 12.09s/it]                                                       {'loss': 0.9141, 'learning_rate': 1.930014838315177e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 760/5198 [2:40:25<14:53:54, 12.09s/it] 15%|â–ˆâ–        | 761/5198 [2:40:37<14:47:40, 12.00s/it]                                                       {'loss': 0.8685, 'learning_rate': 1.9297856605093534e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 761/5198 [2:40:37<14:47:40, 12.00s/it] 15%|â–ˆâ–        | 762/5198 [2:40:50<15:04:29, 12.23s/it]                                                       {'loss': 0.8806, 'learning_rate': 1.9295561217287226e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 762/5198 [2:40:50<15:04:29, 12.23s/it] 15%|â–ˆâ–        | 763/5198 [2:41:01<14:55:52, 12.12s/it]                                                       {'loss': 0.9326, 'learning_rate': 1.9293262220624002e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 763/5198 [2:41:01<14:55:52, 12.12s/it] 15%|â–ˆâ–        | 764/5198 [2:41:13<14:49:21, 12.03s/it]                                                       {'loss': 0.8818, 'learning_rate': 1.9290959615996407e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 764/5198 [2:41:13<14:49:21, 12.03s/it] 15%|â–ˆâ–        | 765/5198 [2:41:26<15:06:33, 12.27s/it]                                                       {'loss': 0.9129, 'learning_rate': 1.9288653404298392e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 765/5198 [2:41:26<15:06:33, 12.27s/it] 15%|â–ˆâ–        | 766/5198 [2:41:37<14:46:22, 12.00s/it]                                                       {'loss': 0.8573, 'learning_rate': 1.9286343586425307e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 766/5198 [2:41:38<14:46:22, 12.00s/it] 15%|â–ˆâ–        | 767/5198 [2:41:49<14:46:08, 12.00s/it]                                                       {'loss': 0.9009, 'learning_rate': 1.9284030163273907e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 767/5198 [2:41:49<14:46:08, 12.00s/it] 15%|â–ˆâ–        | 768/5198 [2:42:01<14:46:05, 12.00s/it]                                                       {'loss': 0.8989, 'learning_rate': 1.9281713135742333e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 768/5198 [2:42:01<14:46:05, 12.00s/it] 15%|â–ˆâ–        | 769/5198 [2:42:15<15:23:44, 12.51s/it]                                                       {'loss': 0.8928, 'learning_rate': 1.9279392504730147e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 769/5198 [2:42:15<15:23:44, 12.51s/it] 15%|â–ˆâ–        | 770/5198 [2:42:27<15:05:12, 12.27s/it]                                                       {'loss': 0.9666, 'learning_rate': 1.9277068271138287e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 770/5198 [2:42:27<15:05:12, 12.27s/it] 15%|â–ˆâ–        | 771/5198 [2:42:40<15:17:55, 12.44s/it]                                                       {'loss': 0.8785, 'learning_rate': 1.9274740435869107e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 771/5198 [2:42:40<15:17:55, 12.44s/it] 15%|â–ˆâ–        | 772/5198 [2:42:51<15:04:17, 12.26s/it]                                                       {'loss': 0.8869, 'learning_rate': 1.927240899982635e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 772/5198 [2:42:52<15:04:17, 12.26s/it] 15%|â–ˆâ–        | 773/5198 [2:43:03<14:50:16, 12.07s/it]                                                       {'loss': 0.9033, 'learning_rate': 1.9270073963915162e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 773/5198 [2:43:03<14:50:16, 12.07s/it] 15%|â–ˆâ–        | 774/5198 [2:43:16<14:57:59, 12.18s/it]                                                       {'loss': 0.9253, 'learning_rate': 1.9267735329042086e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 774/5198 [2:43:16<14:57:59, 12.18s/it] 15%|â–ˆâ–        | 775/5198 [2:43:28<15:00:53, 12.22s/it]                                                       {'loss': 0.8668, 'learning_rate': 1.9265393096115056e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 775/5198 [2:43:28<15:00:53, 12.22s/it] 15%|â–ˆâ–        | 776/5198 [2:43:40<14:58:33, 12.19s/it]                                                       {'loss': 0.8754, 'learning_rate': 1.926304726604341e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 776/5198 [2:43:40<14:58:33, 12.19s/it] 15%|â–ˆâ–        | 777/5198 [2:43:52<14:46:22, 12.03s/it]                                                       {'loss': 0.9063, 'learning_rate': 1.9260697839737875e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 777/5198 [2:43:52<14:46:22, 12.03s/it] 15%|â–ˆâ–        | 778/5198 [2:44:06<15:28:44, 12.61s/it]                                                       {'loss': 0.8459, 'learning_rate': 1.925834481811059e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 778/5198 [2:44:06<15:28:44, 12.61s/it] 15%|â–ˆâ–        | 779/5198 [2:44:18<15:24:17, 12.55s/it]                                                       {'loss': 0.9231, 'learning_rate': 1.9255988202075065e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 779/5198 [2:44:18<15:24:17, 12.55s/it] 15%|â–ˆâ–Œ        | 780/5198 [2:44:30<15:03:20, 12.27s/it]                                                       {'loss': 0.8597, 'learning_rate': 1.925362799254623e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 780/5198 [2:44:30<15:03:20, 12.27s/it] 15%|â–ˆâ–Œ        | 781/5198 [2:44:43<15:24:50, 12.56s/it]                                                       {'loss': 0.9021, 'learning_rate': 1.9251264190440398e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 781/5198 [2:44:43<15:24:50, 12.56s/it] 15%|â–ˆâ–Œ        | 782/5198 [2:44:55<15:24:05, 12.56s/it]                                                       {'loss': 0.8564, 'learning_rate': 1.9248896796675277e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 782/5198 [2:44:55<15:24:05, 12.56s/it] 15%|â–ˆâ–Œ        | 783/5198 [2:45:07<15:06:04, 12.31s/it]                                                       {'loss': 0.9078, 'learning_rate': 1.924652581216997e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 783/5198 [2:45:07<15:06:04, 12.31s/it] 15%|â–ˆâ–Œ        | 784/5198 [2:45:19<14:58:15, 12.21s/it]                                                       {'loss': 0.8789, 'learning_rate': 1.9244151237844975e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 784/5198 [2:45:19<14:58:15, 12.21s/it] 15%|â–ˆâ–Œ        | 785/5198 [2:45:31<14:44:11, 12.02s/it]                                                       {'loss': 0.8635, 'learning_rate': 1.9241773074622182e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 785/5198 [2:45:31<14:44:11, 12.02s/it] 15%|â–ˆâ–Œ        | 786/5198 [2:45:43<14:48:48, 12.09s/it]                                                       {'loss': 0.9247, 'learning_rate': 1.923939132342488e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 786/5198 [2:45:43<14:48:48, 12.09s/it] 15%|â–ˆâ–Œ        | 787/5198 [2:45:54<14:31:42, 11.86s/it]                                                       {'loss': 0.7922, 'learning_rate': 1.923700598517775e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 787/5198 [2:45:54<14:31:42, 11.86s/it] 15%|â–ˆâ–Œ        | 788/5198 [2:46:09<15:37:46, 12.76s/it]                                                       {'loss': 0.8486, 'learning_rate': 1.923461706080685e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 788/5198 [2:46:09<15:37:46, 12.76s/it] 15%|â–ˆâ–Œ        | 789/5198 [2:46:26<17:09:36, 14.01s/it]                                                       {'loss': 0.3691, 'learning_rate': 1.923222455123965e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 789/5198 [2:46:26<17:09:36, 14.01s/it] 15%|â–ˆâ–Œ        | 790/5198 [2:46:38<16:21:45, 13.36s/it]                                                       {'loss': 0.9195, 'learning_rate': 1.9229828457405005e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 790/5198 [2:46:38<16:21:45, 13.36s/it] 15%|â–ˆâ–Œ        | 791/5198 [2:46:55<17:38:59, 14.42s/it]                                                       {'loss': 0.3798, 'learning_rate': 1.9227428780233162e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 791/5198 [2:46:55<17:38:59, 14.42s/it] 15%|â–ˆâ–Œ        | 792/5198 [2:47:06<16:37:13, 13.58s/it]                                                       {'loss': 0.9331, 'learning_rate': 1.922502552065576e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 792/5198 [2:47:07<16:37:13, 13.58s/it] 15%|â–ˆâ–Œ        | 793/5198 [2:47:24<17:57:13, 14.67s/it]                                                       {'loss': 0.3178, 'learning_rate': 1.922261867960582e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 793/5198 [2:47:24<17:57:13, 14.67s/it] 15%|â–ˆâ–Œ        | 794/5198 [2:47:35<16:42:42, 13.66s/it]                                                       {'loss': 0.8914, 'learning_rate': 1.9220208258017763e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 794/5198 [2:47:35<16:42:42, 13.66s/it] 15%|â–ˆâ–Œ        | 795/5198 [2:47:47<16:00:09, 13.08s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.92177942568274e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 795/5198 [2:47:47<16:00:09, 13.08s/it] 15%|â–ˆâ–Œ        | 796/5198 [2:47:59<15:36:30, 12.76s/it]                                                       {'loss': 0.9487, 'learning_rate': 1.921537667697193e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 796/5198 [2:47:59<15:36:30, 12.76s/it] 15%|â–ˆâ–Œ        | 797/5198 [2:48:11<15:24:04, 12.60s/it]                                                       {'loss': 0.8975, 'learning_rate': 1.9212955519389938e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 797/5198 [2:48:11<15:24:04, 12.60s/it] 15%|â–ˆâ–Œ        | 798/5198 [2:48:23<15:03:14, 12.32s/it]                                                       {'loss': 0.9317, 'learning_rate': 1.9210530785021405e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 798/5198 [2:48:23<15:03:14, 12.32s/it] 15%|â–ˆâ–Œ        | 799/5198 [2:48:34<14:48:57, 12.12s/it]                                                       {'loss': 0.8512, 'learning_rate': 1.9208102474807692e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 799/5198 [2:48:34<14:48:57, 12.12s/it] 15%|â–ˆâ–Œ        | 800/5198 [2:48:47<14:58:05, 12.25s/it]                                                       {'loss': 0.9179, 'learning_rate': 1.920567058969155e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 800/5198 [2:48:47<14:58:05, 12.25s/it] 15%|â–ˆâ–Œ        | 801/5198 [2:49:01<15:40:25, 12.83s/it]                                                       {'loss': 0.8729, 'learning_rate': 1.920323513061713e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 801/5198 [2:49:01<15:40:25, 12.83s/it] 15%|â–ˆâ–Œ        | 802/5198 [2:49:14<15:43:12, 12.87s/it]                                                       {'loss': 0.8355, 'learning_rate': 1.9200796098529956e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 802/5198 [2:49:14<15:43:12, 12.87s/it] 15%|â–ˆâ–Œ        | 803/5198 [2:49:26<15:27:04, 12.66s/it]                                                       {'loss': 0.8685, 'learning_rate': 1.919835349437694e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 803/5198 [2:49:26<15:27:04, 12.66s/it] 15%|â–ˆâ–Œ        | 804/5198 [2:49:39<15:28:06, 12.67s/it]                                                       {'loss': 0.8907, 'learning_rate': 1.9195907319106394e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 804/5198 [2:49:39<15:28:06, 12.67s/it] 15%|â–ˆâ–Œ        | 805/5198 [2:49:51<15:07:59, 12.40s/it]                                                       {'loss': 0.8465, 'learning_rate': 1.9193457573667996e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 805/5198 [2:49:51<15:07:59, 12.40s/it] 16%|â–ˆâ–Œ        | 806/5198 [2:50:03<15:01:02, 12.31s/it]                                                       {'loss': 0.8203, 'learning_rate': 1.919100425901283e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 806/5198 [2:50:03<15:01:02, 12.31s/it] 16%|â–ˆâ–Œ        | 807/5198 [2:50:15<14:53:39, 12.21s/it]                                                       {'loss': 0.9466, 'learning_rate': 1.9188547376093355e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 807/5198 [2:50:15<14:53:39, 12.21s/it] 16%|â–ˆâ–Œ        | 808/5198 [2:50:27<14:55:59, 12.25s/it]                                                       {'loss': 0.887, 'learning_rate': 1.918608692586342e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 808/5198 [2:50:27<14:55:59, 12.25s/it] 16%|â–ˆâ–Œ        | 809/5198 [2:50:40<15:18:47, 12.56s/it]                                                       {'loss': 0.8772, 'learning_rate': 1.918362290927825e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 809/5198 [2:50:40<15:18:47, 12.56s/it] 16%|â–ˆâ–Œ        | 810/5198 [2:50:52<14:50:07, 12.17s/it]                                                       {'loss': 0.8915, 'learning_rate': 1.9181155327294468e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 810/5198 [2:50:52<14:50:07, 12.17s/it] 16%|â–ˆâ–Œ        | 811/5198 [2:51:04<14:59:59, 12.31s/it]                                                       {'loss': 0.8631, 'learning_rate': 1.9178684180870072e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 811/5198 [2:51:04<14:59:59, 12.31s/it] 16%|â–ˆâ–Œ        | 812/5198 [2:51:17<15:13:26, 12.50s/it]                                                       {'loss': 0.9051, 'learning_rate': 1.9176209470964446e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 812/5198 [2:51:17<15:13:26, 12.50s/it] 16%|â–ˆâ–Œ        | 813/5198 [2:51:29<14:57:33, 12.28s/it]                                                       {'loss': 0.8355, 'learning_rate': 1.9173731198538354e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 813/5198 [2:51:29<14:57:33, 12.28s/it] 16%|â–ˆâ–Œ        | 814/5198 [2:51:40<14:35:03, 11.98s/it]                                                       {'loss': 0.9167, 'learning_rate': 1.9171249364553956e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 814/5198 [2:51:40<14:35:03, 11.98s/it] 16%|â–ˆâ–Œ        | 815/5198 [2:51:55<15:36:28, 12.82s/it]                                                       {'loss': 0.9099, 'learning_rate': 1.9168763969974773e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 815/5198 [2:51:55<15:36:28, 12.82s/it] 16%|â–ˆâ–Œ        | 816/5198 [2:52:09<16:09:39, 13.28s/it]                                                       {'loss': 0.8557, 'learning_rate': 1.916627501576573e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 816/5198 [2:52:09<16:09:39, 13.28s/it] 16%|â–ˆâ–Œ        | 817/5198 [2:52:21<15:29:32, 12.73s/it]                                                       {'loss': 0.9281, 'learning_rate': 1.916378250289312e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 817/5198 [2:52:21<15:29:32, 12.73s/it] 16%|â–ˆâ–Œ        | 818/5198 [2:52:33<15:09:53, 12.46s/it]                                                       {'loss': 0.8906, 'learning_rate': 1.9161286432324628e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 818/5198 [2:52:33<15:09:53, 12.46s/it] 16%|â–ˆâ–Œ        | 819/5198 [2:52:45<15:01:25, 12.35s/it]                                                       {'loss': 0.9009, 'learning_rate': 1.9158786805029307e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 819/5198 [2:52:45<15:01:25, 12.35s/it] 16%|â–ˆâ–Œ        | 820/5198 [2:52:56<14:49:11, 12.19s/it]                                                       {'loss': 0.8799, 'learning_rate': 1.9156283621977603e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 820/5198 [2:52:57<14:49:11, 12.19s/it] 16%|â–ˆâ–Œ        | 821/5198 [2:53:08<14:40:32, 12.07s/it]                                                       {'loss': 0.8748, 'learning_rate': 1.9153776884141336e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 821/5198 [2:53:08<14:40:32, 12.07s/it] 16%|â–ˆâ–Œ        | 822/5198 [2:53:21<15:01:10, 12.36s/it]                                                       {'loss': 0.8448, 'learning_rate': 1.915126659249371e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 822/5198 [2:53:21<15:01:10, 12.36s/it] 16%|â–ˆâ–Œ        | 823/5198 [2:53:34<15:00:20, 12.35s/it]                                                       {'loss': 0.9153, 'learning_rate': 1.9148752748009304e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 823/5198 [2:53:34<15:00:20, 12.35s/it] 16%|â–ˆâ–Œ        | 824/5198 [2:53:47<15:32:13, 12.79s/it]                                                       {'loss': 0.9429, 'learning_rate': 1.914623535166408e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 824/5198 [2:53:48<15:32:13, 12.79s/it] 16%|â–ˆâ–Œ        | 825/5198 [2:54:01<15:53:30, 13.08s/it]                                                       {'loss': 0.9122, 'learning_rate': 1.9143714404435382e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 825/5198 [2:54:01<15:53:30, 13.08s/it] 16%|â–ˆâ–Œ        | 826/5198 [2:54:13<15:30:14, 12.77s/it]                                                       {'loss': 0.9324, 'learning_rate': 1.9141189907301922e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 826/5198 [2:54:13<15:30:14, 12.77s/it] 16%|â–ˆâ–Œ        | 827/5198 [2:54:25<15:18:36, 12.61s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.9138661861243802e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 827/5198 [2:54:26<15:18:36, 12.61s/it] 16%|â–ˆâ–Œ        | 828/5198 [2:54:37<15:03:59, 12.41s/it]                                                       {'loss': 0.9126, 'learning_rate': 1.913613026724249e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 828/5198 [2:54:37<15:03:59, 12.41s/it] 16%|â–ˆâ–Œ        | 829/5198 [2:54:49<14:35:44, 12.03s/it]                                                       {'loss': 0.8548, 'learning_rate': 1.9133595126280848e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 829/5198 [2:54:49<14:35:44, 12.03s/it] 16%|â–ˆâ–Œ        | 830/5198 [2:55:02<14:57:30, 12.33s/it]                                                       {'loss': 0.8717, 'learning_rate': 1.9131056439343095e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 830/5198 [2:55:02<14:57:30, 12.33s/it] 16%|â–ˆâ–Œ        | 831/5198 [2:55:13<14:43:32, 12.14s/it]                                                       {'loss': 0.8636, 'learning_rate': 1.9128514207414838e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 831/5198 [2:55:13<14:43:32, 12.14s/it] 16%|â–ˆâ–Œ        | 832/5198 [2:55:25<14:32:11, 11.99s/it]                                                       {'loss': 0.8351, 'learning_rate': 1.9125968431483068e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 832/5198 [2:55:25<14:32:11, 11.99s/it] 16%|â–ˆâ–Œ        | 833/5198 [2:55:37<14:35:09, 12.03s/it]                                                       {'loss': 0.9147, 'learning_rate': 1.9123419112536132e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 833/5198 [2:55:37<14:35:09, 12.03s/it] 16%|â–ˆâ–Œ        | 834/5198 [2:55:50<14:46:30, 12.19s/it]                                                       {'loss': 0.9576, 'learning_rate': 1.912086625156377e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 834/5198 [2:55:50<14:46:30, 12.19s/it] 16%|â–ˆâ–Œ        | 835/5198 [2:56:03<15:15:19, 12.59s/it]                                                       {'loss': 0.8679, 'learning_rate': 1.911830984955709e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 835/5198 [2:56:03<15:15:19, 12.59s/it] 16%|â–ˆâ–Œ        | 836/5198 [2:56:15<14:52:38, 12.28s/it]                                                       {'loss': 0.9026, 'learning_rate': 1.911574990750857e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 836/5198 [2:56:15<14:52:38, 12.28s/it] 16%|â–ˆâ–Œ        | 837/5198 [2:56:28<15:22:16, 12.69s/it]                                                       {'loss': 0.9075, 'learning_rate': 1.9113186426412073e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 837/5198 [2:56:28<15:22:16, 12.69s/it] 16%|â–ˆâ–Œ        | 838/5198 [2:56:44<16:35:52, 13.70s/it]                                                       {'loss': 0.3638, 'learning_rate': 1.9110619407262828e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 838/5198 [2:56:44<16:35:52, 13.70s/it] 16%|â–ˆâ–Œ        | 839/5198 [2:56:56<15:50:28, 13.08s/it]                                                       {'loss': 0.9205, 'learning_rate': 1.9108048851057447e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 839/5198 [2:56:56<15:50:28, 13.08s/it] 16%|â–ˆâ–Œ        | 840/5198 [2:57:09<15:41:05, 12.96s/it]                                                       {'loss': 0.8824, 'learning_rate': 1.9105474758793897e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 840/5198 [2:57:09<15:41:05, 12.96s/it] 16%|â–ˆâ–Œ        | 841/5198 [2:57:21<15:16:25, 12.62s/it]                                                       {'loss': 0.9331, 'learning_rate': 1.9102897131471536e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 841/5198 [2:57:21<15:16:25, 12.62s/it] 16%|â–ˆâ–Œ        | 842/5198 [2:57:33<15:02:36, 12.43s/it]                                                       {'loss': 0.8765, 'learning_rate': 1.9100315970091088e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 842/5198 [2:57:33<15:02:36, 12.43s/it] 16%|â–ˆâ–Œ        | 843/5198 [2:57:45<14:56:26, 12.35s/it]                                                       {'loss': 0.8895, 'learning_rate': 1.9097731275654645e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 843/5198 [2:57:45<14:56:26, 12.35s/it] 16%|â–ˆâ–Œ        | 844/5198 [2:57:58<15:19:18, 12.67s/it]                                                       {'loss': 0.8966, 'learning_rate': 1.909514304916568e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 844/5198 [2:57:58<15:19:18, 12.67s/it] 16%|â–ˆâ–‹        | 845/5198 [2:58:10<14:58:11, 12.38s/it]                                                       {'loss': 0.9006, 'learning_rate': 1.9092551291629026e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 845/5198 [2:58:10<14:58:11, 12.38s/it] 16%|â–ˆâ–‹        | 846/5198 [2:58:27<16:35:33, 13.73s/it]                                                       {'loss': 0.3473, 'learning_rate': 1.9089956004050893e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 846/5198 [2:58:27<16:35:33, 13.73s/it] 16%|â–ˆâ–‹        | 847/5198 [2:58:43<17:30:21, 14.48s/it]                                                       {'loss': 0.351, 'learning_rate': 1.908735718743887e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 847/5198 [2:58:43<17:30:21, 14.48s/it] 16%|â–ˆâ–‹        | 848/5198 [2:58:55<16:40:24, 13.80s/it]                                                       {'loss': 0.9456, 'learning_rate': 1.908475484280189e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 848/5198 [2:58:55<16:40:24, 13.80s/it] 16%|â–ˆâ–‹        | 849/5198 [2:59:09<16:32:44, 13.70s/it]                                                       {'loss': 0.9057, 'learning_rate': 1.908214897115029e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 849/5198 [2:59:09<16:32:44, 13.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2254 > 2048). Running this sequence through the model will result in indexing errors
 16%|â–ˆâ–‹        | 850/5198 [2:59:21<15:59:23, 13.24s/it]                                                       {'loss': 0.8762, 'learning_rate': 1.907953957349575e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 850/5198 [2:59:21<15:59:23, 13.24s/it] 16%|â–ˆâ–‹        | 851/5198 [2:59:33<15:29:28, 12.83s/it]                                                       {'loss': 0.9268, 'learning_rate': 1.907692665085133e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 851/5198 [2:59:33<15:29:28, 12.83s/it] 16%|â–ˆâ–‹        | 852/5198 [2:59:44<15:07:59, 12.54s/it]                                                       {'loss': 0.897, 'learning_rate': 1.9074310204231457e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 852/5198 [2:59:45<15:07:59, 12.54s/it] 16%|â–ˆâ–‹        | 853/5198 [2:59:56<14:47:00, 12.25s/it]                                                       {'loss': 0.9262, 'learning_rate': 1.9071690234651923e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 853/5198 [2:59:56<14:47:00, 12.25s/it] 16%|â–ˆâ–‹        | 854/5198 [3:00:08<14:35:05, 12.09s/it]                                                       {'loss': 0.7843, 'learning_rate': 1.9069066743129893e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 854/5198 [3:00:08<14:35:05, 12.09s/it] 16%|â–ˆâ–‹        | 855/5198 [3:00:21<14:49:37, 12.29s/it]                                                       {'loss': 0.873, 'learning_rate': 1.90664397306839e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 855/5198 [3:00:21<14:49:37, 12.29s/it] 16%|â–ˆâ–‹        | 856/5198 [3:00:34<15:24:43, 12.78s/it]                                                       {'loss': 0.8619, 'learning_rate': 1.9063809198333832e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 856/5198 [3:00:35<15:24:43, 12.78s/it] 16%|â–ˆâ–‹        | 857/5198 [3:00:46<14:48:59, 12.29s/it]                                                       {'loss': 0.8814, 'learning_rate': 1.9061175147100957e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 857/5198 [3:00:46<14:48:59, 12.29s/it] 17%|â–ˆâ–‹        | 858/5198 [3:00:58<14:54:31, 12.37s/it]                                                       {'loss': 0.9372, 'learning_rate': 1.905853757800791e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 858/5198 [3:00:58<14:54:31, 12.37s/it] 17%|â–ˆâ–‹        | 859/5198 [3:01:13<15:48:38, 13.12s/it]                                                       {'loss': 0.8985, 'learning_rate': 1.9055896492078675e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 859/5198 [3:01:13<15:48:38, 13.12s/it] 17%|â–ˆâ–‹        | 860/5198 [3:01:25<15:22:30, 12.76s/it]                                                       {'loss': 0.8572, 'learning_rate': 1.905325189033862e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 860/5198 [3:01:25<15:22:30, 12.76s/it] 17%|â–ˆâ–‹        | 861/5198 [3:01:39<15:46:35, 13.10s/it]                                                       {'loss': 0.8968, 'learning_rate': 1.905060377381447e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 861/5198 [3:01:39<15:46:35, 13.10s/it] 17%|â–ˆâ–‹        | 862/5198 [3:01:51<15:25:47, 12.81s/it]                                                       {'loss': 0.9678, 'learning_rate': 1.904795214353431e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 862/5198 [3:01:51<15:25:47, 12.81s/it] 17%|â–ˆâ–‹        | 863/5198 [3:02:03<15:10:09, 12.60s/it]                                                       {'loss': 0.8538, 'learning_rate': 1.90452970005276e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 863/5198 [3:02:03<15:10:09, 12.60s/it] 17%|â–ˆâ–‹        | 864/5198 [3:02:15<14:59:54, 12.46s/it]                                                       {'loss': 0.915, 'learning_rate': 1.9042638345825155e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 864/5198 [3:02:15<14:59:54, 12.46s/it] 17%|â–ˆâ–‹        | 865/5198 [3:02:27<14:34:35, 12.11s/it]                                                       {'loss': 0.8752, 'learning_rate': 1.9039976180459158e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 865/5198 [3:02:27<14:34:35, 12.11s/it] 17%|â–ˆâ–‹        | 866/5198 [3:02:43<16:15:36, 13.51s/it]                                                       {'loss': 0.3145, 'learning_rate': 1.9037310505463153e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 866/5198 [3:02:43<16:15:36, 13.51s/it] 17%|â–ˆâ–‹        | 867/5198 [3:02:55<15:38:14, 13.00s/it]                                                       {'loss': 0.9162, 'learning_rate': 1.9034641321872043e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 867/5198 [3:02:55<15:38:14, 13.00s/it] 17%|â–ˆâ–‹        | 868/5198 [3:03:07<15:18:19, 12.73s/it]                                                       {'loss': 0.913, 'learning_rate': 1.9031968630722104e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 868/5198 [3:03:07<15:18:19, 12.73s/it] 17%|â–ˆâ–‹        | 869/5198 [3:03:20<15:10:22, 12.62s/it]                                                       {'loss': 0.8836, 'learning_rate': 1.902929243305096e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 869/5198 [3:03:20<15:10:22, 12.62s/it] 17%|â–ˆâ–‹        | 870/5198 [3:03:32<15:16:21, 12.70s/it]                                                       {'loss': 0.8686, 'learning_rate': 1.902661272989761e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 870/5198 [3:03:33<15:16:21, 12.70s/it] 17%|â–ˆâ–‹        | 871/5198 [3:03:45<15:12:30, 12.65s/it]                                                       {'loss': 0.8774, 'learning_rate': 1.9023929522302394e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 871/5198 [3:03:45<15:12:30, 12.65s/it] 17%|â–ˆâ–‹        | 872/5198 [3:03:57<15:06:31, 12.57s/it]                                                       {'loss': 0.8471, 'learning_rate': 1.9021242811307044e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 872/5198 [3:03:57<15:06:31, 12.57s/it] 17%|â–ˆâ–‹        | 873/5198 [3:04:13<16:04:09, 13.38s/it]                                                       {'loss': 0.864, 'learning_rate': 1.901855259795462e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 873/5198 [3:04:13<16:04:09, 13.38s/it] 17%|â–ˆâ–‹        | 874/5198 [3:04:25<15:33:01, 12.95s/it]                                                       {'loss': 0.8812, 'learning_rate': 1.9015858883289556e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 874/5198 [3:04:25<15:33:01, 12.95s/it] 17%|â–ˆâ–‹        | 875/5198 [3:04:37<15:14:31, 12.69s/it]                                                       {'loss': 0.8686, 'learning_rate': 1.9013161668357655e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 875/5198 [3:04:37<15:14:31, 12.69s/it] 17%|â–ˆâ–‹        | 876/5198 [3:04:49<14:59:49, 12.49s/it]                                                       {'loss': 0.8527, 'learning_rate': 1.901046095420606e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 876/5198 [3:04:49<14:59:49, 12.49s/it] 17%|â–ˆâ–‹        | 877/5198 [3:05:01<14:53:05, 12.40s/it]                                                       {'loss': 0.8816, 'learning_rate': 1.9007756741883284e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 877/5198 [3:05:01<14:53:05, 12.40s/it] 17%|â–ˆâ–‹        | 878/5198 [3:05:12<14:33:59, 12.14s/it]                                                       {'loss': 0.8887, 'learning_rate': 1.9005049032439193e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 878/5198 [3:05:12<14:33:59, 12.14s/it] 17%|â–ˆâ–‹        | 879/5198 [3:05:25<14:32:57, 12.13s/it]                                                       {'loss': 0.8998, 'learning_rate': 1.9002337826925012e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 879/5198 [3:05:25<14:32:57, 12.13s/it] 17%|â–ˆâ–‹        | 880/5198 [3:05:37<14:33:12, 12.13s/it]                                                       {'loss': 0.8698, 'learning_rate': 1.899962312639333e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 880/5198 [3:05:37<14:33:12, 12.13s/it] 17%|â–ˆâ–‹        | 881/5198 [3:05:54<16:26:31, 13.71s/it]                                                       {'loss': 0.339, 'learning_rate': 1.8996904931898085e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 881/5198 [3:05:54<16:26:31, 13.71s/it] 17%|â–ˆâ–‹        | 882/5198 [3:06:06<15:37:43, 13.04s/it]                                                       {'loss': 0.8374, 'learning_rate': 1.899418324449457e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 882/5198 [3:06:06<15:37:43, 13.04s/it] 17%|â–ˆâ–‹        | 883/5198 [3:06:17<15:04:29, 12.58s/it]                                                       {'loss': 0.8908, 'learning_rate': 1.8991458065239444e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 883/5198 [3:06:17<15:04:29, 12.58s/it] 17%|â–ˆâ–‹        | 884/5198 [3:06:29<15:00:49, 12.53s/it]                                                       {'loss': 0.9011, 'learning_rate': 1.8988729395190712e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 884/5198 [3:06:30<15:00:49, 12.53s/it] 17%|â–ˆâ–‹        | 885/5198 [3:06:43<15:21:08, 12.81s/it]                                                       {'loss': 0.9108, 'learning_rate': 1.8985997235407735e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 885/5198 [3:06:43<15:21:08, 12.81s/it] 17%|â–ˆâ–‹        | 886/5198 [3:06:54<14:50:27, 12.39s/it]                                                       {'loss': 0.9272, 'learning_rate': 1.898326158695124e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 886/5198 [3:06:54<14:50:27, 12.39s/it] 17%|â–ˆâ–‹        | 887/5198 [3:07:09<15:39:40, 13.08s/it]                                                       {'loss': 0.8544, 'learning_rate': 1.8980522450883287e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 887/5198 [3:07:09<15:39:40, 13.08s/it] 17%|â–ˆâ–‹        | 888/5198 [3:07:20<14:57:50, 12.50s/it]                                                       {'loss': 0.9178, 'learning_rate': 1.8977779828267314e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 888/5198 [3:07:20<14:57:50, 12.50s/it] 17%|â–ˆâ–‹        | 889/5198 [3:07:33<14:55:40, 12.47s/it]                                                       {'loss': 0.8373, 'learning_rate': 1.8975033720168094e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 889/5198 [3:07:33<14:55:40, 12.47s/it] 17%|â–ˆâ–‹        | 890/5198 [3:07:46<15:26:25, 12.90s/it]                                                       {'loss': 0.8922, 'learning_rate': 1.897228412765177e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 890/5198 [3:07:47<15:26:25, 12.90s/it] 17%|â–ˆâ–‹        | 891/5198 [3:07:58<15:05:44, 12.62s/it]                                                       {'loss': 0.9035, 'learning_rate': 1.896953105178582e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 891/5198 [3:07:58<15:05:44, 12.62s/it] 17%|â–ˆâ–‹        | 892/5198 [3:08:10<14:42:16, 12.29s/it]                                                       {'loss': 0.9109, 'learning_rate': 1.8966774493639084e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 892/5198 [3:08:10<14:42:16, 12.29s/it] 17%|â–ˆâ–‹        | 893/5198 [3:08:22<14:36:44, 12.22s/it]                                                       {'loss': 0.9503, 'learning_rate': 1.896401445428176e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 893/5198 [3:08:22<14:36:44, 12.22s/it] 17%|â–ˆâ–‹        | 894/5198 [3:08:35<14:51:29, 12.43s/it]                                                       {'loss': 0.8075, 'learning_rate': 1.896125093478538e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 894/5198 [3:08:35<14:51:29, 12.43s/it] 17%|â–ˆâ–‹        | 895/5198 [3:08:47<14:48:15, 12.39s/it]                                                       {'loss': 0.8581, 'learning_rate': 1.895848393622284e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 895/5198 [3:08:47<14:48:15, 12.39s/it] 17%|â–ˆâ–‹        | 896/5198 [3:08:59<14:27:43, 12.10s/it]                                                       {'loss': 0.8507, 'learning_rate': 1.895571345966839e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 896/5198 [3:08:59<14:27:43, 12.10s/it] 17%|â–ˆâ–‹        | 897/5198 [3:09:17<16:40:41, 13.96s/it]                                                       {'loss': 0.3474, 'learning_rate': 1.8952939506197622e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 897/5198 [3:09:17<16:40:41, 13.96s/it] 17%|â–ˆâ–‹        | 898/5198 [3:09:30<16:12:12, 13.57s/it]                                                       {'loss': 0.8672, 'learning_rate': 1.8950162076887477e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 898/5198 [3:09:30<16:12:12, 13.57s/it] 17%|â–ˆâ–‹        | 899/5198 [3:09:42<15:39:58, 13.12s/it]                                                       {'loss': 0.8661, 'learning_rate': 1.894738117281625e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 899/5198 [3:09:42<15:39:58, 13.12s/it] 17%|â–ˆâ–‹        | 900/5198 [3:09:57<16:17:18, 13.64s/it]                                                       {'loss': 0.9092, 'learning_rate': 1.8944596795063584e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 900/5198 [3:09:57<16:17:18, 13.64s/it] 17%|â–ˆâ–‹        | 901/5198 [3:10:12<16:47:41, 14.07s/it]                                                       {'loss': 0.9074, 'learning_rate': 1.894180894471047e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 901/5198 [3:10:12<16:47:41, 14.07s/it] 17%|â–ˆâ–‹        | 902/5198 [3:10:23<15:51:40, 13.29s/it]                                                       {'loss': 0.8892, 'learning_rate': 1.8939017622839253e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 902/5198 [3:10:23<15:51:40, 13.29s/it] 17%|â–ˆâ–‹        | 903/5198 [3:10:35<15:19:55, 12.85s/it]                                                       {'loss': 0.8708, 'learning_rate': 1.8936222830533613e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 903/5198 [3:10:35<15:19:55, 12.85s/it] 17%|â–ˆâ–‹        | 904/5198 [3:10:50<16:02:39, 13.45s/it]                                                       {'loss': 0.8512, 'learning_rate': 1.8933424568878586e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 904/5198 [3:10:50<16:02:39, 13.45s/it] 17%|â–ˆâ–‹        | 905/5198 [3:11:02<15:33:24, 13.05s/it]                                                       {'loss': 0.9346, 'learning_rate': 1.8930622838960555e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 905/5198 [3:11:02<15:33:24, 13.05s/it] 17%|â–ˆâ–‹        | 906/5198 [3:11:13<15:01:32, 12.60s/it]                                                       {'loss': 0.9139, 'learning_rate': 1.8927817641867244e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 906/5198 [3:11:13<15:01:32, 12.60s/it] 17%|â–ˆâ–‹        | 907/5198 [3:11:25<14:42:06, 12.33s/it]                                                       {'loss': 0.8358, 'learning_rate': 1.8925008978687737e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 907/5198 [3:11:25<14:42:06, 12.33s/it] 17%|â–ˆâ–‹        | 908/5198 [3:11:42<16:09:20, 13.56s/it]                                                       {'loss': 0.3572, 'learning_rate': 1.8922196850512446e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 908/5198 [3:11:42<16:09:20, 13.56s/it] 17%|â–ˆâ–‹        | 909/5198 [3:11:53<15:31:14, 13.03s/it]                                                       {'loss': 0.9009, 'learning_rate': 1.8919381258433135e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 909/5198 [3:11:53<15:31:14, 13.03s/it] 18%|â–ˆâ–Š        | 910/5198 [3:12:06<15:16:44, 12.83s/it]                                                       {'loss': 0.887, 'learning_rate': 1.8916562203542916e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 910/5198 [3:12:06<15:16:44, 12.83s/it] 18%|â–ˆâ–Š        | 911/5198 [3:12:18<15:09:33, 12.73s/it]                                                       {'loss': 0.8894, 'learning_rate': 1.8913739686936244e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 911/5198 [3:12:18<15:09:33, 12.73s/it] 18%|â–ˆâ–Š        | 912/5198 [3:12:31<15:04:17, 12.66s/it]                                                       {'loss': 0.9072, 'learning_rate': 1.8910913709708918e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 912/5198 [3:12:31<15:04:17, 12.66s/it] 18%|â–ˆâ–Š        | 913/5198 [3:12:42<14:41:15, 12.34s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.8908084272958077e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 913/5198 [3:12:42<14:41:15, 12.34s/it] 18%|â–ˆâ–Š        | 914/5198 [3:12:54<14:26:58, 12.14s/it]                                                       {'loss': 0.8448, 'learning_rate': 1.8905251377782206e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 914/5198 [3:12:54<14:26:58, 12.14s/it] 18%|â–ˆâ–Š        | 915/5198 [3:13:06<14:22:49, 12.09s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.8902415025281136e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 915/5198 [3:13:06<14:22:49, 12.09s/it] 18%|â–ˆâ–Š        | 916/5198 [3:13:18<14:22:20, 12.08s/it]                                                       {'loss': 0.8791, 'learning_rate': 1.889957521655603e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 916/5198 [3:13:18<14:22:20, 12.08s/it] 18%|â–ˆâ–Š        | 917/5198 [3:13:29<14:09:28, 11.91s/it]                                                       {'loss': 0.8567, 'learning_rate': 1.8896731952709408e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 917/5198 [3:13:30<14:09:28, 11.91s/it] 18%|â–ˆâ–Š        | 918/5198 [3:13:42<14:30:39, 12.21s/it]                                                       {'loss': 0.9052, 'learning_rate': 1.8893885234845117e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 918/5198 [3:13:42<14:30:39, 12.21s/it] 18%|â–ˆâ–Š        | 919/5198 [3:13:54<14:24:48, 12.13s/it]                                                       {'loss': 0.8757, 'learning_rate': 1.8891035064068354e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 919/5198 [3:13:54<14:24:48, 12.13s/it] 18%|â–ˆâ–Š        | 920/5198 [3:14:08<14:49:48, 12.48s/it]                                                       {'loss': 0.8855, 'learning_rate': 1.888818144148565e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 920/5198 [3:14:08<14:49:48, 12.48s/it] 18%|â–ˆâ–Š        | 921/5198 [3:14:20<14:44:41, 12.41s/it]                                                       {'loss': 0.8151, 'learning_rate': 1.888532436820488e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 921/5198 [3:14:20<14:44:41, 12.41s/it] 18%|â–ˆâ–Š        | 922/5198 [3:14:32<14:43:08, 12.39s/it]                                                       {'loss': 0.8274, 'learning_rate': 1.8882463845335263e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 922/5198 [3:14:32<14:43:08, 12.39s/it] 18%|â–ˆâ–Š        | 923/5198 [3:14:45<14:41:33, 12.37s/it]                                                       {'loss': 0.8428, 'learning_rate': 1.8879599873987343e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 923/5198 [3:14:45<14:41:33, 12.37s/it] 18%|â–ˆâ–Š        | 924/5198 [3:14:56<14:30:13, 12.22s/it]                                                       {'loss': 0.8515, 'learning_rate': 1.8876732455273022e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 924/5198 [3:14:56<14:30:13, 12.22s/it] 18%|â–ˆâ–Š        | 925/5198 [3:15:08<14:14:28, 12.00s/it]                                                       {'loss': 0.9129, 'learning_rate': 1.8873861590305527e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 925/5198 [3:15:08<14:14:28, 12.00s/it] 18%|â–ˆâ–Š        | 926/5198 [3:15:24<15:49:26, 13.33s/it]                                                       {'loss': 0.3699, 'learning_rate': 1.8870987280199428e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 926/5198 [3:15:24<15:49:26, 13.33s/it] 18%|â–ˆâ–Š        | 927/5198 [3:15:37<15:27:49, 13.03s/it]                                                       {'loss': 0.9169, 'learning_rate': 1.886810952607063e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 927/5198 [3:15:37<15:27:49, 13.03s/it] 18%|â–ˆâ–Š        | 928/5198 [3:15:49<15:06:52, 12.74s/it]                                                       {'loss': 0.8678, 'learning_rate': 1.8865228329036372e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 928/5198 [3:15:49<15:06:52, 12.74s/it] 18%|â–ˆâ–Š        | 929/5198 [3:16:00<14:39:49, 12.37s/it]                                                       {'loss': 0.9392, 'learning_rate': 1.886234369021524e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 929/5198 [3:16:00<14:39:49, 12.37s/it] 18%|â–ˆâ–Š        | 930/5198 [3:16:12<14:28:09, 12.20s/it]                                                       {'loss': 0.8832, 'learning_rate': 1.885945561072715e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 930/5198 [3:16:12<14:28:09, 12.20s/it] 18%|â–ˆâ–Š        | 931/5198 [3:16:27<15:34:25, 13.14s/it]                                                       {'loss': 0.8805, 'learning_rate': 1.885656409169335e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 931/5198 [3:16:27<15:34:25, 13.14s/it] 18%|â–ˆâ–Š        | 932/5198 [3:16:42<16:05:23, 13.58s/it]                                                       {'loss': 0.9145, 'learning_rate': 1.885366913423643e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 932/5198 [3:16:42<16:05:23, 13.58s/it] 18%|â–ˆâ–Š        | 933/5198 [3:16:54<15:31:25, 13.10s/it]                                                       {'loss': 0.925, 'learning_rate': 1.8850770739480312e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 933/5198 [3:16:54<15:31:25, 13.10s/it] 18%|â–ˆâ–Š        | 934/5198 [3:17:06<15:12:55, 12.85s/it]                                                       {'loss': 0.8243, 'learning_rate': 1.8847868908550252e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 934/5198 [3:17:06<15:12:55, 12.85s/it] 18%|â–ˆâ–Š        | 935/5198 [3:17:19<15:04:42, 12.73s/it]                                                       {'loss': 0.8508, 'learning_rate': 1.8844963642572837e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 935/5198 [3:17:19<15:04:42, 12.73s/it] 18%|â–ˆâ–Š        | 936/5198 [3:17:31<14:45:09, 12.46s/it]                                                       {'loss': 0.8808, 'learning_rate': 1.8842054942676e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 936/5198 [3:17:31<14:45:09, 12.46s/it] 18%|â–ˆâ–Š        | 937/5198 [3:17:43<14:45:02, 12.46s/it]                                                       {'loss': 0.8447, 'learning_rate': 1.8839142809988987e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 937/5198 [3:17:43<14:45:02, 12.46s/it] 18%|â–ˆâ–Š        | 938/5198 [3:17:56<14:53:33, 12.59s/it]                                                       {'loss': 0.8275, 'learning_rate': 1.88362272456424e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 938/5198 [3:17:56<14:53:33, 12.59s/it] 18%|â–ˆâ–Š        | 939/5198 [3:18:07<14:27:46, 12.23s/it]                                                       {'loss': 0.8583, 'learning_rate': 1.8833308250768153e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 939/5198 [3:18:07<14:27:46, 12.23s/it] 18%|â–ˆâ–Š        | 940/5198 [3:18:20<14:46:49, 12.50s/it]                                                       {'loss': 0.867, 'learning_rate': 1.8830385826499507e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 940/5198 [3:18:20<14:46:49, 12.50s/it] 18%|â–ˆâ–Š        | 941/5198 [3:18:32<14:29:35, 12.26s/it]                                                       {'loss': 0.8715, 'learning_rate': 1.882745997397104e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 941/5198 [3:18:32<14:29:35, 12.26s/it] 18%|â–ˆâ–Š        | 942/5198 [3:18:44<14:19:07, 12.11s/it]                                                       {'loss': 0.8602, 'learning_rate': 1.8824530694318675e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 942/5198 [3:18:44<14:19:07, 12.11s/it] 18%|â–ˆâ–Š        | 943/5198 [3:18:56<14:24:03, 12.18s/it]                                                       {'loss': 0.8681, 'learning_rate': 1.882159798867966e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 943/5198 [3:18:56<14:24:03, 12.18s/it] 18%|â–ˆâ–Š        | 944/5198 [3:19:08<14:19:44, 12.13s/it]                                                       {'loss': 0.9461, 'learning_rate': 1.8818661858192562e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 944/5198 [3:19:08<14:19:44, 12.13s/it] 18%|â–ˆâ–Š        | 945/5198 [3:19:21<14:40:01, 12.42s/it]                                                       {'loss': 0.8951, 'learning_rate': 1.88157223039973e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 945/5198 [3:19:21<14:40:01, 12.42s/it] 18%|â–ˆâ–Š        | 946/5198 [3:19:38<16:01:27, 13.57s/it]                                                       {'loss': 0.3629, 'learning_rate': 1.8812779327235106e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 946/5198 [3:19:38<16:01:27, 13.57s/it] 18%|â–ˆâ–Š        | 947/5198 [3:19:50<15:29:46, 13.12s/it]                                                       {'loss': 0.886, 'learning_rate': 1.880983292904854e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 947/5198 [3:19:50<15:29:46, 13.12s/it] 18%|â–ˆâ–Š        | 948/5198 [3:20:02<15:16:22, 12.94s/it]                                                       {'loss': 0.8918, 'learning_rate': 1.88068831105815e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 948/5198 [3:20:02<15:16:22, 12.94s/it] 18%|â–ˆâ–Š        | 949/5198 [3:20:14<14:57:33, 12.67s/it]                                                       {'loss': 0.8934, 'learning_rate': 1.8803929872979214e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 949/5198 [3:20:14<14:57:33, 12.67s/it] 18%|â–ˆâ–Š        | 950/5198 [3:20:26<14:41:40, 12.45s/it]                                                       {'loss': 0.8766, 'learning_rate': 1.8800973217388215e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 950/5198 [3:20:26<14:41:40, 12.45s/it] 18%|â–ˆâ–Š        | 951/5198 [3:20:38<14:24:49, 12.22s/it]                                                       {'loss': 0.8902, 'learning_rate': 1.879801314495639e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 951/5198 [3:20:38<14:24:49, 12.22s/it] 18%|â–ˆâ–Š        | 952/5198 [3:20:51<14:35:09, 12.37s/it]                                                       {'loss': 0.9151, 'learning_rate': 1.879504965683294e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 952/5198 [3:20:51<14:35:09, 12.37s/it] 18%|â–ˆâ–Š        | 953/5198 [3:21:02<14:19:38, 12.15s/it]                                                       {'loss': 0.8365, 'learning_rate': 1.8792082754168385e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 953/5198 [3:21:02<14:19:38, 12.15s/it] 18%|â–ˆâ–Š        | 954/5198 [3:21:14<14:11:43, 12.04s/it]                                                       {'loss': 0.8379, 'learning_rate': 1.878911243811459e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 954/5198 [3:21:14<14:11:43, 12.04s/it] 18%|â–ˆâ–Š        | 955/5198 [3:21:26<14:15:36, 12.10s/it]                                                       {'loss': 0.8039, 'learning_rate': 1.8786138709824726e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 955/5198 [3:21:26<14:15:36, 12.10s/it] 18%|â–ˆâ–Š        | 956/5198 [3:21:40<14:44:18, 12.51s/it]                                                       {'loss': 0.8445, 'learning_rate': 1.8783161570453295e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 956/5198 [3:21:40<14:44:18, 12.51s/it] 18%|â–ˆâ–Š        | 957/5198 [3:21:52<14:43:05, 12.49s/it]                                                       {'loss': 0.8861, 'learning_rate': 1.878018102115614e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 957/5198 [3:21:52<14:43:05, 12.49s/it] 18%|â–ˆâ–Š        | 958/5198 [3:22:04<14:29:39, 12.31s/it]                                                       {'loss': 0.8547, 'learning_rate': 1.8777197063090394e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 958/5198 [3:22:04<14:29:39, 12.31s/it] 18%|â–ˆâ–Š        | 959/5198 [3:22:16<14:18:05, 12.15s/it]                                                       {'loss': 0.8641, 'learning_rate': 1.877420969741454e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 959/5198 [3:22:16<14:18:05, 12.15s/it] 18%|â–ˆâ–Š        | 960/5198 [3:22:29<14:41:01, 12.47s/it]                                                       {'loss': 0.8822, 'learning_rate': 1.877121892528838e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 960/5198 [3:22:29<14:41:01, 12.47s/it] 18%|â–ˆâ–Š        | 961/5198 [3:22:41<14:29:46, 12.32s/it]                                                       {'loss': 0.8768, 'learning_rate': 1.876822474787303e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 961/5198 [3:22:41<14:29:46, 12.32s/it] 19%|â–ˆâ–Š        | 962/5198 [3:22:55<15:17:11, 12.99s/it]                                                       {'loss': 0.9009, 'learning_rate': 1.8765227166330933e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 962/5198 [3:22:56<15:17:11, 12.99s/it] 19%|â–ˆâ–Š        | 963/5198 [3:23:07<14:51:49, 12.63s/it]                                                       {'loss': 0.8896, 'learning_rate': 1.8762226181825857e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 963/5198 [3:23:07<14:51:49, 12.63s/it] 19%|â–ˆâ–Š        | 964/5198 [3:23:19<14:37:13, 12.43s/it]                                                       {'loss': 0.9375, 'learning_rate': 1.875922179552288e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 964/5198 [3:23:19<14:37:13, 12.43s/it] 19%|â–ˆâ–Š        | 965/5198 [3:23:34<15:30:12, 13.19s/it]                                                       {'loss': 0.9192, 'learning_rate': 1.875621400858842e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 965/5198 [3:23:34<15:30:12, 13.19s/it] 19%|â–ˆâ–Š        | 966/5198 [3:23:45<14:49:54, 12.62s/it]                                                       {'loss': 0.8716, 'learning_rate': 1.875320282219019e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 966/5198 [3:23:46<14:49:54, 12.62s/it] 19%|â–ˆâ–Š        | 967/5198 [3:23:58<14:39:02, 12.47s/it]                                                       {'loss': 0.8933, 'learning_rate': 1.8750188237497247e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 967/5198 [3:23:58<14:39:02, 12.47s/it] 19%|â–ˆâ–Š        | 968/5198 [3:24:10<14:31:34, 12.36s/it]                                                       {'loss': 0.8052, 'learning_rate': 1.874717025567995e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 968/5198 [3:24:10<14:31:34, 12.36s/it] 19%|â–ˆâ–Š        | 969/5198 [3:24:21<14:15:22, 12.14s/it]                                                       {'loss': 0.9155, 'learning_rate': 1.874414887790999e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 969/5198 [3:24:21<14:15:22, 12.14s/it] 19%|â–ˆâ–Š        | 970/5198 [3:24:33<14:05:49, 12.00s/it]                                                       {'loss': 0.9198, 'learning_rate': 1.8741124105360363e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 970/5198 [3:24:33<14:05:49, 12.00s/it] 19%|â–ˆâ–Š        | 971/5198 [3:24:45<14:08:22, 12.04s/it]                                                       {'loss': 0.8096, 'learning_rate': 1.873809593920539e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 971/5198 [3:24:45<14:08:22, 12.04s/it] 19%|â–ˆâ–Š        | 972/5198 [3:24:57<14:09:28, 12.06s/it]                                                       {'loss': 0.9226, 'learning_rate': 1.8735064380620717e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 972/5198 [3:24:57<14:09:28, 12.06s/it] 19%|â–ˆâ–Š        | 973/5198 [3:25:14<15:51:13, 13.51s/it]                                                       {'loss': 0.3448, 'learning_rate': 1.873202943078329e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 973/5198 [3:25:14<15:51:13, 13.51s/it] 19%|â–ˆâ–Š        | 974/5198 [3:25:26<15:17:25, 13.03s/it]                                                       {'loss': 0.8739, 'learning_rate': 1.8728991090871387e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 974/5198 [3:25:26<15:17:25, 13.03s/it]