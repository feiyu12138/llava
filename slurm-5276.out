[2024-03-23 15:45:46,564] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:45:48,987] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7: setting --include=localhost:0,1,2,3,4,5,6,7
[2024-03-23 15:45:48,987] [INFO] [runner.py:571:main] cmd = /home/jchen293/.conda/envs/llava_git/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path lmsys/vicuna-7b-v1.5 --version v1 --data_path /datasets/jchen293/data/llava_datasets/LLaVA-Tuning/llava_v1_5_mix665k.json --image_folder /datasets/jchen293/data/llava_datasets/LLaVA-Tuning --vision_tower openai/clip-vit-large-patch14-336 --pretrain_mm_mlp_adapter /datasets/jchen293/weights/llava/checkpoint/llava-v1.5-7b-pretrain-stride-4-layer-16-grouping-avgpool1d/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /datasets/jchen293/weights/llava/checkpoint/llava-v1.5-7b-stride-4-layer-16-grouping-avgpool1d --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb --stride 4 --layer 16 --grouping avgpool1d
[2024-03-23 15:45:50,788] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:45:52,138] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-03-23 15:45:52,138] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-03-23 15:45:52,138] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-03-23 15:45:52,139] [INFO] [launch.py:163:main] dist_world_size=8
[2024-03-23 15:45:52,139] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-03-23 15:46:06,903] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:06,957] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:07,008] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:07,060] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:07,061] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:07,105] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:07,117] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:07,119] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-23 15:46:12,783] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,784] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,787] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,787] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,789] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,791] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,793] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,794] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-23 15:46:12,794] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-03-23 15:46:27,382] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 707, num_elems = 15.36B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.40s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.41s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.45s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.47s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.19s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.37s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.24s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.28s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.20s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.19s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.33s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 17.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.33s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:  50%|█████     | 1/2 [00:39<00:39, 39.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 21.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 23.97s/it]
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
[2024-03-23 15:47:17,070] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 1098, num_elems = 15.67B
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Formatting inputs...Skip in lazy mode
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Parameter Offload: Total persistent parameters: 599040 in 312 params
wandb: Currently logged in as: jienengchen01. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /home/jchen293/code/llava_git/llava/wandb/run-20240323_154940-o4x1dsvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-waterfall-72
wandb: ⭐️ View project at https://wandb.ai/jienengchen01/huggingface
wandb: 🚀 View run at https://wandb.ai/jienengchen01/huggingface/runs/o4x1dsvc
  0%|          | 0/5198 [00:00<?, ?it/s]/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/jchen293/.conda/envs/llava_git/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/5198 [01:08<99:08:43, 68.68s/it]                                                   {'loss': 1.3402, 'learning_rate': 1.282051282051282e-07, 'epoch': 0.0}
  0%|          | 1/5198 [01:08<99:08:43, 68.68s/it]  0%|          | 2/5198 [01:24<53:58:51, 37.40s/it]                                                   {'loss': 1.3505, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
  0%|          | 2/5198 [01:24<53:58:51, 37.40s/it]  0%|          | 3/5198 [01:37<37:52:19, 26.24s/it]                                                   {'loss': 1.347, 'learning_rate': 3.846153846153847e-07, 'epoch': 0.0}
  0%|          | 3/5198 [01:37<37:52:19, 26.24s/it]  0%|          | 4/5198 [01:49<29:56:13, 20.75s/it]                                                   {'loss': 1.3831, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
  0%|          | 4/5198 [01:49<29:56:13, 20.75s/it]  0%|          | 5/5198 [02:01<25:16:14, 17.52s/it]                                                   {'loss': 1.3434, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.0}
  0%|          | 5/5198 [02:01<25:16:14, 17.52s/it]  0%|          | 6/5198 [02:15<23:49:15, 16.52s/it]                                                   {'loss': 1.3762, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
  0%|          | 6/5198 [02:15<23:49:15, 16.52s/it]  0%|          | 7/5198 [02:27<21:41:57, 15.05s/it]                                                   {'loss': 1.3628, 'learning_rate': 8.974358974358975e-07, 'epoch': 0.0}
  0%|          | 7/5198 [02:27<21:41:57, 15.05s/it]  0%|          | 8/5198 [02:39<20:14:39, 14.04s/it]                                                   {'loss': 1.3199, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.0}
  0%|          | 8/5198 [02:39<20:14:39, 14.04s/it]  0%|          | 9/5198 [02:51<19:09:21, 13.29s/it]                                                   {'loss': 1.3591, 'learning_rate': 1.153846153846154e-06, 'epoch': 0.0}
  0%|          | 9/5198 [02:51<19:09:21, 13.29s/it]  0%|          | 10/5198 [03:03<18:45:47, 13.02s/it]                                                    {'loss': 1.2947, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.0}
  0%|          | 10/5198 [03:03<18:45:47, 13.02s/it]  0%|          | 11/5198 [03:15<18:22:13, 12.75s/it]                                                    {'loss': 1.3174, 'learning_rate': 1.4102564102564104e-06, 'epoch': 0.0}
  0%|          | 11/5198 [03:15<18:22:13, 12.75s/it]  0%|          | 12/5198 [03:27<17:49:53, 12.38s/it]                                                    {'loss': 1.3068, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}
  0%|          | 12/5198 [03:27<17:49:53, 12.38s/it]  0%|          | 13/5198 [03:40<18:13:29, 12.65s/it]                                                    {'loss': 1.2483, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.0}
  0%|          | 13/5198 [03:40<18:13:29, 12.65s/it]  0%|          | 14/5198 [03:53<18:15:17, 12.68s/it]                                                    {'loss': 1.1891, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.0}
  0%|          | 14/5198 [03:53<18:15:17, 12.68s/it]  0%|          | 15/5198 [04:05<17:58:24, 12.48s/it]                                                    {'loss': 1.2022, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.0}
  0%|          | 15/5198 [04:05<17:58:24, 12.48s/it]  0%|          | 16/5198 [04:17<17:46:42, 12.35s/it]                                                    {'loss': 1.248, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.0}
  0%|          | 16/5198 [04:17<17:46:42, 12.35s/it]  0%|          | 17/5198 [04:30<18:08:03, 12.60s/it]                                                    {'loss': 1.1541, 'learning_rate': 2.1794871794871797e-06, 'epoch': 0.0}
  0%|          | 17/5198 [04:30<18:08:03, 12.60s/it]  0%|          | 18/5198 [04:42<17:41:06, 12.29s/it]                                                    {'loss': 1.1338, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.0}
  0%|          | 18/5198 [04:42<17:41:06, 12.29s/it]  0%|          | 19/5198 [04:55<17:57:46, 12.49s/it]                                                    {'loss': 1.1902, 'learning_rate': 2.435897435897436e-06, 'epoch': 0.0}
  0%|          | 19/5198 [04:55<17:57:46, 12.49s/it]  0%|          | 20/5198 [05:08<18:14:17, 12.68s/it]                                                    {'loss': 1.0876, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.0}
  0%|          | 20/5198 [05:08<18:14:17, 12.68s/it]  0%|          | 21/5198 [05:19<17:43:48, 12.33s/it]                                                    {'loss': 1.1749, 'learning_rate': 2.6923076923076923e-06, 'epoch': 0.0}
  0%|          | 21/5198 [05:19<17:43:48, 12.33s/it]  0%|          | 22/5198 [05:32<17:55:10, 12.46s/it]                                                    {'loss': 1.1326, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.0}
  0%|          | 22/5198 [05:32<17:55:10, 12.46s/it]  0%|          | 23/5198 [05:45<17:54:39, 12.46s/it]                                                    {'loss': 1.0539, 'learning_rate': 2.948717948717949e-06, 'epoch': 0.0}
  0%|          | 23/5198 [05:45<17:54:39, 12.46s/it]  0%|          | 24/5198 [05:56<17:37:59, 12.27s/it]                                                    {'loss': 1.1554, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.0}
  0%|          | 24/5198 [05:57<17:37:59, 12.27s/it]  0%|          | 25/5198 [06:09<17:53:13, 12.45s/it]                                                    {'loss': 1.1092, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.0}
  0%|          | 25/5198 [06:09<17:53:13, 12.45s/it]  1%|          | 26/5198 [06:22<18:02:41, 12.56s/it]                                                    {'loss': 1.096, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}
  1%|          | 26/5198 [06:22<18:02:41, 12.56s/it]  1%|          | 27/5198 [06:35<18:03:53, 12.58s/it]                                                    {'loss': 1.0987, 'learning_rate': 3.4615384615384617e-06, 'epoch': 0.01}
  1%|          | 27/5198 [06:35<18:03:53, 12.58s/it]  1%|          | 28/5198 [06:46<17:26:42, 12.15s/it]                                                    {'loss': 1.0949, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.01}
  1%|          | 28/5198 [06:46<17:26:42, 12.15s/it]  1%|          | 29/5198 [07:01<18:48:39, 13.10s/it]                                                    {'loss': 1.0499, 'learning_rate': 3.7179487179487184e-06, 'epoch': 0.01}
  1%|          | 29/5198 [07:01<18:48:39, 13.10s/it]  1%|          | 30/5198 [07:13<18:16:35, 12.73s/it]                                                    {'loss': 1.0527, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.01}
  1%|          | 30/5198 [07:13<18:16:35, 12.73s/it]  1%|          | 31/5198 [07:25<17:45:40, 12.37s/it]                                                    {'loss': 1.0969, 'learning_rate': 3.974358974358974e-06, 'epoch': 0.01}
  1%|          | 31/5198 [07:25<17:45:40, 12.37s/it]  1%|          | 32/5198 [07:37<17:51:58, 12.45s/it]                                                    {'loss': 1.0227, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.01}
  1%|          | 32/5198 [07:37<17:51:58, 12.45s/it]  1%|          | 33/5198 [07:51<18:27:48, 12.87s/it]                                                    {'loss': 1.0494, 'learning_rate': 4.230769230769231e-06, 'epoch': 0.01}
  1%|          | 33/5198 [07:51<18:27:48, 12.87s/it]  1%|          | 34/5198 [08:03<18:06:31, 12.62s/it]                                                    {'loss': 1.0306, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.01}
  1%|          | 34/5198 [08:03<18:06:31, 12.62s/it]  1%|          | 35/5198 [08:18<18:50:30, 13.14s/it]                                                    {'loss': 1.005, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.01}
  1%|          | 35/5198 [08:18<18:50:30, 13.14s/it]  1%|          | 36/5198 [08:29<18:13:07, 12.71s/it]                                                    {'loss': 1.0363, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.01}
  1%|          | 36/5198 [08:29<18:13:07, 12.71s/it][2024-03-23 15:58:44,122] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 37/5198 [08:46<19:46:37, 13.80s/it]                                                    {'loss': 0.304, 'learning_rate': 4.743589743589744e-06, 'epoch': 0.01}
  1%|          | 37/5198 [08:46<19:46:37, 13.80s/it]  1%|          | 38/5198 [09:01<20:29:13, 14.29s/it]                                                    {'loss': 1.059, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.01}
  1%|          | 38/5198 [09:01<20:29:13, 14.29s/it]  1%|          | 39/5198 [09:13<19:29:12, 13.60s/it]                                                    {'loss': 1.0517, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 39/5198 [09:13<19:29:12, 13.60s/it]  1%|          | 40/5198 [09:25<18:45:50, 13.10s/it]                                                    {'loss': 1.025, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.01}
  1%|          | 40/5198 [09:25<18:45:50, 13.10s/it]  1%|          | 41/5198 [09:37<18:32:42, 12.95s/it]                                                    {'loss': 1.0213, 'learning_rate': 5.256410256410257e-06, 'epoch': 0.01}
  1%|          | 41/5198 [09:38<18:32:42, 12.95s/it]  1%|          | 42/5198 [09:49<17:59:44, 12.56s/it]                                                    {'loss': 1.0776, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.01}
  1%|          | 42/5198 [09:49<17:59:44, 12.56s/it]  1%|          | 43/5198 [10:01<17:38:22, 12.32s/it]                                                    {'loss': 0.9718, 'learning_rate': 5.512820512820514e-06, 'epoch': 0.01}
  1%|          | 43/5198 [10:01<17:38:22, 12.32s/it]  1%|          | 44/5198 [10:14<17:56:03, 12.53s/it]                                                    {'loss': 1.0382, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.01}
  1%|          | 44/5198 [10:14<17:56:03, 12.53s/it]  1%|          | 45/5198 [10:26<17:41:59, 12.37s/it]                                                    {'loss': 1.0407, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.01}
  1%|          | 45/5198 [10:26<17:41:59, 12.37s/it]  1%|          | 46/5198 [10:39<17:49:22, 12.45s/it]                                                    {'loss': 0.9967, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.01}
  1%|          | 46/5198 [10:39<17:49:22, 12.45s/it]  1%|          | 47/5198 [10:51<17:55:10, 12.52s/it]                                                    {'loss': 0.98, 'learning_rate': 6.025641025641026e-06, 'epoch': 0.01}
  1%|          | 47/5198 [10:51<17:55:10, 12.52s/it]  1%|          | 48/5198 [11:03<17:44:33, 12.40s/it]                                                    {'loss': 0.9794, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.01}
  1%|          | 48/5198 [11:03<17:44:33, 12.40s/it]  1%|          | 49/5198 [11:16<17:42:12, 12.38s/it]                                                    {'loss': 0.9811, 'learning_rate': 6.282051282051282e-06, 'epoch': 0.01}
  1%|          | 49/5198 [11:16<17:42:12, 12.38s/it]  1%|          | 50/5198 [11:29<18:13:21, 12.74s/it]                                                    {'loss': 0.9725, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.01}
  1%|          | 50/5198 [11:29<18:13:21, 12.74s/it]  1%|          | 51/5198 [11:42<18:17:56, 12.80s/it]                                                    {'loss': 1.0121, 'learning_rate': 6.538461538461539e-06, 'epoch': 0.01}
  1%|          | 51/5198 [11:42<18:17:56, 12.80s/it]  1%|          | 52/5198 [11:54<18:00:41, 12.60s/it]                                                    {'loss': 1.009, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}
  1%|          | 52/5198 [11:54<18:00:41, 12.60s/it]  1%|          | 53/5198 [12:06<17:40:34, 12.37s/it]                                                    {'loss': 0.9902, 'learning_rate': 6.794871794871796e-06, 'epoch': 0.01}
  1%|          | 53/5198 [12:06<17:40:34, 12.37s/it]  1%|          | 54/5198 [12:19<17:46:31, 12.44s/it]                                                    {'loss': 0.9778, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.01}
  1%|          | 54/5198 [12:19<17:46:31, 12.44s/it]  1%|          | 55/5198 [12:31<17:46:38, 12.44s/it]                                                    {'loss': 1.0078, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.01}
  1%|          | 55/5198 [12:31<17:46:38, 12.44s/it][2024-03-23 16:02:47,052] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  1%|          | 56/5198 [12:48<19:49:02, 13.87s/it]                                                    {'loss': 0.3157, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.01}
  1%|          | 56/5198 [12:49<19:49:02, 13.87s/it]  1%|          | 57/5198 [13:01<19:10:07, 13.42s/it]                                                    {'loss': 0.9782, 'learning_rate': 7.307692307692308e-06, 'epoch': 0.01}
  1%|          | 57/5198 [13:01<19:10:07, 13.42s/it]  1%|          | 58/5198 [13:13<18:30:15, 12.96s/it]                                                    {'loss': 1.0147, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.01}
  1%|          | 58/5198 [13:13<18:30:15, 12.96s/it]  1%|          | 59/5198 [13:25<18:01:26, 12.63s/it]                                                    {'loss': 1.0303, 'learning_rate': 7.564102564102564e-06, 'epoch': 0.01}
  1%|          | 59/5198 [13:25<18:01:26, 12.63s/it]  1%|          | 60/5198 [13:39<18:35:24, 13.03s/it]                                                    {'loss': 0.9975, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.01}
  1%|          | 60/5198 [13:39<18:35:24, 13.03s/it]  1%|          | 61/5198 [13:52<18:45:41, 13.15s/it]                                                    {'loss': 0.9596, 'learning_rate': 7.820512820512822e-06, 'epoch': 0.01}
  1%|          | 61/5198 [13:52<18:45:41, 13.15s/it]  1%|          | 62/5198 [14:04<18:19:33, 12.85s/it]                                                    {'loss': 0.9759, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.01}
  1%|          | 62/5198 [14:04<18:19:33, 12.85s/it]  1%|          | 63/5198 [14:18<18:46:06, 13.16s/it]                                                    {'loss': 0.9186, 'learning_rate': 8.076923076923077e-06, 'epoch': 0.01}
  1%|          | 63/5198 [14:18<18:46:06, 13.16s/it]  1%|          | 64/5198 [14:30<18:21:05, 12.87s/it]                                                    {'loss': 0.9977, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.01}
  1%|          | 64/5198 [14:30<18:21:05, 12.87s/it]  1%|▏         | 65/5198 [14:44<18:58:16, 13.31s/it]                                                    {'loss': 0.984, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.01}
  1%|▏         | 65/5198 [14:45<18:58:16, 13.31s/it]  1%|▏         | 66/5198 [14:59<19:17:54, 13.54s/it]                                                    {'loss': 0.9623, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.01}
  1%|▏         | 66/5198 [14:59<19:17:54, 13.54s/it]  1%|▏         | 67/5198 [15:11<18:37:36, 13.07s/it]                                                    {'loss': 0.8904, 'learning_rate': 8.58974358974359e-06, 'epoch': 0.01}
  1%|▏         | 67/5198 [15:11<18:37:36, 13.07s/it]  1%|▏         | 68/5198 [15:23<18:12:48, 12.78s/it]                                                    {'loss': 0.9795, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.01}
  1%|▏         | 68/5198 [15:23<18:12:48, 12.78s/it]  1%|▏         | 69/5198 [15:35<18:13:44, 12.79s/it]                                                    {'loss': 0.9736, 'learning_rate': 8.846153846153847e-06, 'epoch': 0.01}
  1%|▏         | 69/5198 [15:36<18:13:44, 12.79s/it]  1%|▏         | 70/5198 [15:48<18:02:49, 12.67s/it]                                                    {'loss': 0.9634, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.01}
  1%|▏         | 70/5198 [15:48<18:02:49, 12.67s/it]  1%|▏         | 71/5198 [16:01<18:02:31, 12.67s/it]                                                    {'loss': 0.9472, 'learning_rate': 9.102564102564104e-06, 'epoch': 0.01}
  1%|▏         | 71/5198 [16:01<18:02:31, 12.67s/it]  1%|▏         | 72/5198 [16:14<18:17:07, 12.84s/it]                                                    {'loss': 0.91, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.01}
  1%|▏         | 72/5198 [16:14<18:17:07, 12.84s/it]  1%|▏         | 73/5198 [16:26<17:56:09, 12.60s/it]                                                    {'loss': 0.9905, 'learning_rate': 9.358974358974359e-06, 'epoch': 0.01}
  1%|▏         | 73/5198 [16:26<17:56:09, 12.60s/it]  1%|▏         | 74/5198 [16:37<17:26:30, 12.25s/it]                                                    {'loss': 0.944, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.01}
  1%|▏         | 74/5198 [16:37<17:26:30, 12.25s/it]  1%|▏         | 75/5198 [16:50<17:37:20, 12.38s/it]                                                    {'loss': 0.9305, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.01}
  1%|▏         | 75/5198 [16:50<17:37:20, 12.38s/it]  1%|▏         | 76/5198 [17:02<17:31:12, 12.31s/it]                                                    {'loss': 0.9374, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.01}
  1%|▏         | 76/5198 [17:02<17:31:12, 12.31s/it]  1%|▏         | 77/5198 [17:15<17:40:11, 12.42s/it]                                                    {'loss': 0.9061, 'learning_rate': 9.871794871794872e-06, 'epoch': 0.01}
  1%|▏         | 77/5198 [17:15<17:40:11, 12.42s/it]  2%|▏         | 78/5198 [17:27<17:35:49, 12.37s/it]                                                    {'loss': 0.9778, 'learning_rate': 1e-05, 'epoch': 0.02}
  2%|▏         | 78/5198 [17:27<17:35:49, 12.37s/it]  2%|▏         | 79/5198 [17:40<17:42:19, 12.45s/it]                                                    {'loss': 1.0187, 'learning_rate': 1.012820512820513e-05, 'epoch': 0.02}
  2%|▏         | 79/5198 [17:40<17:42:19, 12.45s/it]  2%|▏         | 80/5198 [17:52<17:30:24, 12.31s/it]                                                    {'loss': 0.9573, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.02}
  2%|▏         | 80/5198 [17:52<17:30:24, 12.31s/it]  2%|▏         | 81/5198 [18:04<17:18:17, 12.17s/it]                                                    {'loss': 1.0061, 'learning_rate': 1.0384615384615386e-05, 'epoch': 0.02}
  2%|▏         | 81/5198 [18:04<17:18:17, 12.17s/it]  2%|▏         | 82/5198 [18:16<17:28:26, 12.30s/it]                                                    {'loss': 1.0302, 'learning_rate': 1.0512820512820514e-05, 'epoch': 0.02}
  2%|▏         | 82/5198 [18:16<17:28:26, 12.30s/it]  2%|▏         | 83/5198 [18:28<17:08:51, 12.07s/it]                                                    {'loss': 1.0214, 'learning_rate': 1.0641025641025643e-05, 'epoch': 0.02}
  2%|▏         | 83/5198 [18:28<17:08:51, 12.07s/it]  2%|▏         | 84/5198 [18:40<17:20:55, 12.21s/it]                                                    {'loss': 0.9679, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.02}
  2%|▏         | 84/5198 [18:40<17:20:55, 12.21s/it]  2%|▏         | 85/5198 [18:52<17:23:16, 12.24s/it]                                                    {'loss': 0.9463, 'learning_rate': 1.0897435897435898e-05, 'epoch': 0.02}
  2%|▏         | 85/5198 [18:53<17:23:16, 12.24s/it]  2%|▏         | 86/5198 [19:04<17:05:46, 12.04s/it]                                                    {'loss': 0.9444, 'learning_rate': 1.1025641025641028e-05, 'epoch': 0.02}
  2%|▏         | 86/5198 [19:04<17:05:46, 12.04s/it]  2%|▏         | 87/5198 [19:16<17:03:50, 12.02s/it]                                                    {'loss': 0.9976, 'learning_rate': 1.1153846153846154e-05, 'epoch': 0.02}
  2%|▏         | 87/5198 [19:16<17:03:50, 12.02s/it]  2%|▏         | 88/5198 [19:31<18:15:33, 12.86s/it]                                                    {'loss': 0.965, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.02}
  2%|▏         | 88/5198 [19:31<18:15:33, 12.86s/it]  2%|▏         | 89/5198 [19:48<19:56:19, 14.05s/it]                                                    {'loss': 0.2929, 'learning_rate': 1.1410256410256411e-05, 'epoch': 0.02}
  2%|▏         | 89/5198 [19:48<19:56:19, 14.05s/it]  2%|▏         | 90/5198 [19:59<18:52:05, 13.30s/it]                                                    {'loss': 0.91, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.02}
  2%|▏         | 90/5198 [19:59<18:52:05, 13.30s/it]  2%|▏         | 91/5198 [20:11<18:23:24, 12.96s/it]                                                    {'loss': 0.9775, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.02}
  2%|▏         | 91/5198 [20:11<18:23:24, 12.96s/it]  2%|▏         | 92/5198 [20:24<18:06:51, 12.77s/it]                                                    {'loss': 0.9846, 'learning_rate': 1.1794871794871796e-05, 'epoch': 0.02}
  2%|▏         | 92/5198 [20:24<18:06:51, 12.77s/it]  2%|▏         | 93/5198 [20:36<18:06:28, 12.77s/it]                                                    {'loss': 0.9885, 'learning_rate': 1.1923076923076925e-05, 'epoch': 0.02}
  2%|▏         | 93/5198 [20:37<18:06:28, 12.77s/it]  2%|▏         | 94/5198 [20:48<17:37:43, 12.43s/it]                                                    {'loss': 0.9436, 'learning_rate': 1.2051282051282051e-05, 'epoch': 0.02}
  2%|▏         | 94/5198 [20:48<17:37:43, 12.43s/it]  2%|▏         | 95/5198 [21:05<19:29:25, 13.75s/it]                                                    {'loss': 0.3076, 'learning_rate': 1.217948717948718e-05, 'epoch': 0.02}
  2%|▏         | 95/5198 [21:05<19:29:25, 13.75s/it]  2%|▏         | 96/5198 [21:17<18:51:54, 13.31s/it]                                                    {'loss': 0.9523, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.02}
  2%|▏         | 96/5198 [21:17<18:51:54, 13.31s/it]  2%|▏         | 97/5198 [21:31<18:51:15, 13.31s/it]                                                    {'loss': 0.9534, 'learning_rate': 1.2435897435897436e-05, 'epoch': 0.02}
  2%|▏         | 97/5198 [21:31<18:51:15, 13.31s/it]  2%|▏         | 98/5198 [21:45<19:29:50, 13.76s/it]                                                    {'loss': 0.9785, 'learning_rate': 1.2564102564102565e-05, 'epoch': 0.02}
  2%|▏         | 98/5198 [21:45<19:29:50, 13.76s/it]  2%|▏         | 99/5198 [21:59<19:30:39, 13.78s/it]                                                    {'loss': 0.8897, 'learning_rate': 1.2692307692307693e-05, 'epoch': 0.02}
  2%|▏         | 99/5198 [21:59<19:30:39, 13.78s/it]  2%|▏         | 100/5198 [22:16<20:50:25, 14.72s/it]                                                     {'loss': 0.2937, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.02}
  2%|▏         | 100/5198 [22:16<20:50:25, 14.72s/it]  2%|▏         | 101/5198 [22:28<19:42:56, 13.93s/it]                                                     {'loss': 0.9362, 'learning_rate': 1.294871794871795e-05, 'epoch': 0.02}
  2%|▏         | 101/5198 [22:28<19:42:56, 13.93s/it]  2%|▏         | 102/5198 [22:40<18:44:06, 13.24s/it]                                                     {'loss': 1.0475, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.02}
  2%|▏         | 102/5198 [22:40<18:44:06, 13.24s/it]  2%|▏         | 103/5198 [22:54<19:11:18, 13.56s/it]                                                     {'loss': 0.9789, 'learning_rate': 1.3205128205128207e-05, 'epoch': 0.02}
  2%|▏         | 103/5198 [22:54<19:11:18, 13.56s/it]  2%|▏         | 104/5198 [23:10<19:58:09, 14.11s/it]                                                     {'loss': 0.9677, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}
  2%|▏         | 104/5198 [23:10<19:58:09, 14.11s/it]  2%|▏         | 105/5198 [23:26<20:57:54, 14.82s/it]                                                     {'loss': 0.2652, 'learning_rate': 1.3461538461538463e-05, 'epoch': 0.02}
  2%|▏         | 105/5198 [23:26<20:57:54, 14.82s/it]  2%|▏         | 106/5198 [23:38<19:57:36, 14.11s/it]                                                     {'loss': 0.9444, 'learning_rate': 1.3589743589743592e-05, 'epoch': 0.02}
  2%|▏         | 106/5198 [23:39<19:57:36, 14.11s/it]  2%|▏         | 107/5198 [23:50<18:44:13, 13.25s/it]                                                     {'loss': 1.0147, 'learning_rate': 1.3717948717948718e-05, 'epoch': 0.02}
  2%|▏         | 107/5198 [23:50<18:44:13, 13.25s/it]  2%|▏         | 108/5198 [24:02<18:09:38, 12.84s/it]                                                     {'loss': 0.9428, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.02}
  2%|▏         | 108/5198 [24:02<18:09:38, 12.84s/it]  2%|▏         | 109/5198 [24:14<17:54:10, 12.66s/it]                                                     {'loss': 0.9745, 'learning_rate': 1.3974358974358975e-05, 'epoch': 0.02}
  2%|▏         | 109/5198 [24:14<17:54:10, 12.66s/it]  2%|▏         | 110/5198 [24:26<17:47:40, 12.59s/it]                                                     {'loss': 0.9626, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.02}
  2%|▏         | 110/5198 [24:26<17:47:40, 12.59s/it]  2%|▏         | 111/5198 [24:38<17:32:04, 12.41s/it]                                                     {'loss': 0.9439, 'learning_rate': 1.4230769230769232e-05, 'epoch': 0.02}
  2%|▏         | 111/5198 [24:38<17:32:04, 12.41s/it]  2%|▏         | 112/5198 [24:51<17:29:48, 12.38s/it]                                                     {'loss': 1.0296, 'learning_rate': 1.435897435897436e-05, 'epoch': 0.02}
  2%|▏         | 112/5198 [24:51<17:29:48, 12.38s/it]  2%|▏         | 113/5198 [25:04<17:48:48, 12.61s/it]                                                     {'loss': 0.9344, 'learning_rate': 1.4487179487179489e-05, 'epoch': 0.02}
  2%|▏         | 113/5198 [25:04<17:48:48, 12.61s/it]  2%|▏         | 114/5198 [25:16<17:33:37, 12.43s/it]                                                     {'loss': 0.9641, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.02}
  2%|▏         | 114/5198 [25:16<17:33:37, 12.43s/it]  2%|▏         | 115/5198 [25:28<17:32:03, 12.42s/it]                                                     {'loss': 0.9597, 'learning_rate': 1.4743589743589745e-05, 'epoch': 0.02}
  2%|▏         | 115/5198 [25:28<17:32:03, 12.42s/it]  2%|▏         | 116/5198 [25:45<19:27:07, 13.78s/it]                                                     {'loss': 0.2956, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.02}
  2%|▏         | 116/5198 [25:45<19:27:07, 13.78s/it]  2%|▏         | 117/5198 [25:58<19:17:51, 13.67s/it]                                                     {'loss': 0.9819, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.02}
  2%|▏         | 117/5198 [25:59<19:17:51, 13.67s/it]  2%|▏         | 118/5198 [26:10<18:24:34, 13.05s/it]                                                     {'loss': 0.9454, 'learning_rate': 1.5128205128205129e-05, 'epoch': 0.02}
  2%|▏         | 118/5198 [26:10<18:24:34, 13.05s/it]  2%|▏         | 119/5198 [26:22<18:04:16, 12.81s/it]                                                     {'loss': 1.0562, 'learning_rate': 1.5256410256410257e-05, 'epoch': 0.02}
  2%|▏         | 119/5198 [26:22<18:04:16, 12.81s/it]  2%|▏         | 120/5198 [26:36<18:38:20, 13.21s/it]                                                     {'loss': 0.934, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.02}
  2%|▏         | 120/5198 [26:37<18:38:20, 13.21s/it]  2%|▏         | 121/5198 [26:50<18:43:53, 13.28s/it]                                                     {'loss': 0.9917, 'learning_rate': 1.5512820512820516e-05, 'epoch': 0.02}
  2%|▏         | 121/5198 [26:50<18:43:53, 13.28s/it]  2%|▏         | 122/5198 [27:03<18:48:16, 13.34s/it]                                                     {'loss': 1.0131, 'learning_rate': 1.5641025641025644e-05, 'epoch': 0.02}
  2%|▏         | 122/5198 [27:03<18:48:16, 13.34s/it]  2%|▏         | 123/5198 [27:17<19:01:31, 13.50s/it]                                                     {'loss': 0.9071, 'learning_rate': 1.576923076923077e-05, 'epoch': 0.02}
  2%|▏         | 123/5198 [27:17<19:01:31, 13.50s/it]  2%|▏         | 124/5198 [27:30<18:45:23, 13.31s/it]                                                     {'loss': 0.9441, 'learning_rate': 1.5897435897435897e-05, 'epoch': 0.02}
  2%|▏         | 124/5198 [27:30<18:45:23, 13.31s/it]  2%|▏         | 125/5198 [27:43<18:33:43, 13.17s/it]                                                     {'loss': 0.966, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.02}
  2%|▏         | 125/5198 [27:43<18:33:43, 13.17s/it]  2%|▏         | 126/5198 [27:55<18:00:08, 12.78s/it]                                                     {'loss': 0.9479, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.02}
  2%|▏         | 126/5198 [27:55<18:00:08, 12.78s/it]  2%|▏         | 127/5198 [28:06<17:26:32, 12.38s/it]                                                     {'loss': 0.9968, 'learning_rate': 1.6282051282051282e-05, 'epoch': 0.02}
  2%|▏         | 127/5198 [28:06<17:26:32, 12.38s/it]  2%|▏         | 128/5198 [28:19<17:44:44, 12.60s/it]                                                     {'loss': 0.8559, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.02}
  2%|▏         | 128/5198 [28:19<17:44:44, 12.60s/it]  2%|▏         | 129/5198 [28:32<17:50:04, 12.67s/it]                                                     {'loss': 0.9291, 'learning_rate': 1.653846153846154e-05, 'epoch': 0.02}
  2%|▏         | 129/5198 [28:32<17:50:04, 12.67s/it]  3%|▎         | 130/5198 [28:44<17:26:45, 12.39s/it]                                                     {'loss': 0.9523, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
  3%|▎         | 130/5198 [28:44<17:26:45, 12.39s/it]  3%|▎         | 131/5198 [28:57<17:30:39, 12.44s/it]                                                     {'loss': 0.969, 'learning_rate': 1.6794871794871796e-05, 'epoch': 0.03}
  3%|▎         | 131/5198 [28:57<17:30:39, 12.44s/it]  3%|▎         | 132/5198 [29:11<18:14:03, 12.96s/it]                                                     {'loss': 0.9121, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.03}
  3%|▎         | 132/5198 [29:11<18:14:03, 12.96s/it]  3%|▎         | 133/5198 [29:23<18:04:32, 12.85s/it]                                                     {'loss': 0.911, 'learning_rate': 1.7051282051282053e-05, 'epoch': 0.03}
  3%|▎         | 133/5198 [29:23<18:04:32, 12.85s/it]  3%|▎         | 134/5198 [29:36<17:58:35, 12.78s/it]                                                     {'loss': 0.9425, 'learning_rate': 1.717948717948718e-05, 'epoch': 0.03}
  3%|▎         | 134/5198 [29:36<17:58:35, 12.78s/it]  3%|▎         | 135/5198 [29:48<17:40:25, 12.57s/it]                                                     {'loss': 0.9263, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.03}
  3%|▎         | 135/5198 [29:48<17:40:25, 12.57s/it]  3%|▎         | 136/5198 [30:03<18:50:00, 13.39s/it]                                                     {'loss': 0.9035, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.03}
  3%|▎         | 136/5198 [30:03<18:50:00, 13.39s/it]  3%|▎         | 137/5198 [30:16<18:22:08, 13.07s/it]                                                     {'loss': 0.9858, 'learning_rate': 1.7564102564102566e-05, 'epoch': 0.03}
  3%|▎         | 137/5198 [30:16<18:22:08, 13.07s/it]  3%|▎         | 138/5198 [30:29<18:25:44, 13.11s/it]                                                     {'loss': 0.9983, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.03}
  3%|▎         | 138/5198 [30:29<18:25:44, 13.11s/it]  3%|▎         | 139/5198 [30:41<18:11:59, 12.95s/it]                                                     {'loss': 0.928, 'learning_rate': 1.7820512820512823e-05, 'epoch': 0.03}
  3%|▎         | 139/5198 [30:41<18:11:59, 12.95s/it]  3%|▎         | 140/5198 [30:53<17:41:17, 12.59s/it]                                                     {'loss': 0.9978, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.03}
  3%|▎         | 140/5198 [30:53<17:41:17, 12.59s/it]  3%|▎         | 141/5198 [31:06<17:56:49, 12.78s/it]                                                     {'loss': 0.9656, 'learning_rate': 1.807692307692308e-05, 'epoch': 0.03}
  3%|▎         | 141/5198 [31:06<17:56:49, 12.78s/it]  3%|▎         | 142/5198 [31:20<18:12:06, 12.96s/it]                                                     {'loss': 0.9685, 'learning_rate': 1.8205128205128208e-05, 'epoch': 0.03}
  3%|▎         | 142/5198 [31:20<18:12:06, 12.96s/it]  3%|▎         | 143/5198 [31:31<17:34:37, 12.52s/it]                                                     {'loss': 0.9932, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.03}
  3%|▎         | 143/5198 [31:31<17:34:37, 12.52s/it]  3%|▎         | 144/5198 [31:44<17:47:15, 12.67s/it]                                                     {'loss': 0.9721, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.03}
  3%|▎         | 144/5198 [31:44<17:47:15, 12.67s/it]  3%|▎         | 145/5198 [31:56<17:25:10, 12.41s/it]                                                     {'loss': 0.9542, 'learning_rate': 1.8589743589743593e-05, 'epoch': 0.03}
  3%|▎         | 145/5198 [31:56<17:25:10, 12.41s/it]  3%|▎         | 146/5198 [32:09<17:29:06, 12.46s/it]                                                     {'loss': 0.9597, 'learning_rate': 1.8717948717948718e-05, 'epoch': 0.03}
  3%|▎         | 146/5198 [32:09<17:29:06, 12.46s/it]  3%|▎         | 147/5198 [32:21<17:27:05, 12.44s/it]                                                     {'loss': 0.9252, 'learning_rate': 1.8846153846153846e-05, 'epoch': 0.03}
  3%|▎         | 147/5198 [32:21<17:27:05, 12.44s/it]  3%|▎         | 148/5198 [32:33<17:07:57, 12.21s/it]                                                     {'loss': 0.9305, 'learning_rate': 1.8974358974358975e-05, 'epoch': 0.03}
  3%|▎         | 148/5198 [32:33<17:07:57, 12.21s/it]  3%|▎         | 149/5198 [32:45<17:02:46, 12.15s/it]                                                     {'loss': 0.9428, 'learning_rate': 1.9102564102564106e-05, 'epoch': 0.03}
  3%|▎         | 149/5198 [32:45<17:02:46, 12.15s/it]  3%|▎         | 150/5198 [32:57<17:09:13, 12.23s/it]                                                     {'loss': 0.9346, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.03}
  3%|▎         | 150/5198 [32:57<17:09:13, 12.23s/it]  3%|▎         | 151/5198 [33:11<18:02:26, 12.87s/it]                                                     {'loss': 0.9855, 'learning_rate': 1.935897435897436e-05, 'epoch': 0.03}
  3%|▎         | 151/5198 [33:12<18:02:26, 12.87s/it]  3%|▎         | 152/5198 [33:29<19:52:06, 14.17s/it]                                                     {'loss': 0.2926, 'learning_rate': 1.9487179487179488e-05, 'epoch': 0.03}
  3%|▎         | 152/5198 [33:29<19:52:06, 14.17s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 2048). Running this sequence through the model will result in indexing errors
  3%|▎         | 153/5198 [33:41<19:07:31, 13.65s/it]                                                     {'loss': 0.9854, 'learning_rate': 1.9615384615384617e-05, 'epoch': 0.03}
  3%|▎         | 153/5198 [33:41<19:07:31, 13.65s/it]  3%|▎         | 154/5198 [33:53<18:23:21, 13.12s/it]                                                     {'loss': 0.8991, 'learning_rate': 1.9743589743589745e-05, 'epoch': 0.03}
  3%|▎         | 154/5198 [33:53<18:23:21, 13.12s/it]  3%|▎         | 155/5198 [34:05<17:50:29, 12.74s/it]                                                     {'loss': 0.9009, 'learning_rate': 1.9871794871794873e-05, 'epoch': 0.03}
  3%|▎         | 155/5198 [34:05<17:50:29, 12.74s/it]  3%|▎         | 156/5198 [34:17<17:38:00, 12.59s/it]                                                     {'loss': 1.0149, 'learning_rate': 2e-05, 'epoch': 0.03}
  3%|▎         | 156/5198 [34:17<17:38:00, 12.59s/it]  3%|▎         | 157/5198 [34:29<17:27:38, 12.47s/it]                                                     {'loss': 0.9652, 'learning_rate': 1.9999998058827844e-05, 'epoch': 0.03}
  3%|▎         | 157/5198 [34:29<17:27:38, 12.47s/it]  3%|▎         | 158/5198 [34:41<17:20:13, 12.38s/it]                                                     {'loss': 0.9844, 'learning_rate': 1.9999992235312136e-05, 'epoch': 0.03}
  3%|▎         | 158/5198 [34:42<17:20:13, 12.38s/it]  3%|▎         | 159/5198 [34:54<17:30:22, 12.51s/it]                                                     {'loss': 0.9346, 'learning_rate': 1.9999982529455127e-05, 'epoch': 0.03}
  3%|▎         | 159/5198 [34:54<17:30:22, 12.51s/it]  3%|▎         | 160/5198 [35:07<17:39:52, 12.62s/it]                                                     {'loss': 0.9445, 'learning_rate': 1.9999968941260596e-05, 'epoch': 0.03}
  3%|▎         | 160/5198 [35:07<17:39:52, 12.62s/it]  3%|▎         | 161/5198 [35:20<17:36:24, 12.58s/it]                                                     {'loss': 0.9621, 'learning_rate': 1.9999951470733808e-05, 'epoch': 0.03}
  3%|▎         | 161/5198 [35:20<17:36:24, 12.58s/it]  3%|▎         | 162/5198 [35:35<18:44:41, 13.40s/it]                                                     {'loss': 0.9862, 'learning_rate': 1.9999930117881548e-05, 'epoch': 0.03}
  3%|▎         | 162/5198 [35:35<18:44:41, 13.40s/it]  3%|▎         | 163/5198 [35:48<18:43:38, 13.39s/it]                                                     {'loss': 0.9631, 'learning_rate': 1.9999904882712115e-05, 'epoch': 0.03}
  3%|▎         | 163/5198 [35:48<18:43:38, 13.39s/it]  3%|▎         | 164/5198 [36:05<20:09:42, 14.42s/it]                                                     {'loss': 0.336, 'learning_rate': 1.99998757652353e-05, 'epoch': 0.03}
  3%|▎         | 164/5198 [36:05<20:09:42, 14.42s/it]  3%|▎         | 165/5198 [36:17<19:09:55, 13.71s/it]                                                     {'loss': 0.9554, 'learning_rate': 1.9999842765462403e-05, 'epoch': 0.03}
  3%|▎         | 165/5198 [36:17<19:09:55, 13.71s/it]  3%|▎         | 166/5198 [36:30<18:49:06, 13.46s/it]                                                     {'loss': 0.9654, 'learning_rate': 1.999980588340624e-05, 'epoch': 0.03}
  3%|▎         | 166/5198 [36:30<18:49:06, 13.46s/it]  3%|▎         | 167/5198 [36:42<18:18:50, 13.10s/it]                                                     {'loss': 0.975, 'learning_rate': 1.9999765119081132e-05, 'epoch': 0.03}
  3%|▎         | 167/5198 [36:42<18:18:50, 13.10s/it]  3%|▎         | 168/5198 [36:55<18:16:41, 13.08s/it]                                                     {'loss': 0.9364, 'learning_rate': 1.9999720472502902e-05, 'epoch': 0.03}
  3%|▎         | 168/5198 [36:56<18:16:41, 13.08s/it]  3%|▎         | 169/5198 [37:09<18:30:21, 13.25s/it]                                                     {'loss': 0.9467, 'learning_rate': 1.9999671943688885e-05, 'epoch': 0.03}
  3%|▎         | 169/5198 [37:09<18:30:21, 13.25s/it]  3%|▎         | 170/5198 [37:21<18:00:00, 12.89s/it]                                                     {'loss': 0.9276, 'learning_rate': 1.9999619532657915e-05, 'epoch': 0.03}
  3%|▎         | 170/5198 [37:21<18:00:00, 12.89s/it]  3%|▎         | 171/5198 [37:33<17:32:29, 12.56s/it]                                                     {'loss': 0.839, 'learning_rate': 1.9999563239430352e-05, 'epoch': 0.03}
  3%|▎         | 171/5198 [37:33<17:32:29, 12.56s/it]  3%|▎         | 172/5198 [37:46<17:42:50, 12.69s/it]                                                     {'loss': 0.9822, 'learning_rate': 1.9999503064028043e-05, 'epoch': 0.03}
  3%|▎         | 172/5198 [37:46<17:42:50, 12.69s/it]  3%|▎         | 173/5198 [37:58<17:22:08, 12.44s/it]                                                     {'loss': 0.9359, 'learning_rate': 1.999943900647435e-05, 'epoch': 0.03}
  3%|▎         | 173/5198 [37:58<17:22:08, 12.44s/it]  3%|▎         | 174/5198 [38:11<17:30:20, 12.54s/it]                                                     {'loss': 0.9665, 'learning_rate': 1.9999371066794146e-05, 'epoch': 0.03}
  3%|▎         | 174/5198 [38:11<17:30:20, 12.54s/it]  3%|▎         | 175/5198 [38:23<17:21:54, 12.45s/it]                                                     {'loss': 0.9628, 'learning_rate': 1.9999299245013805e-05, 'epoch': 0.03}
  3%|▎         | 175/5198 [38:23<17:21:54, 12.45s/it]  3%|▎         | 176/5198 [38:35<17:08:55, 12.29s/it]                                                     {'loss': 0.9326, 'learning_rate': 1.999922354116121e-05, 'epoch': 0.03}
  3%|▎         | 176/5198 [38:35<17:08:55, 12.29s/it]  3%|▎         | 177/5198 [38:47<17:01:27, 12.21s/it]                                                     {'loss': 0.9326, 'learning_rate': 1.999914395526575e-05, 'epoch': 0.03}
  3%|▎         | 177/5198 [38:47<17:01:27, 12.21s/it]  3%|▎         | 178/5198 [39:00<17:17:47, 12.40s/it]                                                     {'loss': 0.8987, 'learning_rate': 1.9999060487358333e-05, 'epoch': 0.03}
  3%|▎         | 178/5198 [39:00<17:17:47, 12.40s/it]  3%|▎         | 179/5198 [39:12<17:10:47, 12.32s/it]                                                     {'loss': 0.9718, 'learning_rate': 1.9998973137471352e-05, 'epoch': 0.03}
  3%|▎         | 179/5198 [39:12<17:10:47, 12.32s/it]  3%|▎         | 180/5198 [39:28<19:03:11, 13.67s/it]                                                     {'loss': 0.3037, 'learning_rate': 1.9998881905638727e-05, 'epoch': 0.03}
  3%|▎         | 180/5198 [39:29<19:03:11, 13.67s/it]  3%|▎         | 181/5198 [39:42<18:57:38, 13.61s/it]                                                     {'loss': 0.9336, 'learning_rate': 1.9998786791895874e-05, 'epoch': 0.03}
  3%|▎         | 181/5198 [39:42<18:57:38, 13.61s/it]  4%|▎         | 182/5198 [39:55<18:51:16, 13.53s/it]                                                     {'loss': 1.009, 'learning_rate': 1.999868779627972e-05, 'epoch': 0.04}
  4%|▎         | 182/5198 [39:55<18:51:16, 13.53s/it]  4%|▎         | 183/5198 [40:11<19:36:05, 14.07s/it]                                                     {'loss': 0.925, 'learning_rate': 1.9998584918828695e-05, 'epoch': 0.04}
  4%|▎         | 183/5198 [40:11<19:36:05, 14.07s/it]  4%|▎         | 184/5198 [40:23<18:57:05, 13.61s/it]                                                     {'loss': 0.9327, 'learning_rate': 1.9998478159582747e-05, 'epoch': 0.04}
  4%|▎         | 184/5198 [40:23<18:57:05, 13.61s/it]  4%|▎         | 185/5198 [40:35<18:08:36, 13.03s/it]                                                     {'loss': 0.9894, 'learning_rate': 1.999836751858332e-05, 'epoch': 0.04}
  4%|▎         | 185/5198 [40:35<18:08:36, 13.03s/it]  4%|▎         | 186/5198 [40:47<17:48:52, 12.80s/it]                                                     {'loss': 0.9734, 'learning_rate': 1.9998252995873367e-05, 'epoch': 0.04}
  4%|▎         | 186/5198 [40:47<17:48:52, 12.80s/it]  4%|▎         | 187/5198 [41:05<19:51:16, 14.26s/it]                                                     {'loss': 0.3358, 'learning_rate': 1.999813459149735e-05, 'epoch': 0.04}
  4%|▎         | 187/5198 [41:05<19:51:16, 14.26s/it]  4%|▎         | 188/5198 [41:16<18:41:08, 13.43s/it]                                                     {'loss': 0.9175, 'learning_rate': 1.9998012305501243e-05, 'epoch': 0.04}
  4%|▎         | 188/5198 [41:16<18:41:08, 13.43s/it]  4%|▎         | 189/5198 [41:30<18:44:20, 13.47s/it]                                                     {'loss': 0.8682, 'learning_rate': 1.999788613793251e-05, 'epoch': 0.04}
  4%|▎         | 189/5198 [41:30<18:44:20, 13.47s/it]  4%|▎         | 190/5198 [41:46<19:57:15, 14.34s/it]                                                     {'loss': 0.2967, 'learning_rate': 1.999775608884015e-05, 'epoch': 0.04}
  4%|▎         | 190/5198 [41:46<19:57:15, 14.34s/it]  4%|▎         | 191/5198 [41:59<19:08:27, 13.76s/it]                                                     {'loss': 0.9301, 'learning_rate': 1.9997622158274635e-05, 'epoch': 0.04}
  4%|▎         | 191/5198 [41:59<19:08:27, 13.76s/it]  4%|▎         | 192/5198 [42:11<18:23:10, 13.22s/it]                                                     {'loss': 0.9354, 'learning_rate': 1.9997484346287973e-05, 'epoch': 0.04}
  4%|▎         | 192/5198 [42:11<18:23:10, 13.22s/it]  4%|▎         | 193/5198 [42:23<18:08:35, 13.05s/it]                                                     {'loss': 1.0288, 'learning_rate': 1.9997342652933668e-05, 'epoch': 0.04}
  4%|▎         | 193/5198 [42:23<18:08:35, 13.05s/it]  4%|▎         | 194/5198 [42:37<18:36:58, 13.39s/it]                                                     {'loss': 0.968, 'learning_rate': 1.9997197078266723e-05, 'epoch': 0.04}
  4%|▎         | 194/5198 [42:37<18:36:58, 13.39s/it]  4%|▍         | 195/5198 [42:50<18:22:19, 13.22s/it]                                                     {'loss': 0.9107, 'learning_rate': 1.999704762234366e-05, 'epoch': 0.04}
  4%|▍         | 195/5198 [42:50<18:22:19, 13.22s/it]  4%|▍         | 196/5198 [43:05<19:09:22, 13.79s/it]                                                     {'loss': 0.9798, 'learning_rate': 1.99968942852225e-05, 'epoch': 0.04}
  4%|▍         | 196/5198 [43:05<19:09:22, 13.79s/it]  4%|▍         | 197/5198 [43:18<18:41:28, 13.45s/it]                                                     {'loss': 0.9887, 'learning_rate': 1.9996737066962778e-05, 'epoch': 0.04}
  4%|▍         | 197/5198 [43:18<18:41:28, 13.45s/it]  4%|▍         | 198/5198 [43:30<18:15:31, 13.15s/it]                                                     {'loss': 0.9672, 'learning_rate': 1.9996575967625525e-05, 'epoch': 0.04}
  4%|▍         | 198/5198 [43:30<18:15:31, 13.15s/it]  4%|▍         | 199/5198 [43:43<17:56:52, 12.93s/it]                                                     {'loss': 0.9108, 'learning_rate': 1.999641098727329e-05, 'epoch': 0.04}
  4%|▍         | 199/5198 [43:43<17:56:52, 12.93s/it]  4%|▍         | 200/5198 [43:56<18:14:48, 13.14s/it]                                                     {'loss': 0.9423, 'learning_rate': 1.999624212597013e-05, 'epoch': 0.04}
  4%|▍         | 200/5198 [43:57<18:14:48, 13.14s/it]  4%|▍         | 201/5198 [44:08<17:46:07, 12.80s/it]                                                     {'loss': 0.9926, 'learning_rate': 1.9996069383781587e-05, 'epoch': 0.04}
  4%|▍         | 201/5198 [44:09<17:46:07, 12.80s/it]  4%|▍         | 202/5198 [44:21<17:32:35, 12.64s/it]                                                     {'loss': 0.9954, 'learning_rate': 1.9995892760774738e-05, 'epoch': 0.04}
  4%|▍         | 202/5198 [44:21<17:32:35, 12.64s/it]  4%|▍         | 203/5198 [44:33<17:15:37, 12.44s/it]                                                     {'loss': 0.9748, 'learning_rate': 1.9995712257018153e-05, 'epoch': 0.04}
  4%|▍         | 203/5198 [44:33<17:15:37, 12.44s/it]  4%|▍         | 204/5198 [44:45<17:10:19, 12.38s/it]                                                     {'loss': 0.9148, 'learning_rate': 1.9995527872581903e-05, 'epoch': 0.04}
  4%|▍         | 204/5198 [44:45<17:10:19, 12.38s/it]  4%|▍         | 205/5198 [45:02<18:58:59, 13.69s/it]                                                     {'loss': 0.3267, 'learning_rate': 1.9995339607537578e-05, 'epoch': 0.04}
  4%|▍         | 205/5198 [45:02<18:58:59, 13.69s/it]  4%|▍         | 206/5198 [45:13<18:06:17, 13.06s/it]                                                     {'loss': 0.9312, 'learning_rate': 1.9995147461958267e-05, 'epoch': 0.04}
  4%|▍         | 206/5198 [45:13<18:06:17, 13.06s/it]  4%|▍         | 207/5198 [45:25<17:37:21, 12.71s/it]                                                     {'loss': 0.9429, 'learning_rate': 1.999495143591857e-05, 'epoch': 0.04}
  4%|▍         | 207/5198 [45:25<17:37:21, 12.71s/it]  4%|▍         | 208/5198 [45:40<18:22:22, 13.26s/it]                                                     {'loss': 0.9435, 'learning_rate': 1.999475152949459e-05, 'epoch': 0.04}
  4%|▍         | 208/5198 [45:40<18:22:22, 13.26s/it]  4%|▍         | 209/5198 [45:53<18:14:02, 13.16s/it]                                                     {'loss': 0.9836, 'learning_rate': 1.9994547742763935e-05, 'epoch': 0.04}
  4%|▍         | 209/5198 [45:53<18:14:02, 13.16s/it]  4%|▍         | 210/5198 [46:06<18:23:42, 13.28s/it]                                                     {'loss': 0.9744, 'learning_rate': 1.9994340075805724e-05, 'epoch': 0.04}
  4%|▍         | 210/5198 [46:06<18:23:42, 13.28s/it]  4%|▍         | 211/5198 [46:19<18:02:31, 13.02s/it]                                                     {'loss': 0.9533, 'learning_rate': 1.9994128528700583e-05, 'epoch': 0.04}
  4%|▍         | 211/5198 [46:19<18:02:31, 13.02s/it]  4%|▍         | 212/5198 [46:30<17:32:22, 12.66s/it]                                                     {'loss': 0.8812, 'learning_rate': 1.9993913101530635e-05, 'epoch': 0.04}
  4%|▍         | 212/5198 [46:31<17:32:22, 12.66s/it]  4%|▍         | 213/5198 [46:42<17:15:48, 12.47s/it]                                                     {'loss': 0.9211, 'learning_rate': 1.9993693794379525e-05, 'epoch': 0.04}
  4%|▍         | 213/5198 [46:43<17:15:48, 12.47s/it]  4%|▍         | 214/5198 [46:55<17:17:41, 12.49s/it]                                                     {'loss': 0.9432, 'learning_rate': 1.9993470607332387e-05, 'epoch': 0.04}
  4%|▍         | 214/5198 [46:55<17:17:41, 12.49s/it]  4%|▍         | 215/5198 [47:07<17:08:31, 12.38s/it]                                                     {'loss': 0.9551, 'learning_rate': 1.999324354047588e-05, 'epoch': 0.04}
  4%|▍         | 215/5198 [47:07<17:08:31, 12.38s/it]  4%|▍         | 216/5198 [47:19<16:55:46, 12.23s/it]                                                     {'loss': 0.9678, 'learning_rate': 1.9993012593898146e-05, 'epoch': 0.04}
  4%|▍         | 216/5198 [47:19<16:55:46, 12.23s/it]  4%|▍         | 217/5198 [47:36<18:41:32, 13.51s/it]                                                     {'loss': 0.3018, 'learning_rate': 1.9992777767688857e-05, 'epoch': 0.04}
  4%|▍         | 217/5198 [47:36<18:41:32, 13.51s/it]  4%|▍         | 218/5198 [47:52<20:05:31, 14.52s/it]                                                     {'loss': 0.3288, 'learning_rate': 1.9992539061939175e-05, 'epoch': 0.04}
  4%|▍         | 218/5198 [47:52<20:05:31, 14.52s/it]  4%|▍         | 219/5198 [48:05<19:10:42, 13.87s/it]                                                     {'loss': 1.0004, 'learning_rate': 1.999229647674178e-05, 'epoch': 0.04}
  4%|▍         | 219/5198 [48:05<19:10:42, 13.87s/it]  4%|▍         | 220/5198 [48:22<20:23:10, 14.74s/it]                                                     {'loss': 0.2936, 'learning_rate': 1.9992050012190845e-05, 'epoch': 0.04}
  4%|▍         | 220/5198 [48:22<20:23:10, 14.74s/it]  4%|▍         | 221/5198 [48:36<20:24:11, 14.76s/it]                                                     {'loss': 0.9482, 'learning_rate': 1.9991799668382058e-05, 'epoch': 0.04}
  4%|▍         | 221/5198 [48:36<20:24:11, 14.76s/it]  4%|▍         | 222/5198 [48:49<19:24:34, 14.04s/it]                                                     {'loss': 0.9415, 'learning_rate': 1.9991545445412614e-05, 'epoch': 0.04}
  4%|▍         | 222/5198 [48:49<19:24:34, 14.04s/it]  4%|▍         | 223/5198 [49:05<20:10:21, 14.60s/it]                                                     {'loss': 1.0172, 'learning_rate': 1.9991287343381208e-05, 'epoch': 0.04}
  4%|▍         | 223/5198 [49:05<20:10:21, 14.60s/it]  4%|▍         | 224/5198 [49:16<18:52:57, 13.67s/it]                                                     {'loss': 0.9745, 'learning_rate': 1.9991025362388044e-05, 'epoch': 0.04}
  4%|▍         | 224/5198 [49:16<18:52:57, 13.67s/it]  4%|▍         | 225/5198 [49:28<18:07:38, 13.12s/it]                                                     {'loss': 0.9324, 'learning_rate': 1.9990759502534835e-05, 'epoch': 0.04}
  4%|▍         | 225/5198 [49:28<18:07:38, 13.12s/it]  4%|▍         | 226/5198 [49:45<19:43:10, 14.28s/it]                                                     {'loss': 0.2961, 'learning_rate': 1.9990489763924796e-05, 'epoch': 0.04}
  4%|▍         | 226/5198 [49:45<19:43:10, 14.28s/it]  4%|▍         | 227/5198 [49:57<18:38:39, 13.50s/it]                                                     {'loss': 0.903, 'learning_rate': 1.9990216146662648e-05, 'epoch': 0.04}
  4%|▍         | 227/5198 [49:57<18:38:39, 13.50s/it]  4%|▍         | 228/5198 [50:08<17:55:41, 12.99s/it]                                                     {'loss': 0.9784, 'learning_rate': 1.9989938650854618e-05, 'epoch': 0.04}
  4%|▍         | 228/5198 [50:08<17:55:41, 12.99s/it]  4%|▍         | 229/5198 [50:21<17:41:31, 12.82s/it]                                                     {'loss': 0.9198, 'learning_rate': 1.998965727660844e-05, 'epoch': 0.04}
  4%|▍         | 229/5198 [50:21<17:41:31, 12.82s/it]  4%|▍         | 230/5198 [50:33<17:22:21, 12.59s/it]                                                     {'loss': 0.9131, 'learning_rate': 1.9989372024033352e-05, 'epoch': 0.04}
  4%|▍         | 230/5198 [50:33<17:22:21, 12.59s/it]  4%|▍         | 231/5198 [50:45<17:00:04, 12.32s/it]                                                     {'loss': 0.9208, 'learning_rate': 1.99890828932401e-05, 'epoch': 0.04}
  4%|▍         | 231/5198 [50:45<17:00:04, 12.32s/it]  4%|▍         | 232/5198 [50:58<17:27:52, 12.66s/it]                                                     {'loss': 0.9246, 'learning_rate': 1.9988789884340938e-05, 'epoch': 0.04}
  4%|▍         | 232/5198 [50:58<17:27:52, 12.66s/it]  4%|▍         | 233/5198 [51:10<17:03:09, 12.36s/it]                                                     {'loss': 0.9443, 'learning_rate': 1.9988492997449615e-05, 'epoch': 0.04}
  4%|▍         | 233/5198 [51:10<17:03:09, 12.36s/it]  5%|▍         | 234/5198 [51:22<16:58:29, 12.31s/it]                                                     {'loss': 0.9283, 'learning_rate': 1.9988192232681398e-05, 'epoch': 0.05}
  5%|▍         | 234/5198 [51:22<16:58:29, 12.31s/it]  5%|▍         | 235/5198 [51:34<16:43:52, 12.14s/it]                                                     {'loss': 0.9338, 'learning_rate': 1.9987887590153055e-05, 'epoch': 0.05}
  5%|▍         | 235/5198 [51:34<16:43:52, 12.14s/it]  5%|▍         | 236/5198 [51:48<17:37:33, 12.79s/it]                                                     {'loss': 0.9893, 'learning_rate': 1.9987579069982856e-05, 'epoch': 0.05}
  5%|▍         | 236/5198 [51:48<17:37:33, 12.79s/it]  5%|▍         | 237/5198 [52:00<17:20:18, 12.58s/it]                                                     {'loss': 0.9697, 'learning_rate': 1.9987266672290577e-05, 'epoch': 0.05}
  5%|▍         | 237/5198 [52:00<17:20:18, 12.58s/it]  5%|▍         | 238/5198 [52:12<17:09:53, 12.46s/it]                                                     {'loss': 0.9743, 'learning_rate': 1.9986950397197503e-05, 'epoch': 0.05}
  5%|▍         | 238/5198 [52:12<17:09:53, 12.46s/it]  5%|▍         | 239/5198 [52:26<17:37:34, 12.80s/it]                                                     {'loss': 0.9441, 'learning_rate': 1.9986630244826425e-05, 'epoch': 0.05}
  5%|▍         | 239/5198 [52:26<17:37:34, 12.80s/it]  5%|▍         | 240/5198 [52:37<17:09:34, 12.46s/it]                                                     {'loss': 0.9893, 'learning_rate': 1.998630621530164e-05, 'epoch': 0.05}
  5%|▍         | 240/5198 [52:38<17:09:34, 12.46s/it]  5%|▍         | 241/5198 [52:50<17:02:11, 12.37s/it]                                                     {'loss': 0.9602, 'learning_rate': 1.998597830874894e-05, 'epoch': 0.05}
  5%|▍         | 241/5198 [52:50<17:02:11, 12.37s/it]  5%|▍         | 242/5198 [53:02<17:12:28, 12.50s/it]                                                     {'loss': 0.8683, 'learning_rate': 1.9985646525295634e-05, 'epoch': 0.05}
  5%|▍         | 242/5198 [53:02<17:12:28, 12.50s/it]  5%|▍         | 243/5198 [53:15<17:08:45, 12.46s/it]                                                     {'loss': 0.9054, 'learning_rate': 1.998531086507053e-05, 'epoch': 0.05}
  5%|▍         | 243/5198 [53:15<17:08:45, 12.46s/it]  5%|▍         | 244/5198 [53:27<16:50:30, 12.24s/it]                                                     {'loss': 0.9289, 'learning_rate': 1.9984971328203945e-05, 'epoch': 0.05}
  5%|▍         | 244/5198 [53:27<16:50:30, 12.24s/it]  5%|▍         | 245/5198 [53:39<17:04:31, 12.41s/it]                                                     {'loss': 0.9475, 'learning_rate': 1.9984627914827698e-05, 'epoch': 0.05}
  5%|▍         | 245/5198 [53:39<17:04:31, 12.41s/it]  5%|▍         | 246/5198 [53:51<16:51:11, 12.25s/it]                                                     {'loss': 1.0018, 'learning_rate': 1.9984280625075115e-05, 'epoch': 0.05}
  5%|▍         | 246/5198 [53:51<16:51:11, 12.25s/it]  5%|▍         | 247/5198 [54:03<16:46:02, 12.19s/it]                                                     {'loss': 0.9336, 'learning_rate': 1.9983929459081022e-05, 'epoch': 0.05}
  5%|▍         | 247/5198 [54:03<16:46:02, 12.19s/it]  5%|▍         | 248/5198 [54:16<17:06:31, 12.44s/it]                                                     {'loss': 0.9431, 'learning_rate': 1.998357441698176e-05, 'epoch': 0.05}
  5%|▍         | 248/5198 [54:16<17:06:31, 12.44s/it]  5%|▍         | 249/5198 [54:30<17:46:13, 12.93s/it]                                                     {'loss': 0.9101, 'learning_rate': 1.998321549891516e-05, 'epoch': 0.05}
  5%|▍         | 249/5198 [54:30<17:46:13, 12.93s/it]  5%|▍         | 250/5198 [54:44<17:59:22, 13.09s/it]                                                     {'loss': 0.8961, 'learning_rate': 1.9982852705020572e-05, 'epoch': 0.05}
  5%|▍         | 250/5198 [54:44<17:59:22, 13.09s/it]  5%|▍         | 251/5198 [55:00<19:26:14, 14.14s/it]                                                     {'loss': 0.3262, 'learning_rate': 1.9982486035438848e-05, 'epoch': 0.05}
  5%|▍         | 251/5198 [55:00<19:26:14, 14.14s/it]  5%|▍         | 252/5198 [55:12<18:22:26, 13.37s/it]                                                     {'loss': 0.9345, 'learning_rate': 1.9982115490312334e-05, 'epoch': 0.05}
  5%|▍         | 252/5198 [55:12<18:22:26, 13.37s/it]  5%|▍         | 253/5198 [55:24<17:59:25, 13.10s/it]                                                     {'loss': 0.9436, 'learning_rate': 1.9981741069784894e-05, 'epoch': 0.05}
  5%|▍         | 253/5198 [55:24<17:59:25, 13.10s/it]  5%|▍         | 254/5198 [55:38<18:01:46, 13.13s/it]                                                     {'loss': 0.9308, 'learning_rate': 1.9981362774001886e-05, 'epoch': 0.05}
  5%|▍         | 254/5198 [55:38<18:01:46, 13.13s/it]  5%|▍         | 255/5198 [55:50<17:40:40, 12.87s/it]                                                     {'loss': 0.9664, 'learning_rate': 1.9980980603110185e-05, 'epoch': 0.05}
  5%|▍         | 255/5198 [55:50<17:40:40, 12.87s/it]  5%|▍         | 256/5198 [56:02<17:11:51, 12.53s/it]                                                     {'loss': 0.9011, 'learning_rate': 1.9980594557258158e-05, 'epoch': 0.05}
  5%|▍         | 256/5198 [56:02<17:11:51, 12.53s/it]  5%|▍         | 257/5198 [56:15<17:33:16, 12.79s/it]                                                     {'loss': 0.8641, 'learning_rate': 1.9980204636595682e-05, 'epoch': 0.05}
  5%|▍         | 257/5198 [56:15<17:33:16, 12.79s/it]  5%|▍         | 258/5198 [56:28<17:25:19, 12.70s/it]                                                     {'loss': 0.9467, 'learning_rate': 1.9979810841274135e-05, 'epoch': 0.05}
  5%|▍         | 258/5198 [56:28<17:25:19, 12.70s/it]  5%|▍         | 259/5198 [56:42<18:04:35, 13.18s/it]                                                     {'loss': 0.9819, 'learning_rate': 1.9979413171446403e-05, 'epoch': 0.05}
  5%|▍         | 259/5198 [56:42<18:04:35, 13.18s/it]  5%|▌         | 260/5198 [56:54<17:45:39, 12.95s/it]                                                     {'loss': 0.9418, 'learning_rate': 1.9979011627266884e-05, 'epoch': 0.05}
  5%|▌         | 260/5198 [56:54<17:45:39, 12.95s/it]  5%|▌         | 261/5198 [57:06<17:18:58, 12.63s/it]                                                     {'loss': 0.9544, 'learning_rate': 1.997860620889146e-05, 'epoch': 0.05}
  5%|▌         | 261/5198 [57:06<17:18:58, 12.63s/it]  5%|▌         | 262/5198 [57:20<17:52:28, 13.04s/it]                                                     {'loss': 0.8102, 'learning_rate': 1.997819691647753e-05, 'epoch': 0.05}
  5%|▌         | 262/5198 [57:20<17:52:28, 13.04s/it]  5%|▌         | 263/5198 [57:32<17:32:46, 12.80s/it]                                                     {'loss': 0.9604, 'learning_rate': 1.9977783750184e-05, 'epoch': 0.05}
  5%|▌         | 263/5198 [57:32<17:32:46, 12.80s/it]  5%|▌         | 264/5198 [57:45<17:39:40, 12.89s/it]                                                     {'loss': 0.9385, 'learning_rate': 1.9977366710171274e-05, 'epoch': 0.05}
  5%|▌         | 264/5198 [57:46<17:39:40, 12.89s/it]  5%|▌         | 265/5198 [57:57<17:05:58, 12.48s/it]                                                     {'loss': 0.9415, 'learning_rate': 1.9976945796601258e-05, 'epoch': 0.05}
  5%|▌         | 265/5198 [57:57<17:05:58, 12.48s/it]  5%|▌         | 266/5198 [58:09<16:56:44, 12.37s/it]                                                     {'loss': 0.9397, 'learning_rate': 1.9976521009637366e-05, 'epoch': 0.05}
  5%|▌         | 266/5198 [58:09<16:56:44, 12.37s/it]  5%|▌         | 267/5198 [58:22<17:02:16, 12.44s/it]                                                     {'loss': 0.9424, 'learning_rate': 1.997609234944452e-05, 'epoch': 0.05}
  5%|▌         | 267/5198 [58:22<17:02:16, 12.44s/it]  5%|▌         | 268/5198 [58:34<16:49:01, 12.28s/it]                                                     {'loss': 1.01, 'learning_rate': 1.9975659816189137e-05, 'epoch': 0.05}
  5%|▌         | 268/5198 [58:34<16:49:01, 12.28s/it]  5%|▌         | 269/5198 [58:49<18:12:51, 13.30s/it]                                                     {'loss': 0.8635, 'learning_rate': 1.997522341003914e-05, 'epoch': 0.05}
  5%|▌         | 269/5198 [58:49<18:12:51, 13.30s/it]  5%|▌         | 270/5198 [59:02<17:52:23, 13.06s/it]                                                     {'loss': 0.9301, 'learning_rate': 1.9974783131163957e-05, 'epoch': 0.05}
  5%|▌         | 270/5198 [59:02<17:52:23, 13.06s/it]  5%|▌         | 271/5198 [59:14<17:30:43, 12.80s/it]                                                     {'loss': 0.9506, 'learning_rate': 1.9974338979734523e-05, 'epoch': 0.05}
  5%|▌         | 271/5198 [59:14<17:30:43, 12.80s/it]  5%|▌         | 272/5198 [59:26<17:03:44, 12.47s/it]                                                     {'loss': 0.9694, 'learning_rate': 1.997389095592327e-05, 'epoch': 0.05}
  5%|▌         | 272/5198 [59:26<17:03:44, 12.47s/it]  5%|▌         | 273/5198 [59:38<17:03:22, 12.47s/it]                                                     {'loss': 0.9516, 'learning_rate': 1.9973439059904133e-05, 'epoch': 0.05}
  5%|▌         | 273/5198 [59:38<17:03:22, 12.47s/it]  5%|▌         | 274/5198 [59:51<17:24:47, 12.73s/it]                                                     {'loss': 0.9493, 'learning_rate': 1.9972983291852565e-05, 'epoch': 0.05}
  5%|▌         | 274/5198 [59:52<17:24:47, 12.73s/it]  5%|▌         | 275/5198 [1:00:03<17:05:28, 12.50s/it]                                                       {'loss': 0.9652, 'learning_rate': 1.9972523651945496e-05, 'epoch': 0.05}
  5%|▌         | 275/5198 [1:00:03<17:05:28, 12.50s/it]  5%|▌         | 276/5198 [1:00:16<17:01:47, 12.46s/it]                                                       {'loss': 0.9317, 'learning_rate': 1.9972060140361384e-05, 'epoch': 0.05}
  5%|▌         | 276/5198 [1:00:16<17:01:47, 12.46s/it]  5%|▌         | 277/5198 [1:00:28<16:58:34, 12.42s/it]                                                       {'loss': 0.9733, 'learning_rate': 1.997159275728018e-05, 'epoch': 0.05}
  5%|▌         | 277/5198 [1:00:28<16:58:34, 12.42s/it]  5%|▌         | 278/5198 [1:00:41<16:58:46, 12.42s/it]                                                       {'loss': 0.9591, 'learning_rate': 1.9971121502883332e-05, 'epoch': 0.05}
  5%|▌         | 278/5198 [1:00:41<16:58:46, 12.42s/it]  5%|▌         | 279/5198 [1:00:53<16:55:18, 12.38s/it]                                                       {'loss': 0.9625, 'learning_rate': 1.9970646377353802e-05, 'epoch': 0.05}
  5%|▌         | 279/5198 [1:00:53<16:55:18, 12.38s/it]  5%|▌         | 280/5198 [1:01:05<16:49:35, 12.32s/it]                                                       {'loss': 0.9593, 'learning_rate': 1.997016738087605e-05, 'epoch': 0.05}
  5%|▌         | 280/5198 [1:01:05<16:49:35, 12.32s/it]  5%|▌         | 281/5198 [1:01:17<16:45:55, 12.27s/it]                                                       {'loss': 0.9334, 'learning_rate': 1.9969684513636035e-05, 'epoch': 0.05}
  5%|▌         | 281/5198 [1:01:17<16:45:55, 12.27s/it]  5%|▌         | 282/5198 [1:01:31<17:20:59, 12.71s/it]                                                       {'loss': 0.9328, 'learning_rate': 1.9969197775821227e-05, 'epoch': 0.05}
  5%|▌         | 282/5198 [1:01:31<17:20:59, 12.71s/it]  5%|▌         | 283/5198 [1:01:44<17:24:46, 12.75s/it]                                                       {'loss': 0.9209, 'learning_rate': 1.9968707167620593e-05, 'epoch': 0.05}
  5%|▌         | 283/5198 [1:01:44<17:24:46, 12.75s/it]  5%|▌         | 284/5198 [1:01:57<17:29:38, 12.82s/it]                                                       {'loss': 0.9765, 'learning_rate': 1.9968212689224603e-05, 'epoch': 0.05}
  5%|▌         | 284/5198 [1:01:57<17:29:38, 12.82s/it]  5%|▌         | 285/5198 [1:02:09<17:10:39, 12.59s/it]                                                       {'loss': 0.868, 'learning_rate': 1.996771434082523e-05, 'epoch': 0.05}
  5%|▌         | 285/5198 [1:02:09<17:10:39, 12.59s/it]  6%|▌         | 286/5198 [1:02:21<17:10:36, 12.59s/it]                                                       {'loss': 0.9243, 'learning_rate': 1.9967212122615958e-05, 'epoch': 0.06}
  6%|▌         | 286/5198 [1:02:21<17:10:36, 12.59s/it]  6%|▌         | 287/5198 [1:02:33<16:56:25, 12.42s/it]                                                       {'loss': 0.845, 'learning_rate': 1.9966706034791752e-05, 'epoch': 0.06}
  6%|▌         | 287/5198 [1:02:33<16:56:25, 12.42s/it]  6%|▌         | 288/5198 [1:02:46<17:01:41, 12.49s/it]                                                       {'loss': 0.8904, 'learning_rate': 1.9966196077549106e-05, 'epoch': 0.06}
  6%|▌         | 288/5198 [1:02:46<17:01:41, 12.49s/it]  6%|▌         | 289/5198 [1:02:59<17:07:55, 12.56s/it]                                                       {'loss': 0.9521, 'learning_rate': 1.996568225108599e-05, 'epoch': 0.06}
  6%|▌         | 289/5198 [1:02:59<17:07:55, 12.56s/it]  6%|▌         | 290/5198 [1:03:11<16:53:44, 12.39s/it]                                                       {'loss': 0.9316, 'learning_rate': 1.99651645556019e-05, 'epoch': 0.06}
  6%|▌         | 290/5198 [1:03:11<16:53:44, 12.39s/it]  6%|▌         | 291/5198 [1:03:23<16:41:39, 12.25s/it]                                                       {'loss': 0.9639, 'learning_rate': 1.9964642991297817e-05, 'epoch': 0.06}
  6%|▌         | 291/5198 [1:03:23<16:41:39, 12.25s/it]  6%|▌         | 292/5198 [1:03:35<16:33:22, 12.15s/it]                                                       {'loss': 0.9135, 'learning_rate': 1.996411755837623e-05, 'epoch': 0.06}
  6%|▌         | 292/5198 [1:03:35<16:33:22, 12.15s/it]  6%|▌         | 293/5198 [1:03:48<17:11:17, 12.62s/it]                                                       {'loss': 0.9103, 'learning_rate': 1.9963588257041137e-05, 'epoch': 0.06}
  6%|▌         | 293/5198 [1:03:48<17:11:17, 12.62s/it]  6%|▌         | 294/5198 [1:04:00<16:52:22, 12.39s/it]                                                       {'loss': 0.9695, 'learning_rate': 1.996305508749802e-05, 'epoch': 0.06}
  6%|▌         | 294/5198 [1:04:00<16:52:22, 12.39s/it]  6%|▌         | 295/5198 [1:04:14<17:29:28, 12.84s/it]                                                       {'loss': 0.9097, 'learning_rate': 1.9962518049953887e-05, 'epoch': 0.06}
  6%|▌         | 295/5198 [1:04:14<17:29:28, 12.84s/it]  6%|▌         | 296/5198 [1:04:26<17:09:50, 12.61s/it]                                                       {'loss': 0.9684, 'learning_rate': 1.9961977144617225e-05, 'epoch': 0.06}
  6%|▌         | 296/5198 [1:04:26<17:09:50, 12.61s/it][2024-03-23 16:54:41,435] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  6%|▌         | 297/5198 [1:04:43<18:50:37, 13.84s/it]                                                       {'loss': 0.3415, 'learning_rate': 1.996143237169803e-05, 'epoch': 0.06}
  6%|▌         | 297/5198 [1:04:43<18:50:37, 13.84s/it]  6%|▌         | 298/5198 [1:04:56<18:32:20, 13.62s/it]                                                       {'loss': 0.9281, 'learning_rate': 1.996088373140781e-05, 'epoch': 0.06}
  6%|▌         | 298/5198 [1:04:56<18:32:20, 13.62s/it]  6%|▌         | 299/5198 [1:05:08<17:51:21, 13.12s/it]                                                       {'loss': 0.948, 'learning_rate': 1.9960331223959564e-05, 'epoch': 0.06}
  6%|▌         | 299/5198 [1:05:08<17:51:21, 13.12s/it]  6%|▌         | 300/5198 [1:05:20<17:22:27, 12.77s/it]                                                       {'loss': 0.8976, 'learning_rate': 1.995977484956779e-05, 'epoch': 0.06}
  6%|▌         | 300/5198 [1:05:20<17:22:27, 12.77s/it]  6%|▌         | 301/5198 [1:05:33<17:42:45, 13.02s/it]                                                       {'loss': 0.9716, 'learning_rate': 1.9959214608448495e-05, 'epoch': 0.06}
  6%|▌         | 301/5198 [1:05:34<17:42:45, 13.02s/it]  6%|▌         | 302/5198 [1:05:47<17:59:13, 13.23s/it]                                                       {'loss': 0.9928, 'learning_rate': 1.9958650500819183e-05, 'epoch': 0.06}
  6%|▌         | 302/5198 [1:05:47<17:59:13, 13.23s/it]  6%|▌         | 303/5198 [1:05:59<17:27:27, 12.84s/it]                                                       {'loss': 0.9106, 'learning_rate': 1.995808252689886e-05, 'epoch': 0.06}
  6%|▌         | 303/5198 [1:05:59<17:27:27, 12.84s/it]  6%|▌         | 304/5198 [1:06:12<17:36:36, 12.95s/it]                                                       {'loss': 0.8856, 'learning_rate': 1.9957510686908034e-05, 'epoch': 0.06}
  6%|▌         | 304/5198 [1:06:12<17:36:36, 12.95s/it]  6%|▌         | 305/5198 [1:06:25<17:38:01, 12.97s/it]                                                       {'loss': 0.943, 'learning_rate': 1.9956934981068713e-05, 'epoch': 0.06}
  6%|▌         | 305/5198 [1:06:25<17:38:01, 12.97s/it]  6%|▌         | 306/5198 [1:06:37<17:09:55, 12.63s/it]                                                       {'loss': 0.8773, 'learning_rate': 1.9956355409604402e-05, 'epoch': 0.06}
  6%|▌         | 306/5198 [1:06:37<17:09:55, 12.63s/it]  6%|▌         | 307/5198 [1:06:49<16:39:23, 12.26s/it]                                                       {'loss': 0.9759, 'learning_rate': 1.9955771972740118e-05, 'epoch': 0.06}
  6%|▌         | 307/5198 [1:06:49<16:39:23, 12.26s/it]  6%|▌         | 308/5198 [1:07:01<16:48:47, 12.38s/it]                                                       {'loss': 0.89, 'learning_rate': 1.9955184670702363e-05, 'epoch': 0.06}
  6%|▌         | 308/5198 [1:07:01<16:48:47, 12.38s/it]  6%|▌         | 309/5198 [1:07:13<16:28:29, 12.13s/it]                                                       {'loss': 0.9218, 'learning_rate': 1.995459350371915e-05, 'epoch': 0.06}
  6%|▌         | 309/5198 [1:07:13<16:28:29, 12.13s/it]  6%|▌         | 310/5198 [1:07:24<16:18:24, 12.01s/it]                                                       {'loss': 0.938, 'learning_rate': 1.9953998472019996e-05, 'epoch': 0.06}
  6%|▌         | 310/5198 [1:07:25<16:18:24, 12.01s/it]  6%|▌         | 311/5198 [1:07:38<16:52:35, 12.43s/it]                                                       {'loss': 0.915, 'learning_rate': 1.995339957583591e-05, 'epoch': 0.06}
  6%|▌         | 311/5198 [1:07:38<16:52:35, 12.43s/it]  6%|▌         | 312/5198 [1:07:51<16:59:30, 12.52s/it]                                                       {'loss': 0.8653, 'learning_rate': 1.9952796815399403e-05, 'epoch': 0.06}
  6%|▌         | 312/5198 [1:07:51<16:59:30, 12.52s/it]  6%|▌         | 313/5198 [1:08:02<16:29:24, 12.15s/it]                                                       {'loss': 0.9637, 'learning_rate': 1.9952190190944484e-05, 'epoch': 0.06}
  6%|▌         | 313/5198 [1:08:02<16:29:24, 12.15s/it]  6%|▌         | 314/5198 [1:08:14<16:23:40, 12.08s/it]                                                       {'loss': 0.9942, 'learning_rate': 1.9951579702706668e-05, 'epoch': 0.06}
  6%|▌         | 314/5198 [1:08:14<16:23:40, 12.08s/it]  6%|▌         | 315/5198 [1:08:26<16:36:58, 12.25s/it]                                                       {'loss': 0.8748, 'learning_rate': 1.9950965350922975e-05, 'epoch': 0.06}
  6%|▌         | 315/5198 [1:08:27<16:36:58, 12.25s/it]  6%|▌         | 316/5198 [1:08:39<16:39:19, 12.28s/it]                                                       {'loss': 0.9368, 'learning_rate': 1.9950347135831907e-05, 'epoch': 0.06}
  6%|▌         | 316/5198 [1:08:39<16:39:19, 12.28s/it]  6%|▌         | 317/5198 [1:08:52<16:49:35, 12.41s/it]                                                       {'loss': 0.9547, 'learning_rate': 1.994972505767348e-05, 'epoch': 0.06}
  6%|▌         | 317/5198 [1:08:52<16:49:35, 12.41s/it]  6%|▌         | 318/5198 [1:09:04<16:46:50, 12.38s/it]                                                       {'loss': 0.9414, 'learning_rate': 1.994909911668921e-05, 'epoch': 0.06}
  6%|▌         | 318/5198 [1:09:04<16:46:50, 12.38s/it]  6%|▌         | 319/5198 [1:09:16<16:46:19, 12.38s/it]                                                       {'loss': 0.9266, 'learning_rate': 1.99484693131221e-05, 'epoch': 0.06}
  6%|▌         | 319/5198 [1:09:16<16:46:19, 12.38s/it]  6%|▌         | 320/5198 [1:09:30<17:17:46, 12.76s/it]                                                       {'loss': 0.9098, 'learning_rate': 1.994783564721667e-05, 'epoch': 0.06}
  6%|▌         | 320/5198 [1:09:30<17:17:46, 12.76s/it]  6%|▌         | 321/5198 [1:09:43<17:20:49, 12.80s/it]                                                       {'loss': 0.8987, 'learning_rate': 1.9947198119218924e-05, 'epoch': 0.06}
  6%|▌         | 321/5198 [1:09:43<17:20:49, 12.80s/it]  6%|▌         | 322/5198 [1:10:00<19:05:23, 14.09s/it]                                                       {'loss': 0.2906, 'learning_rate': 1.994655672937638e-05, 'epoch': 0.06}
  6%|▌         | 322/5198 [1:10:00<19:05:23, 14.09s/it]  6%|▌         | 323/5198 [1:10:12<18:20:31, 13.55s/it]                                                       {'loss': 1.0145, 'learning_rate': 1.9945911477938044e-05, 'epoch': 0.06}
  6%|▌         | 323/5198 [1:10:12<18:20:31, 13.55s/it]  6%|▌         | 324/5198 [1:10:25<17:55:33, 13.24s/it]                                                       {'loss': 0.9473, 'learning_rate': 1.994526236515442e-05, 'epoch': 0.06}
  6%|▌         | 324/5198 [1:10:25<17:55:33, 13.24s/it]  6%|▋         | 325/5198 [1:10:36<17:19:03, 12.79s/it]                                                       {'loss': 0.9927, 'learning_rate': 1.994460939127753e-05, 'epoch': 0.06}
  6%|▋         | 325/5198 [1:10:37<17:19:03, 12.79s/it]  6%|▋         | 326/5198 [1:10:48<16:56:35, 12.52s/it]                                                       {'loss': 0.8719, 'learning_rate': 1.9943952556560863e-05, 'epoch': 0.06}
  6%|▋         | 326/5198 [1:10:48<16:56:35, 12.52s/it]  6%|▋         | 327/5198 [1:11:00<16:40:47, 12.33s/it]                                                       {'loss': 0.9837, 'learning_rate': 1.9943291861259433e-05, 'epoch': 0.06}
  6%|▋         | 327/5198 [1:11:00<16:40:47, 12.33s/it]  6%|▋         | 328/5198 [1:11:15<17:46:23, 13.14s/it]                                                       {'loss': 0.9208, 'learning_rate': 1.9942627305629747e-05, 'epoch': 0.06}
  6%|▋         | 328/5198 [1:11:15<17:46:23, 13.14s/it]  6%|▋         | 329/5198 [1:11:27<17:08:21, 12.67s/it]                                                       {'loss': 0.9221, 'learning_rate': 1.9941958889929808e-05, 'epoch': 0.06}
  6%|▋         | 329/5198 [1:11:27<17:08:21, 12.67s/it]  6%|▋         | 330/5198 [1:11:40<17:21:11, 12.83s/it]                                                       {'loss': 0.8886, 'learning_rate': 1.9941286614419113e-05, 'epoch': 0.06}
  6%|▋         | 330/5198 [1:11:40<17:21:11, 12.83s/it]  6%|▋         | 331/5198 [1:11:53<17:32:00, 12.97s/it]                                                       {'loss': 0.9517, 'learning_rate': 1.994061047935867e-05, 'epoch': 0.06}
  6%|▋         | 331/5198 [1:11:53<17:32:00, 12.97s/it]  6%|▋         | 332/5198 [1:12:06<17:19:18, 12.82s/it]                                                       {'loss': 0.9317, 'learning_rate': 1.9939930485010968e-05, 'epoch': 0.06}
  6%|▋         | 332/5198 [1:12:06<17:19:18, 12.82s/it]  6%|▋         | 333/5198 [1:12:18<17:00:10, 12.58s/it]                                                       {'loss': 0.9213, 'learning_rate': 1.9939246631640014e-05, 'epoch': 0.06}
  6%|▋         | 333/5198 [1:12:18<17:00:10, 12.58s/it]  6%|▋         | 334/5198 [1:12:30<16:45:30, 12.40s/it]                                                       {'loss': 0.8675, 'learning_rate': 1.99385589195113e-05, 'epoch': 0.06}
  6%|▋         | 334/5198 [1:12:30<16:45:30, 12.40s/it]  6%|▋         | 335/5198 [1:12:41<16:26:14, 12.17s/it]                                                       {'loss': 0.9378, 'learning_rate': 1.9937867348891815e-05, 'epoch': 0.06}
  6%|▋         | 335/5198 [1:12:41<16:26:14, 12.17s/it]  6%|▋         | 336/5198 [1:12:55<16:57:46, 12.56s/it]                                                       {'loss': 0.9423, 'learning_rate': 1.9937171920050057e-05, 'epoch': 0.06}
  6%|▋         | 336/5198 [1:12:55<16:57:46, 12.56s/it]  6%|▋         | 337/5198 [1:13:07<16:56:28, 12.55s/it]                                                       {'loss': 0.9175, 'learning_rate': 1.9936472633256012e-05, 'epoch': 0.06}
  6%|▋         | 337/5198 [1:13:08<16:56:28, 12.55s/it]  7%|▋         | 338/5198 [1:13:19<16:31:48, 12.24s/it]                                                       {'loss': 0.9414, 'learning_rate': 1.9935769488781167e-05, 'epoch': 0.07}
  7%|▋         | 338/5198 [1:13:19<16:31:48, 12.24s/it]  7%|▋         | 339/5198 [1:13:31<16:16:11, 12.05s/it]                                                       {'loss': 0.96, 'learning_rate': 1.993506248689851e-05, 'epoch': 0.07}
  7%|▋         | 339/5198 [1:13:31<16:16:11, 12.05s/it]  7%|▋         | 340/5198 [1:13:44<17:00:31, 12.60s/it]                                                       {'loss': 0.9184, 'learning_rate': 1.993435162788252e-05, 'epoch': 0.07}
  7%|▋         | 340/5198 [1:13:45<17:00:31, 12.60s/it]  7%|▋         | 341/5198 [1:13:56<16:41:28, 12.37s/it]                                                       {'loss': 0.9551, 'learning_rate': 1.993363691200918e-05, 'epoch': 0.07}
  7%|▋         | 341/5198 [1:13:56<16:41:28, 12.37s/it]  7%|▋         | 342/5198 [1:14:10<17:18:11, 12.83s/it]                                                       {'loss': 0.8721, 'learning_rate': 1.9932918339555965e-05, 'epoch': 0.07}
  7%|▋         | 342/5198 [1:14:10<17:18:11, 12.83s/it]  7%|▋         | 343/5198 [1:14:22<17:03:51, 12.65s/it]                                                       {'loss': 0.9761, 'learning_rate': 1.9932195910801848e-05, 'epoch': 0.07}
  7%|▋         | 343/5198 [1:14:22<17:03:51, 12.65s/it]  7%|▋         | 344/5198 [1:14:35<16:52:47, 12.52s/it]                                                       {'loss': 0.9121, 'learning_rate': 1.9931469626027305e-05, 'epoch': 0.07}
  7%|▋         | 344/5198 [1:14:35<16:52:47, 12.52s/it]  7%|▋         | 345/5198 [1:14:47<16:37:24, 12.33s/it]                                                       {'loss': 0.917, 'learning_rate': 1.9930739485514304e-05, 'epoch': 0.07}
  7%|▋         | 345/5198 [1:14:47<16:37:24, 12.33s/it]  7%|▋         | 346/5198 [1:14:59<16:32:16, 12.27s/it]                                                       {'loss': 0.9309, 'learning_rate': 1.9930005489546308e-05, 'epoch': 0.07}
  7%|▋         | 346/5198 [1:14:59<16:32:16, 12.27s/it]  7%|▋         | 347/5198 [1:15:11<16:36:24, 12.32s/it]                                                       {'loss': 0.9609, 'learning_rate': 1.9929267638408277e-05, 'epoch': 0.07}
  7%|▋         | 347/5198 [1:15:11<16:36:24, 12.32s/it]  7%|▋         | 348/5198 [1:15:23<16:26:50, 12.21s/it]                                                       {'loss': 0.9249, 'learning_rate': 1.9928525932386678e-05, 'epoch': 0.07}
  7%|▋         | 348/5198 [1:15:23<16:26:50, 12.21s/it]  7%|▋         | 349/5198 [1:15:36<16:51:02, 12.51s/it]                                                       {'loss': 0.948, 'learning_rate': 1.9927780371769463e-05, 'epoch': 0.07}
  7%|▋         | 349/5198 [1:15:36<16:51:02, 12.51s/it]  7%|▋         | 350/5198 [1:15:50<17:10:49, 12.76s/it]                                                       {'loss': 0.876, 'learning_rate': 1.9927030956846083e-05, 'epoch': 0.07}
  7%|▋         | 350/5198 [1:15:50<17:10:49, 12.76s/it]  7%|▋         | 351/5198 [1:16:02<16:50:30, 12.51s/it]                                                       {'loss': 0.9205, 'learning_rate': 1.992627768790749e-05, 'epoch': 0.07}
  7%|▋         | 351/5198 [1:16:02<16:50:30, 12.51s/it]  7%|▋         | 352/5198 [1:16:18<18:35:09, 13.81s/it]                                                       {'loss': 0.3272, 'learning_rate': 1.9925520565246125e-05, 'epoch': 0.07}
  7%|▋         | 352/5198 [1:16:18<18:35:09, 13.81s/it]  7%|▋         | 353/5198 [1:16:31<17:56:54, 13.34s/it]                                                       {'loss': 0.901, 'learning_rate': 1.9924759589155932e-05, 'epoch': 0.07}
  7%|▋         | 353/5198 [1:16:31<17:56:54, 13.34s/it]  7%|▋         | 354/5198 [1:16:43<17:39:07, 13.12s/it]                                                       {'loss': 0.9774, 'learning_rate': 1.9923994759932344e-05, 'epoch': 0.07}
  7%|▋         | 354/5198 [1:16:43<17:39:07, 13.12s/it]  7%|▋         | 355/5198 [1:16:55<17:05:55, 12.71s/it]                                                       {'loss': 0.9063, 'learning_rate': 1.9923226077872296e-05, 'epoch': 0.07}
  7%|▋         | 355/5198 [1:16:55<17:05:55, 12.71s/it]  7%|▋         | 356/5198 [1:17:09<17:33:13, 13.05s/it]                                                       {'loss': 0.9102, 'learning_rate': 1.9922453543274223e-05, 'epoch': 0.07}
  7%|▋         | 356/5198 [1:17:09<17:33:13, 13.05s/it]  7%|▋         | 357/5198 [1:17:21<17:11:48, 12.79s/it]                                                       {'loss': 0.9152, 'learning_rate': 1.9921677156438044e-05, 'epoch': 0.07}
  7%|▋         | 357/5198 [1:17:21<17:11:48, 12.79s/it]  7%|▋         | 358/5198 [1:17:35<17:30:02, 13.02s/it]                                                       {'loss': 0.9842, 'learning_rate': 1.9920896917665178e-05, 'epoch': 0.07}
  7%|▋         | 358/5198 [1:17:35<17:30:02, 13.02s/it]  7%|▋         | 359/5198 [1:17:47<17:21:33, 12.91s/it]                                                       {'loss': 0.9904, 'learning_rate': 1.992011282725854e-05, 'epoch': 0.07}
  7%|▋         | 359/5198 [1:17:47<17:21:33, 12.91s/it]  7%|▋         | 360/5198 [1:17:59<16:49:40, 12.52s/it]                                                       {'loss': 0.9271, 'learning_rate': 1.9919324885522548e-05, 'epoch': 0.07}
  7%|▋         | 360/5198 [1:17:59<16:49:40, 12.52s/it]  7%|▋         | 361/5198 [1:18:11<16:40:00, 12.40s/it]                                                       {'loss': 0.9303, 'learning_rate': 1.99185330927631e-05, 'epoch': 0.07}
  7%|▋         | 361/5198 [1:18:11<16:40:00, 12.40s/it]  7%|▋         | 362/5198 [1:18:24<16:48:18, 12.51s/it]                                                       {'loss': 0.898, 'learning_rate': 1.99177374492876e-05, 'epoch': 0.07}
  7%|▋         | 362/5198 [1:18:24<16:48:18, 12.51s/it]  7%|▋         | 363/5198 [1:18:36<16:33:54, 12.33s/it]                                                       {'loss': 0.926, 'learning_rate': 1.991693795540494e-05, 'epoch': 0.07}
  7%|▋         | 363/5198 [1:18:36<16:33:54, 12.33s/it]  7%|▋         | 364/5198 [1:18:50<17:27:14, 13.00s/it]                                                       {'loss': 0.9075, 'learning_rate': 1.9916134611425522e-05, 'epoch': 0.07}
  7%|▋         | 364/5198 [1:18:50<17:27:14, 13.00s/it]  7%|▋         | 365/5198 [1:19:04<17:58:10, 13.39s/it]                                                       {'loss': 0.9078, 'learning_rate': 1.9915327417661226e-05, 'epoch': 0.07}
  7%|▋         | 365/5198 [1:19:05<17:58:10, 13.39s/it]  7%|▋         | 366/5198 [1:19:17<17:28:53, 13.02s/it]                                                       {'loss': 0.9386, 'learning_rate': 1.991451637442543e-05, 'epoch': 0.07}
  7%|▋         | 366/5198 [1:19:17<17:28:53, 13.02s/it]  7%|▋         | 367/5198 [1:19:32<18:24:31, 13.72s/it]                                                       {'loss': 0.9535, 'learning_rate': 1.9913701482033008e-05, 'epoch': 0.07}
  7%|▋         | 367/5198 [1:19:32<18:24:31, 13.72s/it]  7%|▋         | 368/5198 [1:19:45<18:01:11, 13.43s/it]                                                       {'loss': 0.9078, 'learning_rate': 1.9912882740800336e-05, 'epoch': 0.07}
  7%|▋         | 368/5198 [1:19:45<18:01:11, 13.43s/it]  7%|▋         | 369/5198 [1:19:58<17:52:20, 13.32s/it]                                                       {'loss': 0.9266, 'learning_rate': 1.9912060151045273e-05, 'epoch': 0.07}
  7%|▋         | 369/5198 [1:19:58<17:52:20, 13.32s/it]  7%|▋         | 370/5198 [1:20:12<18:11:24, 13.56s/it]                                                       {'loss': 0.9636, 'learning_rate': 1.9911233713087172e-05, 'epoch': 0.07}
  7%|▋         | 370/5198 [1:20:12<18:11:24, 13.56s/it]  7%|▋         | 371/5198 [1:20:25<18:00:45, 13.43s/it]                                                       {'loss': 0.936, 'learning_rate': 1.9910403427246895e-05, 'epoch': 0.07}
  7%|▋         | 371/5198 [1:20:25<18:00:45, 13.43s/it]  7%|▋         | 372/5198 [1:20:37<17:25:10, 12.99s/it]                                                       {'loss': 0.9314, 'learning_rate': 1.990956929384678e-05, 'epoch': 0.07}
  7%|▋         | 372/5198 [1:20:37<17:25:10, 12.99s/it]  7%|▋         | 373/5198 [1:20:49<17:06:12, 12.76s/it]                                                       {'loss': 0.9065, 'learning_rate': 1.990873131321067e-05, 'epoch': 0.07}
  7%|▋         | 373/5198 [1:20:49<17:06:12, 12.76s/it]  7%|▋         | 374/5198 [1:21:03<17:22:46, 12.97s/it]                                                       {'loss': 0.9448, 'learning_rate': 1.9907889485663897e-05, 'epoch': 0.07}
  7%|▋         | 374/5198 [1:21:03<17:22:46, 12.97s/it]  7%|▋         | 375/5198 [1:21:15<17:10:08, 12.82s/it]                                                       {'loss': 0.9041, 'learning_rate': 1.9907043811533283e-05, 'epoch': 0.07}
  7%|▋         | 375/5198 [1:21:15<17:10:08, 12.82s/it]  7%|▋         | 376/5198 [1:21:27<16:52:37, 12.60s/it]                                                       {'loss': 0.8956, 'learning_rate': 1.9906194291147155e-05, 'epoch': 0.07}
  7%|▋         | 376/5198 [1:21:27<16:52:37, 12.60s/it]  7%|▋         | 377/5198 [1:21:39<16:41:57, 12.47s/it]                                                       {'loss': 0.9708, 'learning_rate': 1.9905340924835322e-05, 'epoch': 0.07}
  7%|▋         | 377/5198 [1:21:40<16:41:57, 12.47s/it]  7%|▋         | 378/5198 [1:21:52<16:40:31, 12.45s/it]                                                       {'loss': 0.8848, 'learning_rate': 1.9904483712929094e-05, 'epoch': 0.07}
  7%|▋         | 378/5198 [1:21:52<16:40:31, 12.45s/it]  7%|▋         | 379/5198 [1:22:04<16:30:19, 12.33s/it]                                                       {'loss': 0.9199, 'learning_rate': 1.9903622655761267e-05, 'epoch': 0.07}
  7%|▋         | 379/5198 [1:22:04<16:30:19, 12.33s/it]  7%|▋         | 380/5198 [1:22:16<16:17:03, 12.17s/it]                                                       {'loss': 0.9085, 'learning_rate': 1.990275775366613e-05, 'epoch': 0.07}
  7%|▋         | 380/5198 [1:22:16<16:17:03, 12.17s/it]  7%|▋         | 381/5198 [1:22:28<16:21:45, 12.23s/it]                                                       {'loss': 0.9307, 'learning_rate': 1.9901889006979473e-05, 'epoch': 0.07}
  7%|▋         | 381/5198 [1:22:28<16:21:45, 12.23s/it]  7%|▋         | 382/5198 [1:22:39<16:02:37, 11.99s/it]                                                       {'loss': 0.9105, 'learning_rate': 1.990101641603857e-05, 'epoch': 0.07}
  7%|▋         | 382/5198 [1:22:40<16:02:37, 11.99s/it]  7%|▋         | 383/5198 [1:22:53<16:29:35, 12.33s/it]                                                       {'loss': 0.91, 'learning_rate': 1.9900139981182193e-05, 'epoch': 0.07}
  7%|▋         | 383/5198 [1:22:53<16:29:35, 12.33s/it]  7%|▋         | 384/5198 [1:23:05<16:35:46, 12.41s/it]                                                       {'loss': 0.8993, 'learning_rate': 1.9899259702750604e-05, 'epoch': 0.07}
  7%|▋         | 384/5198 [1:23:05<16:35:46, 12.41s/it]  7%|▋         | 385/5198 [1:23:18<16:40:35, 12.47s/it]                                                       {'loss': 0.9114, 'learning_rate': 1.9898375581085555e-05, 'epoch': 0.07}
  7%|▋         | 385/5198 [1:23:18<16:40:35, 12.47s/it]  7%|▋         | 386/5198 [1:23:30<16:37:24, 12.44s/it]                                                       {'loss': 0.9373, 'learning_rate': 1.9897487616530296e-05, 'epoch': 0.07}
  7%|▋         | 386/5198 [1:23:30<16:37:24, 12.44s/it]  7%|▋         | 387/5198 [1:23:42<16:31:44, 12.37s/it]                                                       {'loss': 0.9396, 'learning_rate': 1.9896595809429565e-05, 'epoch': 0.07}
  7%|▋         | 387/5198 [1:23:42<16:31:44, 12.37s/it]  7%|▋         | 388/5198 [1:23:54<16:08:38, 12.08s/it]                                                       {'loss': 0.8979, 'learning_rate': 1.9895700160129593e-05, 'epoch': 0.07}
  7%|▋         | 388/5198 [1:23:54<16:08:38, 12.08s/it]  7%|▋         | 389/5198 [1:24:05<15:56:53, 11.94s/it]                                                       {'loss': 0.937, 'learning_rate': 1.9894800668978095e-05, 'epoch': 0.07}
  7%|▋         | 389/5198 [1:24:05<15:56:53, 11.94s/it]  8%|▊         | 390/5198 [1:24:17<15:59:51, 11.98s/it]                                                       {'loss': 0.9394, 'learning_rate': 1.9893897336324292e-05, 'epoch': 0.08}
  8%|▊         | 390/5198 [1:24:18<15:59:51, 11.98s/it]  8%|▊         | 391/5198 [1:24:30<16:17:51, 12.21s/it]                                                       {'loss': 0.9471, 'learning_rate': 1.9892990162518884e-05, 'epoch': 0.08}
  8%|▊         | 391/5198 [1:24:30<16:17:51, 12.21s/it]  8%|▊         | 392/5198 [1:24:45<17:31:55, 13.13s/it]                                                       {'loss': 0.967, 'learning_rate': 1.9892079147914072e-05, 'epoch': 0.08}
  8%|▊         | 392/5198 [1:24:46<17:31:55, 13.13s/it]  8%|▊         | 393/5198 [1:25:01<18:29:11, 13.85s/it]                                                       {'loss': 0.9176, 'learning_rate': 1.9891164292863537e-05, 'epoch': 0.08}
  8%|▊         | 393/5198 [1:25:01<18:29:11, 13.85s/it]  8%|▊         | 394/5198 [1:25:13<17:45:55, 13.31s/it]                                                       {'loss': 0.9608, 'learning_rate': 1.9890245597722465e-05, 'epoch': 0.08}
  8%|▊         | 394/5198 [1:25:13<17:45:55, 13.31s/it]  8%|▊         | 395/5198 [1:25:27<17:59:05, 13.48s/it]                                                       {'loss': 0.9259, 'learning_rate': 1.9889323062847516e-05, 'epoch': 0.08}
  8%|▊         | 395/5198 [1:25:27<17:59:05, 13.48s/it]  8%|▊         | 396/5198 [1:25:39<17:26:45, 13.08s/it]                                                       {'loss': 0.9606, 'learning_rate': 1.988839668859686e-05, 'epoch': 0.08}
  8%|▊         | 396/5198 [1:25:39<17:26:45, 13.08s/it]  8%|▊         | 397/5198 [1:25:51<17:00:05, 12.75s/it]                                                       {'loss': 0.8919, 'learning_rate': 1.988746647533014e-05, 'epoch': 0.08}
  8%|▊         | 397/5198 [1:25:51<17:00:05, 12.75s/it]  8%|▊         | 398/5198 [1:26:03<16:38:47, 12.48s/it]                                                       {'loss': 0.9646, 'learning_rate': 1.9886532423408495e-05, 'epoch': 0.08}
  8%|▊         | 398/5198 [1:26:03<16:38:47, 12.48s/it]  8%|▊         | 399/5198 [1:26:16<16:44:37, 12.56s/it]                                                       {'loss': 0.9431, 'learning_rate': 1.9885594533194564e-05, 'epoch': 0.08}
  8%|▊         | 399/5198 [1:26:16<16:44:37, 12.56s/it]  8%|▊         | 400/5198 [1:26:29<16:54:28, 12.69s/it]                                                       {'loss': 0.8812, 'learning_rate': 1.9884652805052465e-05, 'epoch': 0.08}
  8%|▊         | 400/5198 [1:26:29<16:54:28, 12.69s/it]  8%|▊         | 401/5198 [1:26:40<16:21:36, 12.28s/it]                                                       {'loss': 0.8992, 'learning_rate': 1.9883707239347804e-05, 'epoch': 0.08}
  8%|▊         | 401/5198 [1:26:40<16:21:36, 12.28s/it]  8%|▊         | 402/5198 [1:26:53<16:42:37, 12.54s/it]                                                       {'loss': 0.92, 'learning_rate': 1.988275783644769e-05, 'epoch': 0.08}
  8%|▊         | 402/5198 [1:26:53<16:42:37, 12.54s/it]  8%|▊         | 403/5198 [1:27:06<16:49:40, 12.63s/it]                                                       {'loss': 0.95, 'learning_rate': 1.988180459672071e-05, 'epoch': 0.08}
  8%|▊         | 403/5198 [1:27:06<16:49:40, 12.63s/it]  8%|▊         | 404/5198 [1:27:18<16:28:52, 12.38s/it]                                                       {'loss': 0.9369, 'learning_rate': 1.988084752053695e-05, 'epoch': 0.08}
  8%|▊         | 404/5198 [1:27:18<16:28:52, 12.38s/it]  8%|▊         | 405/5198 [1:27:30<16:22:13, 12.30s/it]                                                       {'loss': 0.9507, 'learning_rate': 1.9879886608267967e-05, 'epoch': 0.08}
  8%|▊         | 405/5198 [1:27:30<16:22:13, 12.30s/it]  8%|▊         | 406/5198 [1:27:42<16:29:07, 12.38s/it]                                                       {'loss': 0.962, 'learning_rate': 1.9878921860286832e-05, 'epoch': 0.08}
  8%|▊         | 406/5198 [1:27:43<16:29:07, 12.38s/it]  8%|▊         | 407/5198 [1:27:54<16:17:13, 12.24s/it]                                                       {'loss': 0.9016, 'learning_rate': 1.9877953276968088e-05, 'epoch': 0.08}
  8%|▊         | 407/5198 [1:27:54<16:17:13, 12.24s/it]  8%|▊         | 408/5198 [1:28:07<16:20:05, 12.28s/it]                                                       {'loss': 0.8988, 'learning_rate': 1.9876980858687777e-05, 'epoch': 0.08}
  8%|▊         | 408/5198 [1:28:07<16:20:05, 12.28s/it]  8%|▊         | 409/5198 [1:28:23<18:00:58, 13.54s/it]                                                       {'loss': 0.2983, 'learning_rate': 1.9876004605823417e-05, 'epoch': 0.08}
  8%|▊         | 409/5198 [1:28:23<18:00:58, 13.54s/it]  8%|▊         | 410/5198 [1:28:40<19:15:28, 14.48s/it]                                                       {'loss': 0.3098, 'learning_rate': 1.987502451875403e-05, 'epoch': 0.08}
  8%|▊         | 410/5198 [1:28:40<19:15:28, 14.48s/it]  8%|▊         | 411/5198 [1:28:52<18:19:31, 13.78s/it]                                                       {'loss': 0.8993, 'learning_rate': 1.987404059786012e-05, 'epoch': 0.08}
  8%|▊         | 411/5198 [1:28:52<18:19:31, 13.78s/it]  8%|▊         | 412/5198 [1:29:04<17:46:04, 13.36s/it]                                                       {'loss': 0.9289, 'learning_rate': 1.9873052843523676e-05, 'epoch': 0.08}
  8%|▊         | 412/5198 [1:29:05<17:46:04, 13.36s/it]  8%|▊         | 413/5198 [1:29:16<17:01:09, 12.80s/it]                                                       {'loss': 0.919, 'learning_rate': 1.987206125612818e-05, 'epoch': 0.08}
  8%|▊         | 413/5198 [1:29:16<17:01:09, 12.80s/it]  8%|▊         | 414/5198 [1:29:28<16:42:40, 12.58s/it]                                                       {'loss': 0.9317, 'learning_rate': 1.98710658360586e-05, 'epoch': 0.08}
  8%|▊         | 414/5198 [1:29:28<16:42:40, 12.58s/it]  8%|▊         | 415/5198 [1:29:41<16:42:36, 12.58s/it]                                                       {'loss': 0.901, 'learning_rate': 1.987006658370139e-05, 'epoch': 0.08}
  8%|▊         | 415/5198 [1:29:41<16:42:36, 12.58s/it]  8%|▊         | 416/5198 [1:29:52<16:25:51, 12.37s/it]                                                       {'loss': 0.9533, 'learning_rate': 1.9869063499444495e-05, 'epoch': 0.08}
  8%|▊         | 416/5198 [1:29:52<16:25:51, 12.37s/it]  8%|▊         | 417/5198 [1:30:07<17:22:07, 13.08s/it]                                                       {'loss': 0.9604, 'learning_rate': 1.9868056583677346e-05, 'epoch': 0.08}
  8%|▊         | 417/5198 [1:30:07<17:22:07, 13.08s/it]  8%|▊         | 418/5198 [1:30:20<17:22:43, 13.09s/it]                                                       {'loss': 0.9023, 'learning_rate': 1.9867045836790867e-05, 'epoch': 0.08}
  8%|▊         | 418/5198 [1:30:20<17:22:43, 13.09s/it]  8%|▊         | 419/5198 [1:30:33<17:22:43, 13.09s/it]                                                       {'loss': 0.9454, 'learning_rate': 1.9866031259177463e-05, 'epoch': 0.08}
  8%|▊         | 419/5198 [1:30:33<17:22:43, 13.09s/it]  8%|▊         | 420/5198 [1:30:45<16:43:45, 12.60s/it]                                                       {'loss': 0.9421, 'learning_rate': 1.9865012851231022e-05, 'epoch': 0.08}
  8%|▊         | 420/5198 [1:30:45<16:43:45, 12.60s/it]  8%|▊         | 421/5198 [1:31:00<17:51:49, 13.46s/it]                                                       {'loss': 0.9606, 'learning_rate': 1.9863990613346936e-05, 'epoch': 0.08}
  8%|▊         | 421/5198 [1:31:00<17:51:49, 13.46s/it]  8%|▊         | 422/5198 [1:31:13<17:33:32, 13.24s/it]                                                       {'loss': 0.9274, 'learning_rate': 1.986296454592206e-05, 'epoch': 0.08}
  8%|▊         | 422/5198 [1:31:13<17:33:32, 13.24s/it]  8%|▊         | 423/5198 [1:31:25<16:53:49, 12.74s/it]                                                       {'loss': 0.9591, 'learning_rate': 1.9861934649354763e-05, 'epoch': 0.08}
  8%|▊         | 423/5198 [1:31:25<16:53:49, 12.74s/it]  8%|▊         | 424/5198 [1:31:39<17:44:27, 13.38s/it]                                                       {'loss': 0.9168, 'learning_rate': 1.9860900924044873e-05, 'epoch': 0.08}
  8%|▊         | 424/5198 [1:31:40<17:44:27, 13.38s/it]  8%|▊         | 425/5198 [1:31:51<17:06:02, 12.90s/it]                                                       {'loss': 0.8341, 'learning_rate': 1.9859863370393726e-05, 'epoch': 0.08}
  8%|▊         | 425/5198 [1:31:51<17:06:02, 12.90s/it]  8%|▊         | 426/5198 [1:32:03<16:29:10, 12.44s/it]                                                       {'loss': 0.9448, 'learning_rate': 1.9858821988804132e-05, 'epoch': 0.08}
  8%|▊         | 426/5198 [1:32:03<16:29:10, 12.44s/it]  8%|▊         | 427/5198 [1:32:15<16:37:33, 12.55s/it]                                                       {'loss': 0.8953, 'learning_rate': 1.9857776779680393e-05, 'epoch': 0.08}
  8%|▊         | 427/5198 [1:32:15<16:37:33, 12.55s/it]  8%|▊         | 428/5198 [1:32:29<17:07:00, 12.92s/it]                                                       {'loss': 0.9319, 'learning_rate': 1.98567277434283e-05, 'epoch': 0.08}
  8%|▊         | 428/5198 [1:32:29<17:07:00, 12.92s/it]  8%|▊         | 429/5198 [1:32:43<17:22:50, 13.12s/it]                                                       {'loss': 0.919, 'learning_rate': 1.9855674880455115e-05, 'epoch': 0.08}
  8%|▊         | 429/5198 [1:32:43<17:22:50, 13.12s/it]  8%|▊         | 430/5198 [1:32:55<17:07:18, 12.93s/it]                                                       {'loss': 0.9756, 'learning_rate': 1.98546181911696e-05, 'epoch': 0.08}
  8%|▊         | 430/5198 [1:32:55<17:07:18, 12.93s/it]  8%|▊         | 431/5198 [1:33:08<17:05:45, 12.91s/it]                                                       {'loss': 0.9525, 'learning_rate': 1.9853557675982e-05, 'epoch': 0.08}
  8%|▊         | 431/5198 [1:33:08<17:05:45, 12.91s/it]  8%|▊         | 432/5198 [1:33:20<16:47:57, 12.69s/it]                                                       {'loss': 0.8757, 'learning_rate': 1.985249333530404e-05, 'epoch': 0.08}
  8%|▊         | 432/5198 [1:33:20<16:47:57, 12.69s/it]  8%|▊         | 433/5198 [1:33:36<17:56:03, 13.55s/it]                                                       {'loss': 0.8757, 'learning_rate': 1.9851425169548938e-05, 'epoch': 0.08}
  8%|▊         | 433/5198 [1:33:36<17:56:03, 13.55s/it]  8%|▊         | 434/5198 [1:33:52<19:04:05, 14.41s/it]                                                       {'loss': 0.323, 'learning_rate': 1.9850353179131392e-05, 'epoch': 0.08}
  8%|▊         | 434/5198 [1:33:52<19:04:05, 14.41s/it]  8%|▊         | 435/5198 [1:34:08<19:46:39, 14.95s/it]                                                       {'loss': 0.328, 'learning_rate': 1.9849277364467585e-05, 'epoch': 0.08}
  8%|▊         | 435/5198 [1:34:09<19:46:39, 14.95s/it]  8%|▊         | 436/5198 [1:34:20<18:32:52, 14.02s/it]                                                       {'loss': 0.9007, 'learning_rate': 1.984819772597518e-05, 'epoch': 0.08}
  8%|▊         | 436/5198 [1:34:20<18:32:52, 14.02s/it]  8%|▊         | 437/5198 [1:34:32<17:33:50, 13.28s/it]                                                       {'loss': 0.9242, 'learning_rate': 1.9847114264073336e-05, 'epoch': 0.08}
  8%|▊         | 437/5198 [1:34:32<17:33:50, 13.28s/it]  8%|▊         | 438/5198 [1:34:45<17:41:06, 13.38s/it]                                                       {'loss': 0.9342, 'learning_rate': 1.984602697918269e-05, 'epoch': 0.08}
  8%|▊         | 438/5198 [1:34:46<17:41:06, 13.38s/it]  8%|▊         | 439/5198 [1:34:58<17:17:21, 13.08s/it]                                                       {'loss': 0.9109, 'learning_rate': 1.9844935871725363e-05, 'epoch': 0.08}
  8%|▊         | 439/5198 [1:34:58<17:17:21, 13.08s/it]  8%|▊         | 440/5198 [1:35:10<16:57:02, 12.83s/it]                                                       {'loss': 0.8911, 'learning_rate': 1.9843840942124956e-05, 'epoch': 0.08}
  8%|▊         | 440/5198 [1:35:10<16:57:02, 12.83s/it]  8%|▊         | 441/5198 [1:35:22<16:25:58, 12.44s/it]                                                       {'loss': 0.9779, 'learning_rate': 1.9842742190806566e-05, 'epoch': 0.08}
  8%|▊         | 441/5198 [1:35:22<16:25:58, 12.44s/it]  9%|▊         | 442/5198 [1:35:34<16:23:38, 12.41s/it]                                                       {'loss': 0.9076, 'learning_rate': 1.984163961819676e-05, 'epoch': 0.09}
  9%|▊         | 442/5198 [1:35:34<16:23:38, 12.41s/it]  9%|▊         | 443/5198 [1:35:47<16:42:24, 12.65s/it]                                                       {'loss': 0.9241, 'learning_rate': 1.9840533224723595e-05, 'epoch': 0.09}
  9%|▊         | 443/5198 [1:35:47<16:42:24, 12.65s/it]  9%|▊         | 444/5198 [1:36:00<16:34:17, 12.55s/it]                                                       {'loss': 0.9191, 'learning_rate': 1.9839423010816616e-05, 'epoch': 0.09}
  9%|▊         | 444/5198 [1:36:00<16:34:17, 12.55s/it]  9%|▊         | 445/5198 [1:36:12<16:40:05, 12.62s/it]                                                       {'loss': 0.9329, 'learning_rate': 1.983830897690684e-05, 'epoch': 0.09}
  9%|▊         | 445/5198 [1:36:12<16:40:05, 12.62s/it]  9%|▊         | 446/5198 [1:36:26<17:09:48, 13.00s/it]                                                       {'loss': 0.9299, 'learning_rate': 1.9837191123426777e-05, 'epoch': 0.09}
  9%|▊         | 446/5198 [1:36:26<17:09:48, 13.00s/it]  9%|▊         | 447/5198 [1:36:38<16:52:31, 12.79s/it]                                                       {'loss': 0.9425, 'learning_rate': 1.983606945081042e-05, 'epoch': 0.09}
  9%|▊         | 447/5198 [1:36:39<16:52:31, 12.79s/it]  9%|▊         | 448/5198 [1:36:51<16:48:15, 12.74s/it]                                                       {'loss': 0.9278, 'learning_rate': 1.983494395949323e-05, 'epoch': 0.09}
  9%|▊         | 448/5198 [1:36:51<16:48:15, 12.74s/it]  9%|▊         | 449/5198 [1:37:04<16:56:52, 12.85s/it]                                                       {'loss': 0.933, 'learning_rate': 1.983381464991217e-05, 'epoch': 0.09}
  9%|▊         | 449/5198 [1:37:04<16:56:52, 12.85s/it]  9%|▊         | 450/5198 [1:37:17<16:52:01, 12.79s/it]                                                       {'loss': 0.8651, 'learning_rate': 1.9832681522505676e-05, 'epoch': 0.09}
  9%|▊         | 450/5198 [1:37:17<16:52:01, 12.79s/it]  9%|▊         | 451/5198 [1:37:29<16:31:32, 12.53s/it]                                                       {'loss': 0.979, 'learning_rate': 1.9831544577713663e-05, 'epoch': 0.09}
  9%|▊         | 451/5198 [1:37:29<16:31:32, 12.53s/it]  9%|▊         | 452/5198 [1:37:41<16:23:28, 12.43s/it]                                                       {'loss': 0.9435, 'learning_rate': 1.983040381597754e-05, 'epoch': 0.09}
  9%|▊         | 452/5198 [1:37:41<16:23:28, 12.43s/it]  9%|▊         | 453/5198 [1:37:53<16:04:30, 12.20s/it]                                                       {'loss': 0.8631, 'learning_rate': 1.982925923774018e-05, 'epoch': 0.09}
  9%|▊         | 453/5198 [1:37:53<16:04:30, 12.20s/it]  9%|▊         | 454/5198 [1:38:05<16:04:46, 12.20s/it]                                                       {'loss': 0.8856, 'learning_rate': 1.9828110843445954e-05, 'epoch': 0.09}
  9%|▊         | 454/5198 [1:38:05<16:04:46, 12.20s/it]  9%|▉         | 455/5198 [1:38:17<16:14:45, 12.33s/it]                                                       {'loss': 0.9068, 'learning_rate': 1.982695863354071e-05, 'epoch': 0.09}
  9%|▉         | 455/5198 [1:38:18<16:14:45, 12.33s/it]  9%|▉         | 456/5198 [1:38:30<16:09:49, 12.27s/it]                                                       {'loss': 0.8852, 'learning_rate': 1.9825802608471767e-05, 'epoch': 0.09}
  9%|▉         | 456/5198 [1:38:30<16:09:49, 12.27s/it]  9%|▉         | 457/5198 [1:38:41<15:59:59, 12.15s/it]                                                       {'loss': 0.9557, 'learning_rate': 1.982464276868794e-05, 'epoch': 0.09}
  9%|▉         | 457/5198 [1:38:42<15:59:59, 12.15s/it]  9%|▉         | 458/5198 [1:38:55<16:42:18, 12.69s/it]                                                       {'loss': 0.9403, 'learning_rate': 1.982347911463952e-05, 'epoch': 0.09}
  9%|▉         | 458/5198 [1:38:55<16:42:18, 12.69s/it]  9%|▉         | 459/5198 [1:39:09<17:06:15, 12.99s/it]                                                       {'loss': 0.9089, 'learning_rate': 1.9822311646778277e-05, 'epoch': 0.09}
  9%|▉         | 459/5198 [1:39:09<17:06:15, 12.99s/it]  9%|▉         | 460/5198 [1:39:22<17:00:29, 12.92s/it]                                                       {'loss': 0.9113, 'learning_rate': 1.982114036555746e-05, 'epoch': 0.09}
  9%|▉         | 460/5198 [1:39:22<17:00:29, 12.92s/it]  9%|▉         | 461/5198 [1:39:35<16:57:19, 12.89s/it]                                                       {'loss': 0.8848, 'learning_rate': 1.9819965271431797e-05, 'epoch': 0.09}
  9%|▉         | 461/5198 [1:39:35<16:57:19, 12.89s/it]WARNING: tokenization mismatch: 1 vs. 70. (ignored)
  9%|▉         | 462/5198 [1:39:46<16:26:45, 12.50s/it]                                                       {'loss': 0.9166, 'learning_rate': 1.9818786364857506e-05, 'epoch': 0.09}
  9%|▉         | 462/5198 [1:39:46<16:26:45, 12.50s/it]  9%|▉         | 463/5198 [1:39:59<16:35:59, 12.62s/it]                                                       {'loss': 0.9322, 'learning_rate': 1.9817603646292278e-05, 'epoch': 0.09}
  9%|▉         | 463/5198 [1:39:59<16:35:59, 12.62s/it]  9%|▉         | 464/5198 [1:40:13<17:07:20, 13.02s/it]                                                       {'loss': 0.8971, 'learning_rate': 1.9816417116195287e-05, 'epoch': 0.09}
  9%|▉         | 464/5198 [1:40:13<17:07:20, 13.02s/it]  9%|▉         | 465/5198 [1:40:28<17:58:44, 13.68s/it]                                                       {'loss': 0.9247, 'learning_rate': 1.9815226775027182e-05, 'epoch': 0.09}
  9%|▉         | 465/5198 [1:40:28<17:58:44, 13.68s/it]  9%|▉         | 466/5198 [1:40:40<17:19:51, 13.18s/it]                                                       {'loss': 0.9864, 'learning_rate': 1.9814032623250093e-05, 'epoch': 0.09}
  9%|▉         | 466/5198 [1:40:40<17:19:51, 13.18s/it]  9%|▉         | 467/5198 [1:40:55<17:52:30, 13.60s/it]                                                       {'loss': 0.8975, 'learning_rate': 1.9812834661327632e-05, 'epoch': 0.09}
  9%|▉         | 467/5198 [1:40:55<17:52:30, 13.60s/it]  9%|▉         | 468/5198 [1:41:07<17:21:17, 13.21s/it]                                                       {'loss': 0.8633, 'learning_rate': 1.9811632889724888e-05, 'epoch': 0.09}
  9%|▉         | 468/5198 [1:41:07<17:21:17, 13.21s/it]  9%|▉         | 469/5198 [1:41:21<17:42:51, 13.49s/it]                                                       {'loss': 0.8445, 'learning_rate': 1.9810427308908437e-05, 'epoch': 0.09}
  9%|▉         | 469/5198 [1:41:21<17:42:51, 13.49s/it]  9%|▉         | 470/5198 [1:41:34<17:16:19, 13.15s/it]                                                       {'loss': 0.8443, 'learning_rate': 1.9809217919346318e-05, 'epoch': 0.09}
  9%|▉         | 470/5198 [1:41:34<17:16:19, 13.15s/it]  9%|▉         | 471/5198 [1:41:46<16:43:53, 12.74s/it]                                                       {'loss': 0.9777, 'learning_rate': 1.980800472150806e-05, 'epoch': 0.09}
  9%|▉         | 471/5198 [1:41:46<16:43:53, 12.74s/it]  9%|▉         | 472/5198 [1:41:57<16:19:17, 12.43s/it]                                                       {'loss': 0.9214, 'learning_rate': 1.9806787715864674e-05, 'epoch': 0.09}
  9%|▉         | 472/5198 [1:41:57<16:19:17, 12.43s/it]  9%|▉         | 473/5198 [1:42:09<16:12:11, 12.35s/it]                                                       {'loss': 0.9584, 'learning_rate': 1.9805566902888637e-05, 'epoch': 0.09}
  9%|▉         | 473/5198 [1:42:10<16:12:11, 12.35s/it]  9%|▉         | 474/5198 [1:42:22<16:11:57, 12.34s/it]                                                       {'loss': 0.9404, 'learning_rate': 1.9804342283053916e-05, 'epoch': 0.09}
  9%|▉         | 474/5198 [1:42:22<16:11:57, 12.34s/it]  9%|▉         | 475/5198 [1:42:33<15:57:19, 12.16s/it]                                                       {'loss': 0.9839, 'learning_rate': 1.980311385683594e-05, 'epoch': 0.09}
  9%|▉         | 475/5198 [1:42:34<15:57:19, 12.16s/it]  9%|▉         | 476/5198 [1:42:47<16:37:35, 12.68s/it]                                                       {'loss': 0.9377, 'learning_rate': 1.980188162471164e-05, 'epoch': 0.09}
  9%|▉         | 476/5198 [1:42:47<16:37:35, 12.68s/it]  9%|▉         | 477/5198 [1:42:59<16:20:29, 12.46s/it]                                                       {'loss': 0.924, 'learning_rate': 1.98006455871594e-05, 'epoch': 0.09}
  9%|▉         | 477/5198 [1:42:59<16:20:29, 12.46s/it]  9%|▉         | 478/5198 [1:43:11<16:07:19, 12.30s/it]                                                       {'loss': 0.875, 'learning_rate': 1.97994057446591e-05, 'epoch': 0.09}
  9%|▉         | 478/5198 [1:43:11<16:07:19, 12.30s/it]  9%|▉         | 479/5198 [1:43:24<16:16:06, 12.41s/it]                                                       {'loss': 0.913, 'learning_rate': 1.979816209769209e-05, 'epoch': 0.09}
  9%|▉         | 479/5198 [1:43:24<16:16:06, 12.41s/it]  9%|▉         | 480/5198 [1:43:37<16:24:07, 12.52s/it]                                                       {'loss': 0.8639, 'learning_rate': 1.9796914646741187e-05, 'epoch': 0.09}
  9%|▉         | 480/5198 [1:43:37<16:24:07, 12.52s/it]  9%|▉         | 481/5198 [1:43:48<15:59:23, 12.20s/it]                                                       {'loss': 0.9108, 'learning_rate': 1.9795663392290702e-05, 'epoch': 0.09}
  9%|▉         | 481/5198 [1:43:48<15:59:23, 12.20s/it]  9%|▉         | 482/5198 [1:44:00<15:50:32, 12.09s/it]                                                       {'loss': 0.8537, 'learning_rate': 1.9794408334826415e-05, 'epoch': 0.09}
  9%|▉         | 482/5198 [1:44:00<15:50:32, 12.09s/it]  9%|▉         | 483/5198 [1:44:12<15:58:14, 12.19s/it]                                                       {'loss': 0.9268, 'learning_rate': 1.979314947483558e-05, 'epoch': 0.09}
  9%|▉         | 483/5198 [1:44:12<15:58:14, 12.19s/it]  9%|▉         | 484/5198 [1:44:24<15:50:23, 12.10s/it]                                                       {'loss': 0.9716, 'learning_rate': 1.9791886812806932e-05, 'epoch': 0.09}
  9%|▉         | 484/5198 [1:44:24<15:50:23, 12.10s/it]  9%|▉         | 485/5198 [1:44:36<15:38:59, 11.95s/it]                                                       {'loss': 0.8794, 'learning_rate': 1.9790620349230676e-05, 'epoch': 0.09}
  9%|▉         | 485/5198 [1:44:36<15:38:59, 11.95s/it]  9%|▉         | 486/5198 [1:44:49<15:57:12, 12.19s/it]                                                       {'loss': 0.9203, 'learning_rate': 1.9789350084598504e-05, 'epoch': 0.09}
  9%|▉         | 486/5198 [1:44:49<15:57:12, 12.19s/it]  9%|▉         | 487/5198 [1:45:01<15:49:26, 12.09s/it]                                                       {'loss': 0.8683, 'learning_rate': 1.9788076019403565e-05, 'epoch': 0.09}
  9%|▉         | 487/5198 [1:45:01<15:49:26, 12.09s/it]  9%|▉         | 488/5198 [1:45:13<15:49:56, 12.10s/it]                                                       {'loss': 0.9577, 'learning_rate': 1.9786798154140507e-05, 'epoch': 0.09}
  9%|▉         | 488/5198 [1:45:13<15:49:56, 12.10s/it]  9%|▉         | 489/5198 [1:45:30<17:49:31, 13.63s/it]                                                       {'loss': 0.4055, 'learning_rate': 1.9785516489305437e-05, 'epoch': 0.09}
  9%|▉         | 489/5198 [1:45:30<17:49:31, 13.63s/it]  9%|▉         | 490/5198 [1:45:42<17:14:31, 13.18s/it]                                                       {'loss': 0.9272, 'learning_rate': 1.9784231025395936e-05, 'epoch': 0.09}
  9%|▉         | 490/5198 [1:45:42<17:14:31, 13.18s/it]  9%|▉         | 491/5198 [1:45:55<17:07:05, 13.09s/it]                                                       {'loss': 0.9303, 'learning_rate': 1.9782941762911075e-05, 'epoch': 0.09}
  9%|▉         | 491/5198 [1:45:55<17:07:05, 13.09s/it]  9%|▉         | 492/5198 [1:46:08<17:05:40, 13.08s/it]                                                       {'loss': 0.933, 'learning_rate': 1.9781648702351383e-05, 'epoch': 0.09}
  9%|▉         | 492/5198 [1:46:08<17:05:40, 13.08s/it]  9%|▉         | 493/5198 [1:46:23<17:50:42, 13.65s/it]                                                       {'loss': 0.9395, 'learning_rate': 1.9780351844218874e-05, 'epoch': 0.09}
  9%|▉         | 493/5198 [1:46:23<17:50:42, 13.65s/it] 10%|▉         | 494/5198 [1:46:35<17:18:06, 13.24s/it]                                                       {'loss': 0.904, 'learning_rate': 1.977905118901703e-05, 'epoch': 0.1}
 10%|▉         | 494/5198 [1:46:35<17:18:06, 13.24s/it] 10%|▉         | 495/5198 [1:46:47<16:48:21, 12.86s/it]                                                       {'loss': 0.8869, 'learning_rate': 1.977774673725081e-05, 'epoch': 0.1}
 10%|▉         | 495/5198 [1:46:47<16:48:21, 12.86s/it] 10%|▉         | 496/5198 [1:47:05<18:40:59, 14.30s/it]                                                       {'loss': 0.3501, 'learning_rate': 1.977643848942665e-05, 'epoch': 0.1}
 10%|▉         | 496/5198 [1:47:05<18:40:59, 14.30s/it] 10%|▉         | 497/5198 [1:47:17<17:47:07, 13.62s/it]                                                       {'loss': 0.8917, 'learning_rate': 1.977512644605246e-05, 'epoch': 0.1}
 10%|▉         | 497/5198 [1:47:17<17:47:07, 13.62s/it] 10%|▉         | 498/5198 [1:47:29<17:12:37, 13.18s/it]                                                       {'loss': 0.8825, 'learning_rate': 1.9773810607637612e-05, 'epoch': 0.1}
 10%|▉         | 498/5198 [1:47:29<17:12:37, 13.18s/it] 10%|▉         | 499/5198 [1:47:41<16:53:55, 12.95s/it]                                                       {'loss': 0.9261, 'learning_rate': 1.9772490974692962e-05, 'epoch': 0.1}
 10%|▉         | 499/5198 [1:47:41<16:53:55, 12.95s/it] 10%|▉         | 500/5198 [1:47:53<16:29:16, 12.63s/it]                                                       {'loss': 0.9543, 'learning_rate': 1.9771167547730844e-05, 'epoch': 0.1}
 10%|▉         | 500/5198 [1:47:53<16:29:16, 12.63s/it] 10%|▉         | 501/5198 [1:48:06<16:25:21, 12.59s/it]                                                       {'loss': 0.957, 'learning_rate': 1.976984032726505e-05, 'epoch': 0.1}
 10%|▉         | 501/5198 [1:48:06<16:25:21, 12.59s/it] 10%|▉         | 502/5198 [1:48:18<16:26:25, 12.60s/it]                                                       {'loss': 0.9483, 'learning_rate': 1.976850931381086e-05, 'epoch': 0.1}
 10%|▉         | 502/5198 [1:48:18<16:26:25, 12.60s/it] 10%|▉         | 503/5198 [1:48:29<15:50:07, 12.14s/it]                                                       {'loss': 0.9034, 'learning_rate': 1.976717450788501e-05, 'epoch': 0.1}
 10%|▉         | 503/5198 [1:48:30<15:50:07, 12.14s/it] 10%|▉         | 504/5198 [1:48:41<15:36:46, 11.97s/it]                                                       {'loss': 0.8793, 'learning_rate': 1.9765835910005726e-05, 'epoch': 0.1}
 10%|▉         | 504/5198 [1:48:41<15:36:46, 11.97s/it] 10%|▉         | 505/5198 [1:48:54<16:09:56, 12.40s/it]                                                       {'loss': 0.8767, 'learning_rate': 1.9764493520692685e-05, 'epoch': 0.1}
 10%|▉         | 505/5198 [1:48:55<16:09:56, 12.40s/it] 10%|▉         | 506/5198 [1:49:07<16:03:53, 12.33s/it]                                                       {'loss': 1.0008, 'learning_rate': 1.9763147340467067e-05, 'epoch': 0.1}
 10%|▉         | 506/5198 [1:49:07<16:03:53, 12.33s/it] 10%|▉         | 507/5198 [1:49:19<15:53:31, 12.20s/it]                                                       {'loss': 0.8709, 'learning_rate': 1.9761797369851498e-05, 'epoch': 0.1}
 10%|▉         | 507/5198 [1:49:19<15:53:31, 12.20s/it] 10%|▉         | 508/5198 [1:49:31<16:11:47, 12.43s/it]                                                       {'loss': 0.8949, 'learning_rate': 1.9760443609370074e-05, 'epoch': 0.1}
 10%|▉         | 508/5198 [1:49:32<16:11:47, 12.43s/it] 10%|▉         | 509/5198 [1:49:44<16:20:41, 12.55s/it]                                                       {'loss': 0.91, 'learning_rate': 1.975908605954838e-05, 'epoch': 0.1}
 10%|▉         | 509/5198 [1:49:44<16:20:41, 12.55s/it] 10%|▉         | 510/5198 [1:49:57<16:14:57, 12.48s/it]                                                       {'loss': 0.9467, 'learning_rate': 1.9757724720913466e-05, 'epoch': 0.1}
 10%|▉         | 510/5198 [1:49:57<16:14:57, 12.48s/it] 10%|▉         | 511/5198 [1:50:08<15:54:13, 12.22s/it]                                                       {'loss': 0.9137, 'learning_rate': 1.9756359593993845e-05, 'epoch': 0.1}
 10%|▉         | 511/5198 [1:50:08<15:54:13, 12.22s/it] 10%|▉         | 512/5198 [1:50:25<17:34:40, 13.50s/it]                                                       {'loss': 0.3061, 'learning_rate': 1.975499067931951e-05, 'epoch': 0.1}
 10%|▉         | 512/5198 [1:50:25<17:34:40, 13.50s/it] 10%|▉         | 513/5198 [1:50:36<16:50:51, 12.95s/it]                                                       {'loss': 0.9571, 'learning_rate': 1.975361797742192e-05, 'epoch': 0.1}
 10%|▉         | 513/5198 [1:50:36<16:50:51, 12.95s/it] 10%|▉         | 514/5198 [1:50:51<17:18:18, 13.30s/it]                                                       {'loss': 0.9313, 'learning_rate': 1.9752241488834002e-05, 'epoch': 0.1}
 10%|▉         | 514/5198 [1:50:51<17:18:18, 13.30s/it] 10%|▉         | 515/5198 [1:51:03<16:55:23, 13.01s/it]                                                       {'loss': 0.9226, 'learning_rate': 1.975086121409016e-05, 'epoch': 0.1}
 10%|▉         | 515/5198 [1:51:03<16:55:23, 13.01s/it] 10%|▉         | 516/5198 [1:51:16<17:06:55, 13.16s/it]                                                       {'loss': 0.8724, 'learning_rate': 1.974947715372626e-05, 'epoch': 0.1}
 10%|▉         | 516/5198 [1:51:16<17:06:55, 13.16s/it] 10%|▉         | 517/5198 [1:51:30<17:25:33, 13.40s/it]                                                       {'loss': 0.8638, 'learning_rate': 1.974808930827965e-05, 'epoch': 0.1}
 10%|▉         | 517/5198 [1:51:30<17:25:33, 13.40s/it] 10%|▉         | 518/5198 [1:51:43<17:01:54, 13.10s/it]                                                       {'loss': 0.9022, 'learning_rate': 1.9746697678289128e-05, 'epoch': 0.1}
 10%|▉         | 518/5198 [1:51:43<17:01:54, 13.10s/it] 10%|▉         | 519/5198 [1:51:54<16:30:12, 12.70s/it]                                                       {'loss': 0.9117, 'learning_rate': 1.9745302264294982e-05, 'epoch': 0.1}
 10%|▉         | 519/5198 [1:51:55<16:30:12, 12.70s/it] 10%|█         | 520/5198 [1:52:07<16:14:54, 12.50s/it]                                                       {'loss': 0.9164, 'learning_rate': 1.9743903066838954e-05, 'epoch': 0.1}
 10%|█         | 520/5198 [1:52:07<16:14:54, 12.50s/it] 10%|█         | 521/5198 [1:52:20<16:31:07, 12.71s/it]                                                       {'loss': 0.936, 'learning_rate': 1.9742500086464266e-05, 'epoch': 0.1}
 10%|█         | 521/5198 [1:52:20<16:31:07, 12.71s/it] 10%|█         | 522/5198 [1:52:36<17:55:31, 13.80s/it]                                                       {'loss': 0.3267, 'learning_rate': 1.9741093323715597e-05, 'epoch': 0.1}
 10%|█         | 522/5198 [1:52:36<17:55:31, 13.80s/it] 10%|█         | 523/5198 [1:52:48<17:05:43, 13.16s/it]                                                       {'loss': 0.9373, 'learning_rate': 1.9739682779139107e-05, 'epoch': 0.1}
 10%|█         | 523/5198 [1:52:48<17:05:43, 13.16s/it] 10%|█         | 524/5198 [1:53:01<16:58:17, 13.07s/it]                                                       {'loss': 0.9075, 'learning_rate': 1.9738268453282414e-05, 'epoch': 0.1}
 10%|█         | 524/5198 [1:53:01<16:58:17, 13.07s/it] 10%|█         | 525/5198 [1:53:12<16:25:16, 12.65s/it]                                                       {'loss': 0.9338, 'learning_rate': 1.9736850346694608e-05, 'epoch': 0.1}
 10%|█         | 525/5198 [1:53:12<16:25:16, 12.65s/it] 10%|█         | 526/5198 [1:53:24<15:55:03, 12.27s/it]                                                       {'loss': 0.9445, 'learning_rate': 1.973542845992625e-05, 'epoch': 0.1}
 10%|█         | 526/5198 [1:53:24<15:55:03, 12.27s/it] 10%|█         | 527/5198 [1:53:36<15:54:08, 12.26s/it]                                                       {'loss': 0.8805, 'learning_rate': 1.9734002793529362e-05, 'epoch': 0.1}
 10%|█         | 527/5198 [1:53:36<15:54:08, 12.26s/it] 10%|█         | 528/5198 [1:53:51<17:08:50, 13.22s/it]                                                       {'loss': 0.8861, 'learning_rate': 1.9732573348057437e-05, 'epoch': 0.1}
 10%|█         | 528/5198 [1:53:51<17:08:50, 13.22s/it] 10%|█         | 529/5198 [1:54:03<16:40:56, 12.86s/it]                                                       {'loss': 0.9669, 'learning_rate': 1.973114012406544e-05, 'epoch': 0.1}
 10%|█         | 529/5198 [1:54:03<16:40:56, 12.86s/it] 10%|█         | 530/5198 [1:54:16<16:27:09, 12.69s/it]                                                       {'loss': 0.9124, 'learning_rate': 1.9729703122109788e-05, 'epoch': 0.1}
 10%|█         | 530/5198 [1:54:16<16:27:09, 12.69s/it] 10%|█         | 531/5198 [1:54:28<16:14:04, 12.52s/it]                                                       {'loss': 0.8615, 'learning_rate': 1.9728262342748384e-05, 'epoch': 0.1}
 10%|█         | 531/5198 [1:54:28<16:14:04, 12.52s/it] 10%|█         | 532/5198 [1:54:39<15:47:14, 12.18s/it]                                                       {'loss': 0.9266, 'learning_rate': 1.9726817786540584e-05, 'epoch': 0.1}
 10%|█         | 532/5198 [1:54:39<15:47:14, 12.18s/it] 10%|█         | 533/5198 [1:54:51<15:45:35, 12.16s/it]                                                       {'loss': 0.927, 'learning_rate': 1.9725369454047215e-05, 'epoch': 0.1}
 10%|█         | 533/5198 [1:54:51<15:45:35, 12.16s/it] 10%|█         | 534/5198 [1:55:04<15:49:43, 12.22s/it]                                                       {'loss': 0.9626, 'learning_rate': 1.9723917345830568e-05, 'epoch': 0.1}
 10%|█         | 534/5198 [1:55:04<15:49:43, 12.22s/it] 10%|█         | 535/5198 [1:55:18<16:32:10, 12.77s/it]                                                       {'loss': 0.8962, 'learning_rate': 1.9722461462454405e-05, 'epoch': 0.1}
 10%|█         | 535/5198 [1:55:18<16:32:10, 12.77s/it] 10%|█         | 536/5198 [1:55:31<16:36:20, 12.82s/it]                                                       {'loss': 0.8935, 'learning_rate': 1.9721001804483947e-05, 'epoch': 0.1}
 10%|█         | 536/5198 [1:55:31<16:36:20, 12.82s/it] 10%|█         | 537/5198 [1:55:43<16:33:56, 12.79s/it]                                                       {'loss': 0.9878, 'learning_rate': 1.9719538372485887e-05, 'epoch': 0.1}
 10%|█         | 537/5198 [1:55:43<16:33:56, 12.79s/it] 10%|█         | 538/5198 [1:55:55<16:04:12, 12.41s/it]                                                       {'loss': 0.8769, 'learning_rate': 1.9718071167028376e-05, 'epoch': 0.1}
 10%|█         | 538/5198 [1:55:55<16:04:12, 12.41s/it] 10%|█         | 539/5198 [1:56:06<15:41:40, 12.13s/it]                                                       {'loss': 0.897, 'learning_rate': 1.9716600188681038e-05, 'epoch': 0.1}
 10%|█         | 539/5198 [1:56:06<15:41:40, 12.13s/it] 10%|█         | 540/5198 [1:56:20<16:21:54, 12.65s/it]                                                       {'loss': 0.9086, 'learning_rate': 1.971512543801495e-05, 'epoch': 0.1}
 10%|█         | 540/5198 [1:56:20<16:21:54, 12.65s/it] 10%|█         | 541/5198 [1:56:32<16:01:59, 12.39s/it]                                                       {'loss': 0.9307, 'learning_rate': 1.9713646915602663e-05, 'epoch': 0.1}
 10%|█         | 541/5198 [1:56:32<16:01:59, 12.39s/it] 10%|█         | 542/5198 [1:56:47<16:59:13, 13.13s/it]                                                       {'loss': 0.9101, 'learning_rate': 1.9712164622018197e-05, 'epoch': 0.1}
 10%|█         | 542/5198 [1:56:47<16:59:13, 13.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2316 > 2048). Running this sequence through the model will result in indexing errors
 10%|█         | 543/5198 [1:57:00<16:57:01, 13.11s/it]                                                       {'loss': 0.8718, 'learning_rate': 1.9710678557837024e-05, 'epoch': 0.1}
 10%|█         | 543/5198 [1:57:00<16:57:01, 13.11s/it] 10%|█         | 544/5198 [1:57:11<16:19:02, 12.62s/it]                                                       {'loss': 0.9096, 'learning_rate': 1.9709188723636088e-05, 'epoch': 0.1}
 10%|█         | 544/5198 [1:57:11<16:19:02, 12.62s/it] 10%|█         | 545/5198 [1:57:25<16:37:37, 12.86s/it]                                                       {'loss': 0.9107, 'learning_rate': 1.970769511999379e-05, 'epoch': 0.1}
 10%|█         | 545/5198 [1:57:25<16:37:37, 12.86s/it] 11%|█         | 546/5198 [1:57:37<16:25:54, 12.72s/it]                                                       {'loss': 0.8978, 'learning_rate': 1.9706197747490004e-05, 'epoch': 0.11}
 11%|█         | 546/5198 [1:57:37<16:25:54, 12.72s/it] 11%|█         | 547/5198 [1:57:52<17:03:05, 13.20s/it]                                                       {'loss': 0.9012, 'learning_rate': 1.9704696606706055e-05, 'epoch': 0.11}
 11%|█         | 547/5198 [1:57:52<17:03:05, 13.20s/it] 11%|█         | 548/5198 [1:58:07<17:47:11, 13.77s/it]                                                       {'loss': 0.934, 'learning_rate': 1.9703191698224742e-05, 'epoch': 0.11}
 11%|█         | 548/5198 [1:58:07<17:47:11, 13.77s/it] 11%|█         | 549/5198 [1:58:19<17:11:45, 13.32s/it]                                                       {'loss': 0.9397, 'learning_rate': 1.9701683022630323e-05, 'epoch': 0.11}
 11%|█         | 549/5198 [1:58:19<17:11:45, 13.32s/it] 11%|█         | 550/5198 [1:58:31<16:33:27, 12.82s/it]                                                       {'loss': 0.9508, 'learning_rate': 1.9700170580508514e-05, 'epoch': 0.11}
 11%|█         | 550/5198 [1:58:31<16:33:27, 12.82s/it] 11%|█         | 551/5198 [1:58:42<16:11:50, 12.55s/it]                                                       {'loss': 0.9223, 'learning_rate': 1.9698654372446495e-05, 'epoch': 0.11}
 11%|█         | 551/5198 [1:58:43<16:11:50, 12.55s/it] 11%|█         | 552/5198 [1:58:58<17:18:58, 13.42s/it]                                                       {'loss': 0.9119, 'learning_rate': 1.969713439903292e-05, 'epoch': 0.11}
 11%|█         | 552/5198 [1:58:58<17:18:58, 13.42s/it] 11%|█         | 553/5198 [1:59:10<16:48:07, 13.02s/it]                                                       {'loss': 0.9015, 'learning_rate': 1.9695610660857886e-05, 'epoch': 0.11}
 11%|█         | 553/5198 [1:59:10<16:48:07, 13.02s/it] 11%|█         | 554/5198 [1:59:22<16:21:57, 12.69s/it]                                                       {'loss': 0.951, 'learning_rate': 1.9694083158512965e-05, 'epoch': 0.11}
 11%|█         | 554/5198 [1:59:22<16:21:57, 12.69s/it] 11%|█         | 555/5198 [1:59:35<16:39:42, 12.92s/it]                                                       {'loss': 0.952, 'learning_rate': 1.9692551892591185e-05, 'epoch': 0.11}
 11%|█         | 555/5198 [1:59:35<16:39:42, 12.92s/it] 11%|█         | 556/5198 [1:59:48<16:30:38, 12.80s/it]                                                       {'loss': 0.9463, 'learning_rate': 1.9691016863687037e-05, 'epoch': 0.11}
 11%|█         | 556/5198 [1:59:48<16:30:38, 12.80s/it] 11%|█         | 557/5198 [2:00:00<16:21:08, 12.68s/it]                                                       {'loss': 0.8704, 'learning_rate': 1.968947807239647e-05, 'epoch': 0.11}
 11%|█         | 557/5198 [2:00:00<16:21:08, 12.68s/it] 11%|█         | 558/5198 [2:00:12<16:04:18, 12.47s/it]                                                       {'loss': 0.886, 'learning_rate': 1.9687935519316897e-05, 'epoch': 0.11}
 11%|█         | 558/5198 [2:00:12<16:04:18, 12.47s/it] 11%|█         | 559/5198 [2:00:26<16:38:49, 12.92s/it]                                                       {'loss': 0.896, 'learning_rate': 1.9686389205047186e-05, 'epoch': 0.11}
 11%|█         | 559/5198 [2:00:26<16:38:49, 12.92s/it] 11%|█         | 560/5198 [2:00:38<16:07:39, 12.52s/it]                                                       {'loss': 0.9377, 'learning_rate': 1.9684839130187678e-05, 'epoch': 0.11}
 11%|█         | 560/5198 [2:00:38<16:07:39, 12.52s/it] 11%|█         | 561/5198 [2:00:50<15:50:32, 12.30s/it]                                                       {'loss': 0.8799, 'learning_rate': 1.968328529534016e-05, 'epoch': 0.11}
 11%|█         | 561/5198 [2:00:50<15:50:32, 12.30s/it] 11%|█         | 562/5198 [2:01:02<15:51:46, 12.32s/it]                                                       {'loss': 0.8998, 'learning_rate': 1.9681727701107885e-05, 'epoch': 0.11}
 11%|█         | 562/5198 [2:01:02<15:51:46, 12.32s/it] 11%|█         | 563/5198 [2:01:15<16:09:32, 12.55s/it]                                                       {'loss': 0.8785, 'learning_rate': 1.9680166348095568e-05, 'epoch': 0.11}
 11%|█         | 563/5198 [2:01:15<16:09:32, 12.55s/it] 11%|█         | 564/5198 [2:01:28<16:09:22, 12.55s/it]                                                       {'loss': 0.866, 'learning_rate': 1.967860123690937e-05, 'epoch': 0.11}
 11%|█         | 564/5198 [2:01:28<16:09:22, 12.55s/it] 11%|█         | 565/5198 [2:01:41<16:23:50, 12.74s/it]                                                       {'loss': 0.8901, 'learning_rate': 1.9677032368156934e-05, 'epoch': 0.11}
 11%|█         | 565/5198 [2:01:41<16:23:50, 12.74s/it] 11%|█         | 566/5198 [2:01:54<16:41:16, 12.97s/it]                                                       {'loss': 0.8922, 'learning_rate': 1.967545974244734e-05, 'epoch': 0.11}
 11%|█         | 566/5198 [2:01:54<16:41:16, 12.97s/it] 11%|█         | 567/5198 [2:02:06<16:06:30, 12.52s/it]                                                       {'loss': 0.9504, 'learning_rate': 1.9673883360391138e-05, 'epoch': 0.11}
 11%|█         | 567/5198 [2:02:06<16:06:30, 12.52s/it] 11%|█         | 568/5198 [2:02:20<16:52:37, 13.12s/it]                                                       {'loss': 0.9287, 'learning_rate': 1.9672303222600333e-05, 'epoch': 0.11}
 11%|█         | 568/5198 [2:02:20<16:52:37, 13.12s/it] 11%|█         | 569/5198 [2:02:32<16:20:29, 12.71s/it]                                                       {'loss': 0.947, 'learning_rate': 1.967071932968839e-05, 'epoch': 0.11}
 11%|█         | 569/5198 [2:02:32<16:20:29, 12.71s/it] 11%|█         | 570/5198 [2:02:48<17:25:40, 13.56s/it]                                                       {'loss': 0.8443, 'learning_rate': 1.9669131682270232e-05, 'epoch': 0.11}
 11%|█         | 570/5198 [2:02:48<17:25:40, 13.56s/it] 11%|█         | 571/5198 [2:03:00<16:59:37, 13.22s/it]                                                       {'loss': 0.8477, 'learning_rate': 1.9667540280962235e-05, 'epoch': 0.11}
 11%|█         | 571/5198 [2:03:00<16:59:37, 13.22s/it] 11%|█         | 572/5198 [2:03:12<16:32:57, 12.88s/it]                                                       {'loss': 0.9265, 'learning_rate': 1.966594512638224e-05, 'epoch': 0.11}
 11%|█         | 572/5198 [2:03:12<16:32:57, 12.88s/it] 11%|█         | 573/5198 [2:03:24<16:06:56, 12.54s/it]                                                       {'loss': 0.9173, 'learning_rate': 1.9664346219149538e-05, 'epoch': 0.11}
 11%|█         | 573/5198 [2:03:24<16:06:56, 12.54s/it] 11%|█         | 574/5198 [2:03:36<15:57:21, 12.42s/it]                                                       {'loss': 0.8549, 'learning_rate': 1.966274355988488e-05, 'epoch': 0.11}
 11%|█         | 574/5198 [2:03:36<15:57:21, 12.42s/it] 11%|█         | 575/5198 [2:03:50<16:29:31, 12.84s/it]                                                       {'loss': 0.917, 'learning_rate': 1.9661137149210473e-05, 'epoch': 0.11}
 11%|█         | 575/5198 [2:03:50<16:29:31, 12.84s/it] 11%|█         | 576/5198 [2:04:06<17:44:50, 13.82s/it]                                                       {'loss': 0.3126, 'learning_rate': 1.9659526987749987e-05, 'epoch': 0.11}
 11%|█         | 576/5198 [2:04:06<17:44:50, 13.82s/it][2024-03-23 17:54:22,277] [WARNING] [stage3.py:1991:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
 11%|█         | 577/5198 [2:04:24<19:14:33, 14.99s/it]                                                       {'loss': 0.3646, 'learning_rate': 1.9657913076128532e-05, 'epoch': 0.11}
 11%|█         | 577/5198 [2:04:24<19:14:33, 14.99s/it] 11%|█         | 578/5198 [2:04:36<18:04:48, 14.09s/it]                                                       {'loss': 0.8908, 'learning_rate': 1.965629541497269e-05, 'epoch': 0.11}
 11%|█         | 578/5198 [2:04:36<18:04:48, 14.09s/it] 11%|█         | 579/5198 [2:04:51<18:34:18, 14.47s/it]                                                       {'loss': 0.8995, 'learning_rate': 1.9654674004910493e-05, 'epoch': 0.11}
 11%|█         | 579/5198 [2:04:51<18:34:18, 14.47s/it] 11%|█         | 580/5198 [2:05:03<17:46:44, 13.86s/it]                                                       {'loss': 0.9404, 'learning_rate': 1.9653048846571427e-05, 'epoch': 0.11}
 11%|█         | 580/5198 [2:05:04<17:46:44, 13.86s/it] 11%|█         | 581/5198 [2:05:15<17:00:01, 13.26s/it]                                                       {'loss': 0.8925, 'learning_rate': 1.9651419940586437e-05, 'epoch': 0.11}
 11%|█         | 581/5198 [2:05:15<17:00:01, 13.26s/it] 11%|█         | 582/5198 [2:05:28<16:41:24, 13.02s/it]                                                       {'loss': 0.9372, 'learning_rate': 1.964978728758791e-05, 'epoch': 0.11}
 11%|█         | 582/5198 [2:05:28<16:41:24, 13.02s/it] 11%|█         | 583/5198 [2:05:40<16:33:27, 12.92s/it]                                                       {'loss': 0.9494, 'learning_rate': 1.9648150888209715e-05, 'epoch': 0.11}
 11%|█         | 583/5198 [2:05:41<16:33:27, 12.92s/it] 11%|█         | 584/5198 [2:05:53<16:14:56, 12.68s/it]                                                       {'loss': 0.9477, 'learning_rate': 1.9646510743087144e-05, 'epoch': 0.11}
 11%|█         | 584/5198 [2:05:53<16:14:56, 12.68s/it] 11%|█▏        | 585/5198 [2:06:05<16:01:31, 12.51s/it]                                                       {'loss': 0.8919, 'learning_rate': 1.964486685285697e-05, 'epoch': 0.11}
 11%|█▏        | 585/5198 [2:06:05<16:01:31, 12.51s/it] 11%|█▏        | 586/5198 [2:06:17<16:03:49, 12.54s/it]                                                       {'loss': 0.907, 'learning_rate': 1.9643219218157395e-05, 'epoch': 0.11}
 11%|█▏        | 586/5198 [2:06:17<16:03:49, 12.54s/it] 11%|█▏        | 587/5198 [2:06:31<16:30:33, 12.89s/it]                                                       {'loss': 0.9108, 'learning_rate': 1.9641567839628092e-05, 'epoch': 0.11}
 11%|█▏        | 587/5198 [2:06:31<16:30:33, 12.89s/it] 11%|█▏        | 588/5198 [2:06:43<16:01:54, 12.52s/it]                                                       {'loss': 0.9121, 'learning_rate': 1.963991271791019e-05, 'epoch': 0.11}
 11%|█▏        | 588/5198 [2:06:43<16:01:54, 12.52s/it] 11%|█▏        | 589/5198 [2:06:55<15:54:31, 12.43s/it]                                                       {'loss': 0.8656, 'learning_rate': 1.9638253853646255e-05, 'epoch': 0.11}
 11%|█▏        | 589/5198 [2:06:55<15:54:31, 12.43s/it] 11%|█▏        | 590/5198 [2:07:07<15:45:17, 12.31s/it]                                                       {'loss': 0.9252, 'learning_rate': 1.9636591247480323e-05, 'epoch': 0.11}
 11%|█▏        | 590/5198 [2:07:07<15:45:17, 12.31s/it] 11%|█▏        | 591/5198 [2:07:23<17:13:28, 13.46s/it]                                                       {'loss': 0.3587, 'learning_rate': 1.9634924900057867e-05, 'epoch': 0.11}
 11%|█▏        | 591/5198 [2:07:23<17:13:28, 13.46s/it] 11%|█▏        | 592/5198 [2:07:37<17:31:49, 13.70s/it]                                                       {'loss': 0.91, 'learning_rate': 1.963325481202583e-05, 'epoch': 0.11}
 11%|█▏        | 592/5198 [2:07:37<17:31:49, 13.70s/it] 11%|█▏        | 593/5198 [2:07:49<16:44:11, 13.08s/it]                                                       {'loss': 0.8955, 'learning_rate': 1.963158098403259e-05, 'epoch': 0.11}
 11%|█▏        | 593/5198 [2:07:49<16:44:11, 13.08s/it] 11%|█▏        | 594/5198 [2:08:01<16:17:05, 12.73s/it]                                                       {'loss': 0.8698, 'learning_rate': 1.9629903416727987e-05, 'epoch': 0.11}
 11%|█▏        | 594/5198 [2:08:01<16:17:05, 12.73s/it] 11%|█▏        | 595/5198 [2:08:16<17:18:47, 13.54s/it]                                                       {'loss': 0.8701, 'learning_rate': 1.962822211076331e-05, 'epoch': 0.11}
 11%|█▏        | 595/5198 [2:08:16<17:18:47, 13.54s/it] 11%|█▏        | 596/5198 [2:08:28<16:41:51, 13.06s/it]                                                       {'loss': 0.9144, 'learning_rate': 1.96265370667913e-05, 'epoch': 0.11}
 11%|█▏        | 596/5198 [2:08:28<16:41:51, 13.06s/it] 11%|█▏        | 597/5198 [2:08:40<16:07:12, 12.61s/it]                                                       {'loss': 0.8728, 'learning_rate': 1.9624848285466146e-05, 'epoch': 0.11}
 11%|█▏        | 597/5198 [2:08:40<16:07:12, 12.61s/it] 12%|█▏        | 598/5198 [2:08:52<15:52:56, 12.43s/it]                                                       {'loss': 0.887, 'learning_rate': 1.9623155767443498e-05, 'epoch': 0.12}
 12%|█▏        | 598/5198 [2:08:52<15:52:56, 12.43s/it] 12%|█▏        | 599/5198 [2:09:04<15:54:24, 12.45s/it]                                                       {'loss': 0.8903, 'learning_rate': 1.9621459513380445e-05, 'epoch': 0.12}
 12%|█▏        | 599/5198 [2:09:04<15:54:24, 12.45s/it] 12%|█▏        | 600/5198 [2:09:16<15:42:54, 12.30s/it]                                                       {'loss': 0.9527, 'learning_rate': 1.9619759523935532e-05, 'epoch': 0.12}
 12%|█▏        | 600/5198 [2:09:16<15:42:54, 12.30s/it] 12%|█▏        | 601/5198 [2:09:28<15:30:03, 12.14s/it]                                                       {'loss': 0.8411, 'learning_rate': 1.9618055799768757e-05, 'epoch': 0.12}
 12%|█▏        | 601/5198 [2:09:28<15:30:03, 12.14s/it] 12%|█▏        | 602/5198 [2:09:41<15:39:03, 12.26s/it]                                                       {'loss': 0.8908, 'learning_rate': 1.961634834154156e-05, 'epoch': 0.12}
 12%|█▏        | 602/5198 [2:09:41<15:39:03, 12.26s/it] 12%|█▏        | 603/5198 [2:09:52<15:30:27, 12.15s/it]                                                       {'loss': 0.9043, 'learning_rate': 1.9614637149916834e-05, 'epoch': 0.12}
 12%|█▏        | 603/5198 [2:09:53<15:30:27, 12.15s/it] 12%|█▏        | 604/5198 [2:10:04<15:27:40, 12.12s/it]                                                       {'loss': 0.9122, 'learning_rate': 1.9612922225558924e-05, 'epoch': 0.12}
 12%|█▏        | 604/5198 [2:10:05<15:27:40, 12.12s/it] 12%|█▏        | 605/5198 [2:10:19<16:14:07, 12.73s/it]                                                       {'loss': 0.8976, 'learning_rate': 1.961120356913363e-05, 'epoch': 0.12}
 12%|█▏        | 605/5198 [2:10:19<16:14:07, 12.73s/it] 12%|█▏        | 606/5198 [2:10:31<16:10:39, 12.68s/it]                                                       {'loss': 0.9397, 'learning_rate': 1.960948118130818e-05, 'epoch': 0.12}
 12%|█▏        | 606/5198 [2:10:31<16:10:39, 12.68s/it] 12%|█▏        | 607/5198 [2:10:43<15:44:19, 12.34s/it]                                                       {'loss': 0.9028, 'learning_rate': 1.9607755062751273e-05, 'epoch': 0.12}
 12%|█▏        | 607/5198 [2:10:43<15:44:19, 12.34s/it] 12%|█▏        | 608/5198 [2:10:59<17:12:32, 13.50s/it]                                                       {'loss': 0.3435, 'learning_rate': 1.9606025214133046e-05, 'epoch': 0.12}
 12%|█▏        | 608/5198 [2:10:59<17:12:32, 13.50s/it] 12%|█▏        | 609/5198 [2:11:15<18:09:36, 14.25s/it]                                                       {'loss': 0.3256, 'learning_rate': 1.9604291636125084e-05, 'epoch': 0.12}
 12%|█▏        | 609/5198 [2:11:15<18:09:36, 14.25s/it] 12%|█▏        | 610/5198 [2:11:28<17:34:16, 13.79s/it]                                                       {'loss': 0.8578, 'learning_rate': 1.960255432940043e-05, 'epoch': 0.12}
 12%|█▏        | 610/5198 [2:11:28<17:34:16, 13.79s/it] 12%|█▏        | 611/5198 [2:11:44<18:22:38, 14.42s/it]                                                       {'loss': 0.8753, 'learning_rate': 1.9600813294633552e-05, 'epoch': 0.12}
 12%|█▏        | 611/5198 [2:11:44<18:22:38, 14.42s/it] 12%|█▏        | 612/5198 [2:11:57<17:53:38, 14.05s/it]                                                       {'loss': 0.8726, 'learning_rate': 1.9599068532500394e-05, 'epoch': 0.12}
 12%|█▏        | 612/5198 [2:11:57<17:53:38, 14.05s/it] 12%|█▏        | 613/5198 [2:12:09<17:04:03, 13.40s/it]                                                       {'loss': 0.9223, 'learning_rate': 1.9597320043678322e-05, 'epoch': 0.12}
 12%|█▏        | 613/5198 [2:12:09<17:04:03, 13.40s/it] 12%|█▏        | 614/5198 [2:12:21<16:34:04, 13.01s/it]                                                       {'loss': 0.8817, 'learning_rate': 1.9595567828846166e-05, 'epoch': 0.12}
 12%|█▏        | 614/5198 [2:12:21<16:34:04, 13.01s/it] 12%|█▏        | 615/5198 [2:12:35<16:55:49, 13.30s/it]                                                       {'loss': 0.9135, 'learning_rate': 1.9593811888684192e-05, 'epoch': 0.12}
 12%|█▏        | 615/5198 [2:12:35<16:55:49, 13.30s/it] 12%|█▏        | 616/5198 [2:12:48<16:54:51, 13.29s/it]                                                       {'loss': 0.8713, 'learning_rate': 1.9592052223874115e-05, 'epoch': 0.12}
 12%|█▏        | 616/5198 [2:12:48<16:54:51, 13.29s/it] 12%|█▏        | 617/5198 [2:13:00<16:33:37, 13.01s/it]                                                       {'loss': 0.8908, 'learning_rate': 1.959028883509911e-05, 'epoch': 0.12}
 12%|█▏        | 617/5198 [2:13:00<16:33:37, 13.01s/it] 12%|█▏        | 618/5198 [2:13:12<16:04:08, 12.63s/it]                                                       {'loss': 0.8848, 'learning_rate': 1.9588521723043764e-05, 'epoch': 0.12}
 12%|█▏        | 618/5198 [2:13:12<16:04:08, 12.63s/it] 12%|█▏        | 619/5198 [2:13:25<16:00:30, 12.59s/it]                                                       {'loss': 0.9086, 'learning_rate': 1.958675088839415e-05, 'epoch': 0.12}
 12%|█▏        | 619/5198 [2:13:25<16:00:30, 12.59s/it] 12%|█▏        | 620/5198 [2:13:37<16:07:28, 12.68s/it]                                                       {'loss': 0.8939, 'learning_rate': 1.9584976331837758e-05, 'epoch': 0.12}
 12%|█▏        | 620/5198 [2:13:38<16:07:28, 12.68s/it] 12%|█▏        | 621/5198 [2:13:49<15:46:54, 12.41s/it]                                                       {'loss': 0.9219, 'learning_rate': 1.9583198054063535e-05, 'epoch': 0.12}
 12%|█▏        | 621/5198 [2:13:49<15:46:54, 12.41s/it] 12%|█▏        | 622/5198 [2:14:01<15:31:07, 12.21s/it]                                                       {'loss': 0.9027, 'learning_rate': 1.9581416055761865e-05, 'epoch': 0.12}
 12%|█▏        | 622/5198 [2:14:01<15:31:07, 12.21s/it] 12%|█▏        | 623/5198 [2:14:14<15:49:00, 12.45s/it]                                                       {'loss': 0.9636, 'learning_rate': 1.9579630337624585e-05, 'epoch': 0.12}
 12%|█▏        | 623/5198 [2:14:14<15:49:00, 12.45s/it] 12%|█▏        | 624/5198 [2:14:26<15:46:44, 12.42s/it]                                                       {'loss': 0.9336, 'learning_rate': 1.9577840900344974e-05, 'epoch': 0.12}
 12%|█▏        | 624/5198 [2:14:26<15:46:44, 12.42s/it] 12%|█▏        | 625/5198 [2:14:39<15:44:51, 12.40s/it]                                                       {'loss': 0.8939, 'learning_rate': 1.9576047744617752e-05, 'epoch': 0.12}
 12%|█▏        | 625/5198 [2:14:39<15:44:51, 12.40s/it] 12%|█▏        | 626/5198 [2:14:52<16:16:00, 12.81s/it]                                                       {'loss': 0.8514, 'learning_rate': 1.957425087113908e-05, 'epoch': 0.12}
 12%|█▏        | 626/5198 [2:14:53<16:16:00, 12.81s/it] 12%|█▏        | 627/5198 [2:15:05<16:14:32, 12.79s/it]                                                       {'loss': 0.9471, 'learning_rate': 1.9572450280606568e-05, 'epoch': 0.12}
 12%|█▏        | 627/5198 [2:15:05<16:14:32, 12.79s/it] 12%|█▏        | 628/5198 [2:15:18<16:08:11, 12.71s/it]                                                       {'loss': 0.8889, 'learning_rate': 1.9570645973719273e-05, 'epoch': 0.12}
 12%|█▏        | 628/5198 [2:15:18<16:08:11, 12.71s/it] 12%|█▏        | 629/5198 [2:15:29<15:46:04, 12.42s/it]                                                       {'loss': 0.8797, 'learning_rate': 1.9568837951177677e-05, 'epoch': 0.12}
 12%|█▏        | 629/5198 [2:15:30<15:46:04, 12.42s/it] 12%|█▏        | 630/5198 [2:15:44<16:43:40, 13.18s/it]                                                       {'loss': 0.9143, 'learning_rate': 1.9567026213683728e-05, 'epoch': 0.12}
 12%|█▏        | 630/5198 [2:15:44<16:43:40, 13.18s/it] 12%|█▏        | 631/5198 [2:15:57<16:21:36, 12.90s/it]                                                       {'loss': 0.9278, 'learning_rate': 1.9565210761940798e-05, 'epoch': 0.12}
 12%|█▏        | 631/5198 [2:15:57<16:21:36, 12.90s/it] 12%|█▏        | 632/5198 [2:16:09<16:01:09, 12.63s/it]                                                       {'loss': 0.9367, 'learning_rate': 1.956339159665371e-05, 'epoch': 0.12}
 12%|█▏        | 632/5198 [2:16:09<16:01:09, 12.63s/it] 12%|█▏        | 633/5198 [2:16:21<16:00:19, 12.62s/it]                                                       {'loss': 0.917, 'learning_rate': 1.956156871852873e-05, 'epoch': 0.12}
 12%|█▏        | 633/5198 [2:16:21<16:00:19, 12.62s/it] 12%|█▏        | 634/5198 [2:16:33<15:50:19, 12.49s/it]                                                       {'loss': 0.91, 'learning_rate': 1.9559742128273558e-05, 'epoch': 0.12}
 12%|█▏        | 634/5198 [2:16:34<15:50:19, 12.49s/it] 12%|█▏        | 635/5198 [2:16:46<15:45:15, 12.43s/it]                                                       {'loss': 0.8832, 'learning_rate': 1.9557911826597337e-05, 'epoch': 0.12}
 12%|█▏        | 635/5198 [2:16:46<15:45:15, 12.43s/it] 12%|█▏        | 636/5198 [2:16:58<15:49:56, 12.49s/it]                                                       {'loss': 0.8978, 'learning_rate': 1.9556077814210662e-05, 'epoch': 0.12}
 12%|█▏        | 636/5198 [2:16:58<15:49:56, 12.49s/it] 12%|█▏        | 637/5198 [2:17:10<15:36:56, 12.33s/it]                                                       {'loss': 0.8789, 'learning_rate': 1.955424009182555e-05, 'epoch': 0.12}
 12%|█▏        | 637/5198 [2:17:10<15:36:56, 12.33s/it] 12%|█▏        | 638/5198 [2:17:24<16:06:47, 12.72s/it]                                                       {'loss': 0.8357, 'learning_rate': 1.955239866015547e-05, 'epoch': 0.12}
 12%|█▏        | 638/5198 [2:17:24<16:06:47, 12.72s/it] 12%|█▏        | 639/5198 [2:17:39<16:53:53, 13.34s/it]                                                       {'loss': 0.8898, 'learning_rate': 1.9550553519915335e-05, 'epoch': 0.12}
 12%|█▏        | 639/5198 [2:17:39<16:53:53, 13.34s/it] 12%|█▏        | 640/5198 [2:17:50<16:13:04, 12.81s/it]                                                       {'loss': 0.9129, 'learning_rate': 1.954870467182149e-05, 'epoch': 0.12}
 12%|█▏        | 640/5198 [2:17:50<16:13:04, 12.81s/it] 12%|█▏        | 641/5198 [2:18:02<15:56:41, 12.60s/it]                                                       {'loss': 0.8781, 'learning_rate': 1.954685211659172e-05, 'epoch': 0.12}
 12%|█▏        | 641/5198 [2:18:02<15:56:41, 12.60s/it] 12%|█▏        | 642/5198 [2:18:16<16:12:35, 12.81s/it]                                                       {'loss': 0.9237, 'learning_rate': 1.9544995854945248e-05, 'epoch': 0.12}
 12%|█▏        | 642/5198 [2:18:16<16:12:35, 12.81s/it] 12%|█▏        | 643/5198 [2:18:27<15:48:05, 12.49s/it]                                                       {'loss': 0.8997, 'learning_rate': 1.954313588760274e-05, 'epoch': 0.12}
 12%|█▏        | 643/5198 [2:18:28<15:48:05, 12.49s/it] 12%|█▏        | 644/5198 [2:18:40<15:55:33, 12.59s/it]                                                       {'loss': 0.8397, 'learning_rate': 1.9541272215286304e-05, 'epoch': 0.12}
 12%|█▏        | 644/5198 [2:18:40<15:55:33, 12.59s/it] 12%|█▏        | 645/5198 [2:18:53<15:52:21, 12.55s/it]                                                       {'loss': 0.8745, 'learning_rate': 1.9539404838719477e-05, 'epoch': 0.12}
 12%|█▏        | 645/5198 [2:18:53<15:52:21, 12.55s/it] 12%|█▏        | 646/5198 [2:19:05<15:40:32, 12.40s/it]                                                       {'loss': 0.8561, 'learning_rate': 1.9537533758627242e-05, 'epoch': 0.12}
 12%|█▏        | 646/5198 [2:19:05<15:40:32, 12.40s/it] 12%|█▏        | 647/5198 [2:19:17<15:25:28, 12.20s/it]                                                       {'loss': 0.9228, 'learning_rate': 1.953565897573601e-05, 'epoch': 0.12}
 12%|█▏        | 647/5198 [2:19:17<15:25:28, 12.20s/it] 12%|█▏        | 648/5198 [2:19:28<15:16:35, 12.09s/it]                                                       {'loss': 0.8549, 'learning_rate': 1.9533780490773645e-05, 'epoch': 0.12}
 12%|█▏        | 648/5198 [2:19:28<15:16:35, 12.09s/it] 12%|█▏        | 649/5198 [2:19:44<16:35:10, 13.13s/it]                                                       {'loss': 0.837, 'learning_rate': 1.9531898304469435e-05, 'epoch': 0.12}
 12%|█▏        | 649/5198 [2:19:44<16:35:10, 13.13s/it] 13%|█▎        | 650/5198 [2:19:56<16:13:33, 12.84s/it]                                                       {'loss': 0.8922, 'learning_rate': 1.953001241755411e-05, 'epoch': 0.13}
 13%|█▎        | 650/5198 [2:19:56<16:13:33, 12.84s/it] 13%|█▎        | 651/5198 [2:20:09<16:03:16, 12.71s/it]                                                       {'loss': 0.9291, 'learning_rate': 1.952812283075984e-05, 'epoch': 0.13}
 13%|█▎        | 651/5198 [2:20:09<16:03:16, 12.71s/it] 13%|█▎        | 652/5198 [2:20:21<15:53:52, 12.59s/it]                                                       {'loss': 0.8922, 'learning_rate': 1.952622954482022e-05, 'epoch': 0.13}
 13%|█▎        | 652/5198 [2:20:21<15:53:52, 12.59s/it] 13%|█▎        | 653/5198 [2:20:34<16:10:01, 12.81s/it]                                                       {'loss': 0.9585, 'learning_rate': 1.9524332560470293e-05, 'epoch': 0.13}
 13%|█▎        | 653/5198 [2:20:34<16:10:01, 12.81s/it] 13%|█▎        | 654/5198 [2:20:46<15:45:56, 12.49s/it]                                                       {'loss': 0.8945, 'learning_rate': 1.9522431878446536e-05, 'epoch': 0.13}
 13%|█▎        | 654/5198 [2:20:46<15:45:56, 12.49s/it] 13%|█▎        | 655/5198 [2:20:58<15:47:39, 12.52s/it]                                                       {'loss': 0.9675, 'learning_rate': 1.9520527499486856e-05, 'epoch': 0.13}
 13%|█▎        | 655/5198 [2:20:59<15:47:39, 12.52s/it] 13%|█▎        | 656/5198 [2:21:15<17:20:14, 13.74s/it]                                                       {'loss': 0.4156, 'learning_rate': 1.95186194243306e-05, 'epoch': 0.13}
 13%|█▎        | 656/5198 [2:21:15<17:20:14, 13.74s/it] 13%|█▎        | 657/5198 [2:21:27<16:38:00, 13.19s/it]                                                       {'loss': 0.8827, 'learning_rate': 1.9516707653718546e-05, 'epoch': 0.13}
 13%|█▎        | 657/5198 [2:21:27<16:38:00, 13.19s/it] 13%|█▎        | 658/5198 [2:21:40<16:25:55, 13.03s/it]                                                       {'loss': 0.8401, 'learning_rate': 1.9514792188392914e-05, 'epoch': 0.13}
 13%|█▎        | 658/5198 [2:21:40<16:25:55, 13.03s/it] 13%|█▎        | 659/5198 [2:21:51<15:56:49, 12.65s/it]                                                       {'loss': 0.8873, 'learning_rate': 1.9512873029097347e-05, 'epoch': 0.13}
 13%|█▎        | 659/5198 [2:21:52<15:56:49, 12.65s/it] 13%|█▎        | 660/5198 [2:22:03<15:35:39, 12.37s/it]                                                       {'loss': 0.8732, 'learning_rate': 1.9510950176576933e-05, 'epoch': 0.13}
 13%|█▎        | 660/5198 [2:22:03<15:35:39, 12.37s/it] 13%|█▎        | 661/5198 [2:22:15<15:31:33, 12.32s/it]                                                       {'loss': 0.8967, 'learning_rate': 1.950902363157819e-05, 'epoch': 0.13}
 13%|█▎        | 661/5198 [2:22:15<15:31:33, 12.32s/it] 13%|█▎        | 662/5198 [2:22:28<15:33:53, 12.35s/it]                                                       {'loss': 0.8673, 'learning_rate': 1.950709339484907e-05, 'epoch': 0.13}
 13%|█▎        | 662/5198 [2:22:28<15:33:53, 12.35s/it] 13%|█▎        | 663/5198 [2:22:40<15:24:04, 12.23s/it]                                                       {'loss': 0.9319, 'learning_rate': 1.9505159467138954e-05, 'epoch': 0.13}
 13%|█▎        | 663/5198 [2:22:40<15:24:04, 12.23s/it] 13%|█▎        | 664/5198 [2:22:52<15:27:31, 12.27s/it]                                                       {'loss': 0.8614, 'learning_rate': 1.9503221849198655e-05, 'epoch': 0.13}
 13%|█▎        | 664/5198 [2:22:52<15:27:31, 12.27s/it] 13%|█▎        | 665/5198 [2:23:04<15:29:41, 12.31s/it]                                                       {'loss': 0.8934, 'learning_rate': 1.9501280541780435e-05, 'epoch': 0.13}
 13%|█▎        | 665/5198 [2:23:04<15:29:41, 12.31s/it] 13%|█▎        | 666/5198 [2:23:16<15:12:32, 12.08s/it]                                                       {'loss': 0.9021, 'learning_rate': 1.9499335545637968e-05, 'epoch': 0.13}
 13%|█▎        | 666/5198 [2:23:16<15:12:32, 12.08s/it] 13%|█▎        | 667/5198 [2:23:29<15:33:03, 12.36s/it]                                                       {'loss': 0.9393, 'learning_rate': 1.949738686152637e-05, 'epoch': 0.13}
 13%|█▎        | 667/5198 [2:23:29<15:33:03, 12.36s/it] 13%|█▎        | 668/5198 [2:23:44<16:25:37, 13.05s/it]                                                       {'loss': 0.8707, 'learning_rate': 1.9495434490202188e-05, 'epoch': 0.13}
 13%|█▎        | 668/5198 [2:23:44<16:25:37, 13.05s/it] 13%|█▎        | 669/5198 [2:23:56<16:03:22, 12.76s/it]                                                       {'loss': 0.9282, 'learning_rate': 1.94934784324234e-05, 'epoch': 0.13}
 13%|█▎        | 669/5198 [2:23:56<16:03:22, 12.76s/it] 13%|█▎        | 670/5198 [2:24:10<16:37:43, 13.22s/it]                                                       {'loss': 0.8435, 'learning_rate': 1.9491518688949417e-05, 'epoch': 0.13}
 13%|█▎        | 670/5198 [2:24:10<16:37:43, 13.22s/it] 13%|█▎        | 671/5198 [2:24:22<16:18:01, 12.96s/it]                                                       {'loss': 0.8613, 'learning_rate': 1.9489555260541074e-05, 'epoch': 0.13}
 13%|█▎        | 671/5198 [2:24:22<16:18:01, 12.96s/it] 13%|█▎        | 672/5198 [2:24:36<16:22:49, 13.03s/it]                                                       {'loss': 0.9135, 'learning_rate': 1.948758814796064e-05, 'epoch': 0.13}
 13%|█▎        | 672/5198 [2:24:36<16:22:49, 13.03s/it] 13%|█▎        | 673/5198 [2:24:52<17:41:35, 14.08s/it]                                                       {'loss': 0.4337, 'learning_rate': 1.9485617351971827e-05, 'epoch': 0.13}
 13%|█▎        | 673/5198 [2:24:52<17:41:35, 14.08s/it] 13%|█▎        | 674/5198 [2:25:04<17:00:52, 13.54s/it]                                                       {'loss': 0.8278, 'learning_rate': 1.9483642873339753e-05, 'epoch': 0.13}
 13%|█▎        | 674/5198 [2:25:04<17:00:52, 13.54s/it] 13%|█▎        | 675/5198 [2:25:17<16:43:00, 13.31s/it]                                                       {'loss': 0.8852, 'learning_rate': 1.9481664712830987e-05, 'epoch': 0.13}
 13%|█▎        | 675/5198 [2:25:17<16:43:00, 13.31s/it] 13%|█▎        | 676/5198 [2:25:34<18:11:09, 14.48s/it]                                                       {'loss': 0.407, 'learning_rate': 1.9479682871213515e-05, 'epoch': 0.13}
 13%|█▎        | 676/5198 [2:25:35<18:11:09, 14.48s/it] 13%|█▎        | 677/5198 [2:25:46<17:14:39, 13.73s/it]                                                       {'loss': 0.9121, 'learning_rate': 1.9477697349256756e-05, 'epoch': 0.13}
 13%|█▎        | 677/5198 [2:25:46<17:14:39, 13.73s/it] 13%|█▎        | 678/5198 [2:26:00<17:20:52, 13.82s/it]                                                       {'loss': 0.8706, 'learning_rate': 1.947570814773156e-05, 'epoch': 0.13}
 13%|█▎        | 678/5198 [2:26:00<17:20:52, 13.82s/it] 13%|█▎        | 679/5198 [2:26:17<18:17:32, 14.57s/it]                                                       {'loss': 0.3677, 'learning_rate': 1.9473715267410206e-05, 'epoch': 0.13}
 13%|█▎        | 679/5198 [2:26:17<18:17:32, 14.57s/it] 13%|█▎        | 680/5198 [2:26:29<17:23:30, 13.86s/it]                                                       {'loss': 0.9404, 'learning_rate': 1.9471718709066392e-05, 'epoch': 0.13}
 13%|█▎        | 680/5198 [2:26:29<17:23:30, 13.86s/it] 13%|█▎        | 681/5198 [2:26:41<16:40:33, 13.29s/it]                                                       {'loss': 0.944, 'learning_rate': 1.9469718473475256e-05, 'epoch': 0.13}
 13%|█▎        | 681/5198 [2:26:41<16:40:33, 13.29s/it] 13%|█▎        | 682/5198 [2:26:52<16:00:04, 12.76s/it]                                                       {'loss': 0.9422, 'learning_rate': 1.9467714561413358e-05, 'epoch': 0.13}
 13%|█▎        | 682/5198 [2:26:52<16:00:04, 12.76s/it] 13%|█▎        | 683/5198 [2:27:05<15:46:55, 12.58s/it]                                                       {'loss': 0.9362, 'learning_rate': 1.9465706973658683e-05, 'epoch': 0.13}
 13%|█▎        | 683/5198 [2:27:05<15:46:55, 12.58s/it] 13%|█▎        | 684/5198 [2:27:17<15:48:25, 12.61s/it]                                                       {'loss': 0.9007, 'learning_rate': 1.9463695710990648e-05, 'epoch': 0.13}
 13%|█▎        | 684/5198 [2:27:17<15:48:25, 12.61s/it] 13%|█▎        | 685/5198 [2:27:29<15:24:46, 12.29s/it]                                                       {'loss': 0.8954, 'learning_rate': 1.946168077419009e-05, 'epoch': 0.13}
 13%|█▎        | 685/5198 [2:27:29<15:24:46, 12.29s/it] 13%|█▎        | 686/5198 [2:27:42<15:52:29, 12.67s/it]                                                       {'loss': 0.9077, 'learning_rate': 1.9459662164039283e-05, 'epoch': 0.13}
 13%|█▎        | 686/5198 [2:27:42<15:52:29, 12.67s/it] 13%|█▎        | 687/5198 [2:27:55<15:42:59, 12.54s/it]                                                       {'loss': 0.9176, 'learning_rate': 1.9457639881321917e-05, 'epoch': 0.13}
 13%|█▎        | 687/5198 [2:27:55<15:42:59, 12.54s/it] 13%|█▎        | 688/5198 [2:28:06<15:21:07, 12.25s/it]                                                       {'loss': 0.9267, 'learning_rate': 1.9455613926823115e-05, 'epoch': 0.13}
 13%|█▎        | 688/5198 [2:28:06<15:21:07, 12.25s/it] 13%|█▎        | 689/5198 [2:28:19<15:24:14, 12.30s/it]                                                       {'loss': 0.9023, 'learning_rate': 1.945358430132942e-05, 'epoch': 0.13}
 13%|█▎        | 689/5198 [2:28:19<15:24:14, 12.30s/it] 13%|█▎        | 690/5198 [2:28:32<15:43:33, 12.56s/it]                                                       {'loss': 0.9324, 'learning_rate': 1.9451551005628803e-05, 'epoch': 0.13}
 13%|█▎        | 690/5198 [2:28:32<15:43:33, 12.56s/it] 13%|█▎        | 691/5198 [2:28:48<17:13:01, 13.75s/it]                                                       {'loss': 0.3439, 'learning_rate': 1.9449514040510654e-05, 'epoch': 0.13}
 13%|█▎        | 691/5198 [2:28:48<17:13:01, 13.75s/it] 13%|█▎        | 692/5198 [2:29:01<16:59:47, 13.58s/it]                                                       {'loss': 0.8864, 'learning_rate': 1.9447473406765803e-05, 'epoch': 0.13}
 13%|█▎        | 692/5198 [2:29:01<16:59:47, 13.58s/it] 13%|█▎        | 693/5198 [2:29:14<16:31:28, 13.21s/it]                                                       {'loss': 0.866, 'learning_rate': 1.9445429105186487e-05, 'epoch': 0.13}
 13%|█▎        | 693/5198 [2:29:14<16:31:28, 13.21s/it] 13%|█▎        | 694/5198 [2:29:25<15:53:51, 12.71s/it]                                                       {'loss': 0.8765, 'learning_rate': 1.9443381136566382e-05, 'epoch': 0.13}
 13%|█▎        | 694/5198 [2:29:25<15:53:51, 12.71s/it] 13%|█▎        | 695/5198 [2:29:39<16:19:48, 13.06s/it]                                                       {'loss': 0.8735, 'learning_rate': 1.9441329501700568e-05, 'epoch': 0.13}
 13%|█▎        | 695/5198 [2:29:39<16:19:48, 13.06s/it] 13%|█▎        | 696/5198 [2:29:52<16:07:09, 12.89s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.943927420138557e-05, 'epoch': 0.13}
 13%|█▎        | 696/5198 [2:29:52<16:07:09, 12.89s/it] 13%|█▎        | 697/5198 [2:30:05<16:08:18, 12.91s/it]                                                       {'loss': 0.9103, 'learning_rate': 1.9437215236419322e-05, 'epoch': 0.13}
 13%|█▎        | 697/5198 [2:30:05<16:08:18, 12.91s/it] 13%|█▎        | 698/5198 [2:30:19<16:34:09, 13.26s/it]                                                       {'loss': 0.8937, 'learning_rate': 1.9435152607601187e-05, 'epoch': 0.13}
 13%|█▎        | 698/5198 [2:30:19<16:34:09, 13.26s/it] 13%|█▎        | 699/5198 [2:30:30<16:00:59, 12.82s/it]                                                       {'loss': 0.8872, 'learning_rate': 1.943308631573195e-05, 'epoch': 0.13}
 13%|█▎        | 699/5198 [2:30:31<16:00:59, 12.82s/it] 13%|█▎        | 700/5198 [2:30:43<15:48:12, 12.65s/it]                                                       {'loss': 0.8878, 'learning_rate': 1.9431016361613816e-05, 'epoch': 0.13}
 13%|█▎        | 700/5198 [2:30:43<15:48:12, 12.65s/it] 13%|█▎        | 701/5198 [2:30:56<15:53:35, 12.72s/it]                                                       {'loss': 0.9111, 'learning_rate': 1.9428942746050406e-05, 'epoch': 0.13}
 13%|█▎        | 701/5198 [2:30:56<15:53:35, 12.72s/it] 14%|█▎        | 702/5198 [2:31:12<17:25:19, 13.95s/it]                                                       {'loss': 0.3302, 'learning_rate': 1.9426865469846773e-05, 'epoch': 0.14}
 14%|█▎        | 702/5198 [2:31:12<17:25:19, 13.95s/it] 14%|█▎        | 703/5198 [2:31:27<17:41:16, 14.17s/it]                                                       {'loss': 0.9206, 'learning_rate': 1.9424784533809393e-05, 'epoch': 0.14}
 14%|█▎        | 703/5198 [2:31:27<17:41:16, 14.17s/it] 14%|█▎        | 704/5198 [2:31:40<17:08:31, 13.73s/it]                                                       {'loss': 0.915, 'learning_rate': 1.942269993874615e-05, 'epoch': 0.14}
 14%|█▎        | 704/5198 [2:31:40<17:08:31, 13.73s/it] 14%|█▎        | 705/5198 [2:31:52<16:27:49, 13.19s/it]                                                       {'loss': 0.9538, 'learning_rate': 1.9420611685466358e-05, 'epoch': 0.14}
 14%|█▎        | 705/5198 [2:31:52<16:27:49, 13.19s/it] 14%|█▎        | 706/5198 [2:32:05<16:31:01, 13.24s/it]                                                       {'loss': 0.8631, 'learning_rate': 1.9418519774780748e-05, 'epoch': 0.14}
 14%|█▎        | 706/5198 [2:32:05<16:31:01, 13.24s/it] 14%|█▎        | 707/5198 [2:32:20<17:11:02, 13.77s/it]                                                       {'loss': 0.8816, 'learning_rate': 1.9416424207501474e-05, 'epoch': 0.14}
 14%|█▎        | 707/5198 [2:32:20<17:11:02, 13.77s/it] 14%|█▎        | 708/5198 [2:32:33<16:45:53, 13.44s/it]                                                       {'loss': 0.8663, 'learning_rate': 1.9414324984442102e-05, 'epoch': 0.14}
 14%|█▎        | 708/5198 [2:32:33<16:45:53, 13.44s/it] 14%|█▎        | 709/5198 [2:32:48<17:30:51, 14.05s/it]                                                       {'loss': 0.8554, 'learning_rate': 1.9412222106417632e-05, 'epoch': 0.14}
 14%|█▎        | 709/5198 [2:32:48<17:30:51, 14.05s/it] 14%|█▎        | 710/5198 [2:33:04<18:07:52, 14.54s/it]                                                       {'loss': 0.9296, 'learning_rate': 1.9410115574244462e-05, 'epoch': 0.14}
 14%|█▎        | 710/5198 [2:33:04<18:07:52, 14.54s/it] 14%|█▎        | 711/5198 [2:33:17<17:32:36, 14.08s/it]                                                       {'loss': 0.886, 'learning_rate': 1.9408005388740433e-05, 'epoch': 0.14}
 14%|█▎        | 711/5198 [2:33:17<17:32:36, 14.08s/it] 14%|█▎        | 712/5198 [2:33:29<16:41:58, 13.40s/it]                                                       {'loss': 0.9322, 'learning_rate': 1.9405891550724778e-05, 'epoch': 0.14}
 14%|█▎        | 712/5198 [2:33:29<16:41:58, 13.40s/it] 14%|█▎        | 713/5198 [2:33:45<17:34:28, 14.11s/it]                                                       {'loss': 0.9182, 'learning_rate': 1.940377406101817e-05, 'epoch': 0.14}
 14%|█▎        | 713/5198 [2:33:45<17:34:28, 14.11s/it] 14%|█▎        | 714/5198 [2:33:56<16:40:38, 13.39s/it]                                                       {'loss': 0.8985, 'learning_rate': 1.9401652920442694e-05, 'epoch': 0.14}
 14%|█▎        | 714/5198 [2:33:56<16:40:38, 13.39s/it] 14%|█▍        | 715/5198 [2:34:10<16:41:56, 13.41s/it]                                                       {'loss': 0.9783, 'learning_rate': 1.9399528129821842e-05, 'epoch': 0.14}
 14%|█▍        | 715/5198 [2:34:10<16:41:56, 13.41s/it] 14%|█▍        | 716/5198 [2:34:22<16:25:08, 13.19s/it]                                                       {'loss': 0.9023, 'learning_rate': 1.939739968998054e-05, 'epoch': 0.14}
 14%|█▍        | 716/5198 [2:34:22<16:25:08, 13.19s/it] 14%|█▍        | 717/5198 [2:34:34<15:59:06, 12.84s/it]                                                       {'loss': 0.9479, 'learning_rate': 1.939526760174511e-05, 'epoch': 0.14}
 14%|█▍        | 717/5198 [2:34:34<15:59:06, 12.84s/it] 14%|█▍        | 718/5198 [2:34:47<15:43:01, 12.63s/it]                                                       {'loss': 0.954, 'learning_rate': 1.939313186594331e-05, 'epoch': 0.14}
 14%|█▍        | 718/5198 [2:34:47<15:43:01, 12.63s/it] 14%|█▍        | 719/5198 [2:34:59<15:44:14, 12.65s/it]                                                       {'loss': 0.8578, 'learning_rate': 1.9390992483404308e-05, 'epoch': 0.14}
 14%|█▍        | 719/5198 [2:34:59<15:44:14, 12.65s/it] 14%|█▍        | 720/5198 [2:35:11<15:32:58, 12.50s/it]                                                       {'loss': 0.9141, 'learning_rate': 1.938884945495868e-05, 'epoch': 0.14}
 14%|█▍        | 720/5198 [2:35:11<15:32:58, 12.50s/it] 14%|█▍        | 721/5198 [2:35:24<15:35:35, 12.54s/it]                                                       {'loss': 0.9083, 'learning_rate': 1.9386702781438425e-05, 'epoch': 0.14}
 14%|█▍        | 721/5198 [2:35:24<15:35:35, 12.54s/it] 14%|█▍        | 722/5198 [2:35:37<15:34:39, 12.53s/it]                                                       {'loss': 0.9411, 'learning_rate': 1.938455246367696e-05, 'epoch': 0.14}
 14%|█▍        | 722/5198 [2:35:37<15:34:39, 12.53s/it] 14%|█▍        | 723/5198 [2:35:50<15:44:58, 12.67s/it]                                                       {'loss': 0.8738, 'learning_rate': 1.9382398502509107e-05, 'epoch': 0.14}
 14%|█▍        | 723/5198 [2:35:50<15:44:58, 12.67s/it] 14%|█▍        | 724/5198 [2:36:02<15:47:35, 12.71s/it]                                                       {'loss': 0.8915, 'learning_rate': 1.938024089877111e-05, 'epoch': 0.14}
 14%|█▍        | 724/5198 [2:36:02<15:47:35, 12.71s/it] 14%|█▍        | 725/5198 [2:36:15<15:37:21, 12.57s/it]                                                       {'loss': 0.9057, 'learning_rate': 1.9378079653300624e-05, 'epoch': 0.14}
 14%|█▍        | 725/5198 [2:36:15<15:37:21, 12.57s/it] 14%|█▍        | 726/5198 [2:36:26<15:21:54, 12.37s/it]                                                       {'loss': 0.8912, 'learning_rate': 1.9375914766936723e-05, 'epoch': 0.14}
 14%|█▍        | 726/5198 [2:36:27<15:21:54, 12.37s/it] 14%|█▍        | 727/5198 [2:36:38<15:13:16, 12.26s/it]                                                       {'loss': 0.9258, 'learning_rate': 1.9373746240519884e-05, 'epoch': 0.14}
 14%|█▍        | 727/5198 [2:36:38<15:13:16, 12.26s/it] 14%|█▍        | 728/5198 [2:36:52<15:43:48, 12.67s/it]                                                       {'loss': 0.9183, 'learning_rate': 1.937157407489201e-05, 'epoch': 0.14}
 14%|█▍        | 728/5198 [2:36:52<15:43:48, 12.67s/it] 14%|█▍        | 729/5198 [2:37:05<15:55:52, 12.83s/it]                                                       {'loss': 0.8878, 'learning_rate': 1.9369398270896403e-05, 'epoch': 0.14}
 14%|█▍        | 729/5198 [2:37:05<15:55:52, 12.83s/it] 14%|█▍        | 730/5198 [2:37:23<17:39:59, 14.23s/it]                                                       {'loss': 0.3176, 'learning_rate': 1.936721882937779e-05, 'epoch': 0.14}
 14%|█▍        | 730/5198 [2:37:23<17:39:59, 14.23s/it] 14%|█▍        | 731/5198 [2:37:37<17:42:39, 14.27s/it]                                                       {'loss': 0.8991, 'learning_rate': 1.9365035751182307e-05, 'epoch': 0.14}
 14%|█▍        | 731/5198 [2:37:37<17:42:39, 14.27s/it] 14%|█▍        | 732/5198 [2:37:49<16:50:15, 13.57s/it]                                                       {'loss': 0.8926, 'learning_rate': 1.93628490371575e-05, 'epoch': 0.14}
 14%|█▍        | 732/5198 [2:37:49<16:50:15, 13.57s/it] 14%|█▍        | 733/5198 [2:38:01<16:09:26, 13.03s/it]                                                       {'loss': 0.9151, 'learning_rate': 1.9360658688152322e-05, 'epoch': 0.14}
 14%|█▍        | 733/5198 [2:38:01<16:09:26, 13.03s/it] 14%|█▍        | 734/5198 [2:38:13<15:53:08, 12.81s/it]                                                       {'loss': 0.8722, 'learning_rate': 1.9358464705017143e-05, 'epoch': 0.14}
 14%|█▍        | 734/5198 [2:38:13<15:53:08, 12.81s/it] 14%|█▍        | 735/5198 [2:38:26<15:42:33, 12.67s/it]                                                       {'loss': 0.9242, 'learning_rate': 1.9356267088603745e-05, 'epoch': 0.14}
 14%|█▍        | 735/5198 [2:38:26<15:42:33, 12.67s/it] 14%|█▍        | 736/5198 [2:38:38<15:32:37, 12.54s/it]                                                       {'loss': 0.8432, 'learning_rate': 1.9354065839765316e-05, 'epoch': 0.14}
 14%|█▍        | 736/5198 [2:38:38<15:32:37, 12.54s/it] 14%|█▍        | 737/5198 [2:38:50<15:15:34, 12.31s/it]                                                       {'loss': 0.9143, 'learning_rate': 1.9351860959356462e-05, 'epoch': 0.14}
 14%|█▍        | 737/5198 [2:38:50<15:15:34, 12.31s/it] 14%|█▍        | 738/5198 [2:39:02<15:22:32, 12.41s/it]                                                       {'loss': 0.8653, 'learning_rate': 1.9349652448233187e-05, 'epoch': 0.14}
 14%|█▍        | 738/5198 [2:39:02<15:22:32, 12.41s/it] 14%|█▍        | 739/5198 [2:39:14<15:00:19, 12.11s/it]                                                       {'loss': 0.8947, 'learning_rate': 1.934744030725291e-05, 'epoch': 0.14}
 14%|█▍        | 739/5198 [2:39:14<15:00:19, 12.11s/it] 14%|█▍        | 740/5198 [2:39:26<15:05:37, 12.19s/it]                                                       {'loss': 0.8727, 'learning_rate': 1.934522453727447e-05, 'epoch': 0.14}
 14%|█▍        | 740/5198 [2:39:26<15:05:37, 12.19s/it] 14%|█▍        | 741/5198 [2:39:38<15:07:54, 12.22s/it]                                                       {'loss': 0.8715, 'learning_rate': 1.93430051391581e-05, 'epoch': 0.14}
 14%|█▍        | 741/5198 [2:39:38<15:07:54, 12.22s/it] 14%|█▍        | 742/5198 [2:39:51<15:19:31, 12.38s/it]                                                       {'loss': 0.8995, 'learning_rate': 1.934078211376544e-05, 'epoch': 0.14}
 14%|█▍        | 742/5198 [2:39:51<15:19:31, 12.38s/it] 14%|█▍        | 743/5198 [2:40:03<15:07:42, 12.22s/it]                                                       {'loss': 0.9031, 'learning_rate': 1.9338555461959554e-05, 'epoch': 0.14}
 14%|█▍        | 743/5198 [2:40:03<15:07:42, 12.22s/it] 14%|█▍        | 744/5198 [2:40:15<15:02:37, 12.16s/it]                                                       {'loss': 0.9072, 'learning_rate': 1.93363251846049e-05, 'epoch': 0.14}
 14%|█▍        | 744/5198 [2:40:15<15:02:37, 12.16s/it] 14%|█▍        | 745/5198 [2:40:28<15:24:24, 12.46s/it]                                                       {'loss': 0.8867, 'learning_rate': 1.9334091282567352e-05, 'epoch': 0.14}
 14%|█▍        | 745/5198 [2:40:28<15:24:24, 12.46s/it] 14%|█▍        | 746/5198 [2:40:40<15:14:25, 12.32s/it]                                                       {'loss': 0.9139, 'learning_rate': 1.9331853756714185e-05, 'epoch': 0.14}
 14%|█▍        | 746/5198 [2:40:40<15:14:25, 12.32s/it] 14%|█▍        | 747/5198 [2:40:52<15:01:40, 12.15s/it]                                                       {'loss': 0.8915, 'learning_rate': 1.9329612607914088e-05, 'epoch': 0.14}
 14%|█▍        | 747/5198 [2:40:52<15:01:40, 12.15s/it] 14%|█▍        | 748/5198 [2:41:09<16:52:40, 13.65s/it]                                                       {'loss': 0.3433, 'learning_rate': 1.9327367837037142e-05, 'epoch': 0.14}
 14%|█▍        | 748/5198 [2:41:09<16:52:40, 13.65s/it] 14%|█▍        | 749/5198 [2:41:25<17:40:37, 14.30s/it]                                                       {'loss': 0.3205, 'learning_rate': 1.9325119444954855e-05, 'epoch': 0.14}
 14%|█▍        | 749/5198 [2:41:25<17:40:37, 14.30s/it] 14%|█▍        | 750/5198 [2:41:38<17:13:44, 13.94s/it]                                                       {'loss': 0.9129, 'learning_rate': 1.9322867432540126e-05, 'epoch': 0.14}
 14%|█▍        | 750/5198 [2:41:38<17:13:44, 13.94s/it] 14%|█▍        | 751/5198 [2:41:50<16:35:19, 13.43s/it]                                                       {'loss': 0.9362, 'learning_rate': 1.9320611800667268e-05, 'epoch': 0.14}
 14%|█▍        | 751/5198 [2:41:50<16:35:19, 13.43s/it] 14%|█▍        | 752/5198 [2:42:04<16:39:37, 13.49s/it]                                                       {'loss': 0.9097, 'learning_rate': 1.9318352550211986e-05, 'epoch': 0.14}
 14%|█▍        | 752/5198 [2:42:04<16:39:37, 13.49s/it] 14%|█▍        | 753/5198 [2:42:16<16:09:28, 13.09s/it]                                                       {'loss': 0.8598, 'learning_rate': 1.9316089682051403e-05, 'epoch': 0.14}
 14%|█▍        | 753/5198 [2:42:16<16:09:28, 13.09s/it] 15%|█▍        | 754/5198 [2:42:28<15:51:08, 12.84s/it]                                                       {'loss': 0.8885, 'learning_rate': 1.9313823197064042e-05, 'epoch': 0.15}
 15%|█▍        | 754/5198 [2:42:28<15:51:08, 12.84s/it] 15%|█▍        | 755/5198 [2:42:40<15:20:30, 12.43s/it]                                                       {'loss': 0.887, 'learning_rate': 1.9311553096129835e-05, 'epoch': 0.15}
 15%|█▍        | 755/5198 [2:42:40<15:20:30, 12.43s/it] 15%|█▍        | 756/5198 [2:42:52<15:09:13, 12.28s/it]                                                       {'loss': 0.8967, 'learning_rate': 1.9309279380130112e-05, 'epoch': 0.15}
 15%|█▍        | 756/5198 [2:42:52<15:09:13, 12.28s/it] 15%|█▍        | 757/5198 [2:43:04<15:13:03, 12.34s/it]                                                       {'loss': 0.9705, 'learning_rate': 1.93070020499476e-05, 'epoch': 0.15}
 15%|█▍        | 757/5198 [2:43:04<15:13:03, 12.34s/it] 15%|█▍        | 758/5198 [2:43:17<15:20:24, 12.44s/it]                                                       {'loss': 0.9547, 'learning_rate': 1.930472110646645e-05, 'epoch': 0.15}
 15%|█▍        | 758/5198 [2:43:17<15:20:24, 12.44s/it] 15%|█▍        | 759/5198 [2:43:29<15:18:35, 12.42s/it]                                                       {'loss': 0.9016, 'learning_rate': 1.9302436550572187e-05, 'epoch': 0.15}
 15%|█▍        | 759/5198 [2:43:29<15:18:35, 12.42s/it] 15%|█▍        | 760/5198 [2:43:42<15:19:14, 12.43s/it]                                                       {'loss': 0.9112, 'learning_rate': 1.930014838315177e-05, 'epoch': 0.15}
 15%|█▍        | 760/5198 [2:43:42<15:19:14, 12.43s/it] 15%|█▍        | 761/5198 [2:43:54<15:13:11, 12.35s/it]                                                       {'loss': 0.8682, 'learning_rate': 1.9297856605093534e-05, 'epoch': 0.15}
 15%|█▍        | 761/5198 [2:43:54<15:13:11, 12.35s/it] 15%|█▍        | 762/5198 [2:44:07<15:29:55, 12.58s/it]                                                       {'loss': 0.8792, 'learning_rate': 1.9295561217287226e-05, 'epoch': 0.15}
 15%|█▍        | 762/5198 [2:44:07<15:29:55, 12.58s/it] 15%|█▍        | 763/5198 [2:44:19<15:25:20, 12.52s/it]                                                       {'loss': 0.9336, 'learning_rate': 1.9293262220624002e-05, 'epoch': 0.15}
 15%|█▍        | 763/5198 [2:44:19<15:25:20, 12.52s/it] 15%|█▍        | 764/5198 [2:44:31<15:09:22, 12.31s/it]                                                       {'loss': 0.8829, 'learning_rate': 1.9290959615996407e-05, 'epoch': 0.15}
 15%|█▍        | 764/5198 [2:44:31<15:09:22, 12.31s/it] 15%|█▍        | 765/5198 [2:44:44<15:27:20, 12.55s/it]                                                       {'loss': 0.9135, 'learning_rate': 1.9288653404298392e-05, 'epoch': 0.15}
 15%|█▍        | 765/5198 [2:44:44<15:27:20, 12.55s/it] 15%|█▍        | 766/5198 [2:44:56<15:12:31, 12.35s/it]                                                       {'loss': 0.8596, 'learning_rate': 1.9286343586425307e-05, 'epoch': 0.15}
 15%|█▍        | 766/5198 [2:44:56<15:12:31, 12.35s/it] 15%|█▍        | 767/5198 [2:45:08<15:05:30, 12.26s/it]                                                       {'loss': 0.9012, 'learning_rate': 1.9284030163273907e-05, 'epoch': 0.15}
 15%|█▍        | 767/5198 [2:45:08<15:05:30, 12.26s/it] 15%|█▍        | 768/5198 [2:45:20<14:55:25, 12.13s/it]                                                       {'loss': 0.8986, 'learning_rate': 1.9281713135742333e-05, 'epoch': 0.15}
 15%|█▍        | 768/5198 [2:45:20<14:55:25, 12.13s/it] 15%|█▍        | 769/5198 [2:45:34<15:40:34, 12.74s/it]                                                       {'loss': 0.8939, 'learning_rate': 1.9279392504730147e-05, 'epoch': 0.15}
 15%|█▍        | 769/5198 [2:45:34<15:40:34, 12.74s/it] 15%|█▍        | 770/5198 [2:45:47<15:35:34, 12.68s/it]                                                       {'loss': 0.9664, 'learning_rate': 1.9277068271138287e-05, 'epoch': 0.15}
 15%|█▍        | 770/5198 [2:45:47<15:35:34, 12.68s/it] 15%|█▍        | 771/5198 [2:46:00<15:41:38, 12.76s/it]                                                       {'loss': 0.88, 'learning_rate': 1.9274740435869107e-05, 'epoch': 0.15}
 15%|█▍        | 771/5198 [2:46:00<15:41:38, 12.76s/it] 15%|█▍        | 772/5198 [2:46:11<15:21:06, 12.49s/it]                                                       {'loss': 0.8847, 'learning_rate': 1.927240899982635e-05, 'epoch': 0.15}
 15%|█▍        | 772/5198 [2:46:11<15:21:06, 12.49s/it] 15%|█▍        | 773/5198 [2:46:24<15:16:47, 12.43s/it]                                                       {'loss': 0.9011, 'learning_rate': 1.9270073963915162e-05, 'epoch': 0.15}
 15%|█▍        | 773/5198 [2:46:24<15:16:47, 12.43s/it] 15%|█▍        | 774/5198 [2:46:36<15:23:40, 12.53s/it]                                                       {'loss': 0.9269, 'learning_rate': 1.9267735329042086e-05, 'epoch': 0.15}
 15%|█▍        | 774/5198 [2:46:37<15:23:40, 12.53s/it] 15%|█▍        | 775/5198 [2:46:48<15:09:04, 12.33s/it]                                                       {'loss': 0.8687, 'learning_rate': 1.9265393096115056e-05, 'epoch': 0.15}
 15%|█▍        | 775/5198 [2:46:48<15:09:04, 12.33s/it] 15%|█▍        | 776/5198 [2:47:01<15:11:13, 12.36s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.926304726604341e-05, 'epoch': 0.15}
 15%|█▍        | 776/5198 [2:47:01<15:11:13, 12.36s/it] 15%|█▍        | 777/5198 [2:47:13<15:06:08, 12.30s/it]                                                       {'loss': 0.9051, 'learning_rate': 1.9260697839737875e-05, 'epoch': 0.15}
 15%|█▍        | 777/5198 [2:47:13<15:06:08, 12.30s/it] 15%|█▍        | 778/5198 [2:47:27<15:46:24, 12.85s/it]                                                       {'loss': 0.8473, 'learning_rate': 1.925834481811059e-05, 'epoch': 0.15}
 15%|█▍        | 778/5198 [2:47:27<15:46:24, 12.85s/it] 15%|█▍        | 779/5198 [2:47:40<15:42:05, 12.79s/it]                                                       {'loss': 0.922, 'learning_rate': 1.9255988202075065e-05, 'epoch': 0.15}
 15%|█▍        | 779/5198 [2:47:40<15:42:05, 12.79s/it] 15%|█▌        | 780/5198 [2:47:52<15:27:25, 12.60s/it]                                                       {'loss': 0.8596, 'learning_rate': 1.925362799254623e-05, 'epoch': 0.15}
 15%|█▌        | 780/5198 [2:47:52<15:27:25, 12.60s/it] 15%|█▌        | 781/5198 [2:48:06<15:53:43, 12.96s/it]                                                       {'loss': 0.9016, 'learning_rate': 1.9251264190440398e-05, 'epoch': 0.15}
 15%|█▌        | 781/5198 [2:48:06<15:53:43, 12.96s/it] 15%|█▌        | 782/5198 [2:48:19<15:52:33, 12.94s/it]                                                       {'loss': 0.8557, 'learning_rate': 1.9248896796675277e-05, 'epoch': 0.15}
 15%|█▌        | 782/5198 [2:48:19<15:52:33, 12.94s/it] 15%|█▌        | 783/5198 [2:48:31<15:37:18, 12.74s/it]                                                       {'loss': 0.908, 'learning_rate': 1.924652581216997e-05, 'epoch': 0.15}
 15%|█▌        | 783/5198 [2:48:31<15:37:18, 12.74s/it] 15%|█▌        | 784/5198 [2:48:43<15:30:03, 12.64s/it]                                                       {'loss': 0.8795, 'learning_rate': 1.9244151237844975e-05, 'epoch': 0.15}
 15%|█▌        | 784/5198 [2:48:43<15:30:03, 12.64s/it] 15%|█▌        | 785/5198 [2:48:55<15:13:37, 12.42s/it]                                                       {'loss': 0.8616, 'learning_rate': 1.9241773074622182e-05, 'epoch': 0.15}
 15%|█▌        | 785/5198 [2:48:55<15:13:37, 12.42s/it] 15%|█▌        | 786/5198 [2:49:08<15:14:30, 12.44s/it]                                                       {'loss': 0.922, 'learning_rate': 1.923939132342488e-05, 'epoch': 0.15}
 15%|█▌        | 786/5198 [2:49:08<15:14:30, 12.44s/it] 15%|█▌        | 787/5198 [2:49:19<14:53:05, 12.15s/it]                                                       {'loss': 0.7878, 'learning_rate': 1.923700598517775e-05, 'epoch': 0.15}
 15%|█▌        | 787/5198 [2:49:19<14:53:05, 12.15s/it] 15%|█▌        | 788/5198 [2:49:35<16:05:43, 13.14s/it]                                                       {'loss': 0.8483, 'learning_rate': 1.923461706080685e-05, 'epoch': 0.15}
 15%|█▌        | 788/5198 [2:49:35<16:05:43, 13.14s/it] 15%|█▌        | 789/5198 [2:49:52<17:37:52, 14.40s/it]                                                       {'loss': 0.3671, 'learning_rate': 1.923222455123965e-05, 'epoch': 0.15}
 15%|█▌        | 789/5198 [2:49:52<17:37:52, 14.40s/it] 15%|█▌        | 790/5198 [2:50:04<16:37:43, 13.58s/it]                                                       {'loss': 0.915, 'learning_rate': 1.9229828457405005e-05, 'epoch': 0.15}
 15%|█▌        | 790/5198 [2:50:04<16:37:43, 13.58s/it] 15%|█▌        | 791/5198 [2:50:20<17:47:13, 14.53s/it]                                                       {'loss': 0.3828, 'learning_rate': 1.9227428780233162e-05, 'epoch': 0.15}
 15%|█▌        | 791/5198 [2:50:20<17:47:13, 14.53s/it] 15%|█▌        | 792/5198 [2:50:32<16:54:22, 13.81s/it]                                                       {'loss': 0.9342, 'learning_rate': 1.922502552065576e-05, 'epoch': 0.15}
 15%|█▌        | 792/5198 [2:50:32<16:54:22, 13.81s/it] 15%|█▌        | 793/5198 [2:50:49<18:02:26, 14.74s/it]                                                       {'loss': 0.322, 'learning_rate': 1.922261867960582e-05, 'epoch': 0.15}
 15%|█▌        | 793/5198 [2:50:49<18:02:26, 14.74s/it] 15%|█▌        | 794/5198 [2:51:01<17:00:49, 13.91s/it]                                                       {'loss': 0.8891, 'learning_rate': 1.9220208258017763e-05, 'epoch': 0.15}
 15%|█▌        | 794/5198 [2:51:01<17:00:49, 13.91s/it] 15%|█▌        | 795/5198 [2:51:13<16:19:53, 13.35s/it]                                                       {'loss': 0.9053, 'learning_rate': 1.92177942568274e-05, 'epoch': 0.15}
 15%|█▌        | 795/5198 [2:51:13<16:19:53, 13.35s/it] 15%|█▌        | 796/5198 [2:51:25<15:41:16, 12.83s/it]                                                       {'loss': 0.942, 'learning_rate': 1.921537667697193e-05, 'epoch': 0.15}
 15%|█▌        | 796/5198 [2:51:25<15:41:16, 12.83s/it] 15%|█▌        | 797/5198 [2:51:38<15:37:35, 12.78s/it]                                                       {'loss': 0.8961, 'learning_rate': 1.9212955519389938e-05, 'epoch': 0.15}
 15%|█▌        | 797/5198 [2:51:38<15:37:35, 12.78s/it] 15%|█▌        | 798/5198 [2:51:50<15:29:38, 12.68s/it]                                                       {'loss': 0.9303, 'learning_rate': 1.9210530785021405e-05, 'epoch': 0.15}
 15%|█▌        | 798/5198 [2:51:50<15:29:38, 12.68s/it] 15%|█▌        | 799/5198 [2:52:02<15:08:03, 12.39s/it]                                                       {'loss': 0.8513, 'learning_rate': 1.9208102474807692e-05, 'epoch': 0.15}
 15%|█▌        | 799/5198 [2:52:02<15:08:03, 12.39s/it] 15%|█▌        | 800/5198 [2:52:14<15:04:16, 12.34s/it]                                                       {'loss': 0.916, 'learning_rate': 1.920567058969155e-05, 'epoch': 0.15}
 15%|█▌        | 800/5198 [2:52:14<15:04:16, 12.34s/it] 15%|█▌        | 801/5198 [2:52:29<16:04:05, 13.16s/it]                                                       {'loss': 0.8678, 'learning_rate': 1.920323513061713e-05, 'epoch': 0.15}
 15%|█▌        | 801/5198 [2:52:29<16:04:05, 13.16s/it] 15%|█▌        | 802/5198 [2:52:43<16:14:38, 13.30s/it]                                                       {'loss': 0.8315, 'learning_rate': 1.9200796098529956e-05, 'epoch': 0.15}
 15%|█▌        | 802/5198 [2:52:43<16:14:38, 13.30s/it] 15%|█▌        | 803/5198 [2:52:55<15:52:02, 13.00s/it]                                                       {'loss': 0.8636, 'learning_rate': 1.919835349437694e-05, 'epoch': 0.15}
 15%|█▌        | 803/5198 [2:52:55<15:52:02, 13.00s/it] 15%|█▌        | 804/5198 [2:53:08<16:00:36, 13.12s/it]                                                       {'loss': 0.889, 'learning_rate': 1.9195907319106394e-05, 'epoch': 0.15}
 15%|█▌        | 804/5198 [2:53:08<16:00:36, 13.12s/it] 15%|█▌        | 805/5198 [2:53:20<15:34:20, 12.76s/it]                                                       {'loss': 0.8446, 'learning_rate': 1.9193457573667996e-05, 'epoch': 0.15}
 15%|█▌        | 805/5198 [2:53:20<15:34:20, 12.76s/it] 16%|█▌        | 806/5198 [2:53:33<15:34:23, 12.76s/it]                                                       {'loss': 0.8176, 'learning_rate': 1.919100425901283e-05, 'epoch': 0.16}
 16%|█▌        | 806/5198 [2:53:33<15:34:23, 12.76s/it] 16%|█▌        | 807/5198 [2:53:45<15:23:44, 12.62s/it]                                                       {'loss': 0.9441, 'learning_rate': 1.9188547376093355e-05, 'epoch': 0.16}
 16%|█▌        | 807/5198 [2:53:45<15:23:44, 12.62s/it] 16%|█▌        | 808/5198 [2:53:58<15:17:56, 12.55s/it]                                                       {'loss': 0.8862, 'learning_rate': 1.918608692586342e-05, 'epoch': 0.16}
 16%|█▌        | 808/5198 [2:53:58<15:17:56, 12.55s/it] 16%|█▌        | 809/5198 [2:54:11<15:42:39, 12.89s/it]                                                       {'loss': 0.8744, 'learning_rate': 1.918362290927825e-05, 'epoch': 0.16}
 16%|█▌        | 809/5198 [2:54:12<15:42:39, 12.89s/it] 16%|█▌        | 810/5198 [2:54:24<15:25:42, 12.66s/it]                                                       {'loss': 0.885, 'learning_rate': 1.9181155327294468e-05, 'epoch': 0.16}
 16%|█▌        | 810/5198 [2:54:24<15:25:42, 12.66s/it] 16%|█▌        | 811/5198 [2:54:36<15:17:11, 12.54s/it]                                                       {'loss': 0.8617, 'learning_rate': 1.9178684180870072e-05, 'epoch': 0.16}
 16%|█▌        | 811/5198 [2:54:36<15:17:11, 12.54s/it] 16%|█▌        | 812/5198 [2:54:49<15:31:22, 12.74s/it]                                                       {'loss': 0.8999, 'learning_rate': 1.9176209470964446e-05, 'epoch': 0.16}
 16%|█▌        | 812/5198 [2:54:49<15:31:22, 12.74s/it] 16%|█▌        | 813/5198 [2:55:01<15:23:15, 12.63s/it]                                                       {'loss': 0.8344, 'learning_rate': 1.9173731198538354e-05, 'epoch': 0.16}
 16%|█▌        | 813/5198 [2:55:01<15:23:15, 12.63s/it] 16%|█▌        | 814/5198 [2:55:13<15:04:20, 12.38s/it]                                                       {'loss': 0.9137, 'learning_rate': 1.9171249364553956e-05, 'epoch': 0.16}
 16%|█▌        | 814/5198 [2:55:13<15:04:20, 12.38s/it] 16%|█▌        | 815/5198 [2:55:28<15:59:59, 13.14s/it]                                                       {'loss': 0.9112, 'learning_rate': 1.9168763969974773e-05, 'epoch': 0.16}
 16%|█▌        | 815/5198 [2:55:28<15:59:59, 13.14s/it] 16%|█▌        | 816/5198 [2:55:43<16:41:53, 13.72s/it]                                                       {'loss': 0.8547, 'learning_rate': 1.916627501576573e-05, 'epoch': 0.16}
 16%|█▌        | 816/5198 [2:55:43<16:41:53, 13.72s/it] 16%|█▌        | 817/5198 [2:55:55<15:55:22, 13.08s/it]                                                       {'loss': 0.9275, 'learning_rate': 1.916378250289312e-05, 'epoch': 0.16}
 16%|█▌        | 817/5198 [2:55:55<15:55:22, 13.08s/it] 16%|█▌        | 818/5198 [2:56:07<15:28:25, 12.72s/it]                                                       {'loss': 0.8913, 'learning_rate': 1.9161286432324628e-05, 'epoch': 0.16}
 16%|█▌        | 818/5198 [2:56:07<15:28:25, 12.72s/it] 16%|█▌        | 819/5198 [2:56:19<15:13:45, 12.52s/it]                                                       {'loss': 0.8999, 'learning_rate': 1.9158786805029307e-05, 'epoch': 0.16}
 16%|█▌        | 819/5198 [2:56:19<15:13:45, 12.52s/it] 16%|█▌        | 820/5198 [2:56:31<15:13:44, 12.52s/it]                                                       {'loss': 0.8777, 'learning_rate': 1.9156283621977603e-05, 'epoch': 0.16}
 16%|█▌        | 820/5198 [2:56:31<15:13:44, 12.52s/it] 16%|█▌        | 821/5198 [2:56:43<15:04:40, 12.40s/it]                                                       {'loss': 0.8712, 'learning_rate': 1.9153776884141336e-05, 'epoch': 0.16}
 16%|█▌        | 821/5198 [2:56:43<15:04:40, 12.40s/it] 16%|█▌        | 822/5198 [2:56:57<15:23:24, 12.66s/it]                                                       {'loss': 0.844, 'learning_rate': 1.915126659249371e-05, 'epoch': 0.16}
 16%|█▌        | 822/5198 [2:56:57<15:23:24, 12.66s/it] 16%|█▌        | 823/5198 [2:57:09<15:24:41, 12.68s/it]                                                       {'loss': 0.9145, 'learning_rate': 1.9148752748009304e-05, 'epoch': 0.16}
 16%|█▌        | 823/5198 [2:57:09<15:24:41, 12.68s/it] 16%|█▌        | 824/5198 [2:57:24<15:58:21, 13.15s/it]                                                       {'loss': 0.9403, 'learning_rate': 1.914623535166408e-05, 'epoch': 0.16}
 16%|█▌        | 824/5198 [2:57:24<15:58:21, 13.15s/it] 16%|█▌        | 825/5198 [2:57:38<16:25:02, 13.52s/it]                                                       {'loss': 0.9075, 'learning_rate': 1.9143714404435382e-05, 'epoch': 0.16}
 16%|█▌        | 825/5198 [2:57:38<16:25:02, 13.52s/it] 16%|█▌        | 826/5198 [2:57:50<15:57:15, 13.14s/it]                                                       {'loss': 0.9319, 'learning_rate': 1.9141189907301922e-05, 'epoch': 0.16}
 16%|█▌        | 826/5198 [2:57:50<15:57:15, 13.14s/it] 16%|█▌        | 827/5198 [2:58:03<15:45:44, 12.98s/it]                                                       {'loss': 0.8707, 'learning_rate': 1.9138661861243802e-05, 'epoch': 0.16}
 16%|█▌        | 827/5198 [2:58:03<15:45:44, 12.98s/it] 16%|█▌        | 828/5198 [2:58:15<15:26:41, 12.72s/it]                                                       {'loss': 0.9075, 'learning_rate': 1.913613026724249e-05, 'epoch': 0.16}
 16%|█▌        | 828/5198 [2:58:15<15:26:41, 12.72s/it] 16%|█▌        | 829/5198 [2:58:27<15:03:33, 12.41s/it]                                                       {'loss': 0.8547, 'learning_rate': 1.9133595126280848e-05, 'epoch': 0.16}
 16%|█▌        | 829/5198 [2:58:27<15:03:33, 12.41s/it] 16%|█▌        | 830/5198 [2:58:40<15:16:03, 12.58s/it]                                                       {'loss': 0.8721, 'learning_rate': 1.9131056439343095e-05, 'epoch': 0.16}
 16%|█▌        | 830/5198 [2:58:40<15:16:03, 12.58s/it] 16%|█▌        | 831/5198 [2:58:52<15:01:48, 12.39s/it]                                                       {'loss': 0.8626, 'learning_rate': 1.9128514207414838e-05, 'epoch': 0.16}
 16%|█▌        | 831/5198 [2:58:52<15:01:48, 12.39s/it] 16%|█▌        | 832/5198 [2:59:04<15:01:55, 12.39s/it]                                                       {'loss': 0.8356, 'learning_rate': 1.9125968431483068e-05, 'epoch': 0.16}
 16%|█▌        | 832/5198 [2:59:04<15:01:55, 12.39s/it] 16%|█▌        | 833/5198 [2:59:16<14:59:31, 12.36s/it]                                                       {'loss': 0.9131, 'learning_rate': 1.9123419112536132e-05, 'epoch': 0.16}
 16%|█▌        | 833/5198 [2:59:16<14:59:31, 12.36s/it] 16%|█▌        | 834/5198 [2:59:29<14:59:06, 12.36s/it]                                                       {'loss': 0.9574, 'learning_rate': 1.912086625156377e-05, 'epoch': 0.16}
 16%|█▌        | 834/5198 [2:59:29<14:59:06, 12.36s/it] 16%|█▌        | 835/5198 [2:59:43<15:37:31, 12.89s/it]                                                       {'loss': 0.8659, 'learning_rate': 1.911830984955709e-05, 'epoch': 0.16}
 16%|█▌        | 835/5198 [2:59:43<15:37:31, 12.89s/it] 16%|█▌        | 836/5198 [2:59:55<15:21:17, 12.67s/it]                                                       {'loss': 0.8999, 'learning_rate': 1.911574990750857e-05, 'epoch': 0.16}
 16%|█▌        | 836/5198 [2:59:55<15:21:17, 12.67s/it] 16%|█▌        | 837/5198 [3:00:09<15:47:33, 13.04s/it]                                                       {'loss': 0.9056, 'learning_rate': 1.9113186426412073e-05, 'epoch': 0.16}
 16%|█▌        | 837/5198 [3:00:09<15:47:33, 13.04s/it] 16%|█▌        | 838/5198 [3:00:25<17:00:07, 14.04s/it]                                                       {'loss': 0.3494, 'learning_rate': 1.9110619407262828e-05, 'epoch': 0.16}
 16%|█▌        | 838/5198 [3:00:25<17:00:07, 14.04s/it] 16%|█▌        | 839/5198 [3:00:37<16:13:44, 13.40s/it]                                                       {'loss': 0.919, 'learning_rate': 1.9108048851057447e-05, 'epoch': 0.16}
 16%|█▌        | 839/5198 [3:00:37<16:13:44, 13.40s/it] 16%|█▌        | 840/5198 [3:00:50<15:54:05, 13.14s/it]                                                       {'loss': 0.8798, 'learning_rate': 1.9105474758793897e-05, 'epoch': 0.16}
 16%|█▌        | 840/5198 [3:00:50<15:54:05, 13.14s/it] 16%|█▌        | 841/5198 [3:01:02<15:31:20, 12.83s/it]                                                       {'loss': 0.9323, 'learning_rate': 1.9102897131471536e-05, 'epoch': 0.16}
 16%|█▌        | 841/5198 [3:01:02<15:31:20, 12.83s/it] 16%|█▌        | 842/5198 [3:01:14<15:28:06, 12.78s/it]                                                       {'loss': 0.8738, 'learning_rate': 1.9100315970091088e-05, 'epoch': 0.16}
 16%|█▌        | 842/5198 [3:01:14<15:28:06, 12.78s/it] 16%|█▌        | 843/5198 [3:01:27<15:25:46, 12.75s/it]                                                       {'loss': 0.89, 'learning_rate': 1.9097731275654645e-05, 'epoch': 0.16}
 16%|█▌        | 843/5198 [3:01:27<15:25:46, 12.75s/it] 16%|█▌        | 844/5198 [3:01:41<15:44:50, 13.02s/it]                                                       {'loss': 0.8975, 'learning_rate': 1.909514304916568e-05, 'epoch': 0.16}
 16%|█▌        | 844/5198 [3:01:41<15:44:50, 13.02s/it] 16%|█▋        | 845/5198 [3:01:53<15:28:19, 12.80s/it]                                                       {'loss': 0.9008, 'learning_rate': 1.9092551291629026e-05, 'epoch': 0.16}
 16%|█▋        | 845/5198 [3:01:53<15:28:19, 12.80s/it] 16%|█▋        | 846/5198 [3:02:10<16:56:06, 14.01s/it]                                                       {'loss': 0.3308, 'learning_rate': 1.9089956004050893e-05, 'epoch': 0.16}
 16%|█▋        | 846/5198 [3:02:10<16:56:06, 14.01s/it] 16%|█▋        | 847/5198 [3:02:26<17:51:36, 14.78s/it]                                                       {'loss': 0.3341, 'learning_rate': 1.908735718743887e-05, 'epoch': 0.16}
 16%|█▋        | 847/5198 [3:02:26<17:51:36, 14.78s/it] 16%|█▋        | 848/5198 [3:02:39<17:04:18, 14.13s/it]                                                       {'loss': 0.9425, 'learning_rate': 1.908475484280189e-05, 'epoch': 0.16}
 16%|█▋        | 848/5198 [3:02:39<17:04:18, 14.13s/it] 16%|█▋        | 849/5198 [3:02:53<17:01:08, 14.09s/it]                                                       {'loss': 0.9038, 'learning_rate': 1.908214897115029e-05, 'epoch': 0.16}
 16%|█▋        | 849/5198 [3:02:53<17:01:08, 14.09s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2254 > 2048). Running this sequence through the model will result in indexing errors
 16%|█▋        | 850/5198 [3:03:06<16:28:52, 13.65s/it]                                                       {'loss': 0.8722, 'learning_rate': 1.907953957349575e-05, 'epoch': 0.16}
 16%|█▋        | 850/5198 [3:03:06<16:28:52, 13.65s/it] 16%|█▋        | 851/5198 [3:03:17<15:43:52, 13.03s/it]                                                       {'loss': 0.9219, 'learning_rate': 1.907692665085133e-05, 'epoch': 0.16}
 16%|█▋        | 851/5198 [3:03:17<15:43:52, 13.03s/it] 16%|█▋        | 852/5198 [3:03:29<15:25:05, 12.77s/it]                                                       {'loss': 0.8944, 'learning_rate': 1.9074310204231457e-05, 'epoch': 0.16}
 16%|█▋        | 852/5198 [3:03:29<15:25:05, 12.77s/it] 16%|█▋        | 853/5198 [3:03:41<15:11:00, 12.58s/it]                                                       {'loss': 0.9213, 'learning_rate': 1.9071690234651923e-05, 'epoch': 0.16}
 16%|█▋        | 853/5198 [3:03:42<15:11:00, 12.58s/it] 16%|█▋        | 854/5198 [3:03:53<14:57:04, 12.39s/it]                                                       {'loss': 0.787, 'learning_rate': 1.9069066743129893e-05, 'epoch': 0.16}
 16%|█▋        | 854/5198 [3:03:53<14:57:04, 12.39s/it] 16%|█▋        | 855/5198 [3:04:06<15:04:16, 12.49s/it]                                                       {'loss': 0.8698, 'learning_rate': 1.90664397306839e-05, 'epoch': 0.16}
 16%|█▋        | 855/5198 [3:04:06<15:04:16, 12.49s/it] 16%|█▋        | 856/5198 [3:04:21<15:47:37, 13.09s/it]                                                       {'loss': 0.8614, 'learning_rate': 1.9063809198333832e-05, 'epoch': 0.16}
 16%|█▋        | 856/5198 [3:04:21<15:47:37, 13.09s/it] 16%|█▋        | 857/5198 [3:04:32<15:13:23, 12.62s/it]                                                       {'loss': 0.878, 'learning_rate': 1.9061175147100957e-05, 'epoch': 0.16}
 16%|█▋        | 857/5198 [3:04:32<15:13:23, 12.62s/it] 17%|█▋        | 858/5198 [3:04:45<15:22:13, 12.75s/it]                                                       {'loss': 0.9351, 'learning_rate': 1.905853757800791e-05, 'epoch': 0.17}
 17%|█▋        | 858/5198 [3:04:45<15:22:13, 12.75s/it] 17%|█▋        | 859/5198 [3:05:01<16:21:51, 13.58s/it]                                                       {'loss': 0.8959, 'learning_rate': 1.9055896492078675e-05, 'epoch': 0.17}
 17%|█▋        | 859/5198 [3:05:01<16:21:51, 13.58s/it] 17%|█▋        | 860/5198 [3:05:13<15:56:23, 13.23s/it]                                                       {'loss': 0.8562, 'learning_rate': 1.905325189033862e-05, 'epoch': 0.17}
 17%|█▋        | 860/5198 [3:05:13<15:56:23, 13.23s/it] 17%|█▋        | 861/5198 [3:05:28<16:21:52, 13.58s/it]                                                       {'loss': 0.8954, 'learning_rate': 1.905060377381447e-05, 'epoch': 0.17}
 17%|█▋        | 861/5198 [3:05:28<16:21:52, 13.58s/it] 17%|█▋        | 862/5198 [3:05:40<15:50:09, 13.15s/it]                                                       {'loss': 0.9665, 'learning_rate': 1.904795214353431e-05, 'epoch': 0.17}
 17%|█▋        | 862/5198 [3:05:40<15:50:09, 13.15s/it] 17%|█▋        | 863/5198 [3:05:53<15:43:57, 13.07s/it]                                                       {'loss': 0.8496, 'learning_rate': 1.90452970005276e-05, 'epoch': 0.17}
 17%|█▋        | 863/5198 [3:05:53<15:43:57, 13.07s/it] 17%|█▋        | 864/5198 [3:06:05<15:32:41, 12.91s/it]                                                       {'loss': 0.9111, 'learning_rate': 1.9042638345825155e-05, 'epoch': 0.17}
 17%|█▋        | 864/5198 [3:06:05<15:32:41, 12.91s/it] 17%|█▋        | 865/5198 [3:06:17<15:06:58, 12.56s/it]                                                       {'loss': 0.8734, 'learning_rate': 1.9039976180459158e-05, 'epoch': 0.17}
 17%|█▋        | 865/5198 [3:06:17<15:06:58, 12.56s/it] 17%|█▋        | 866/5198 [3:06:34<16:37:49, 13.82s/it]                                                       {'loss': 0.3074, 'learning_rate': 1.9037310505463153e-05, 'epoch': 0.17}
 17%|█▋        | 866/5198 [3:06:34<16:37:49, 13.82s/it] 17%|█▋        | 867/5198 [3:06:46<16:00:09, 13.30s/it]                                                       {'loss': 0.9133, 'learning_rate': 1.9034641321872043e-05, 'epoch': 0.17}
 17%|█▋        | 867/5198 [3:06:46<16:00:09, 13.30s/it] 17%|█▋        | 868/5198 [3:06:58<15:43:16, 13.07s/it]                                                       {'loss': 0.911, 'learning_rate': 1.9031968630722104e-05, 'epoch': 0.17}
 17%|█▋        | 868/5198 [3:06:58<15:43:16, 13.07s/it] 17%|█▋        | 869/5198 [3:07:11<15:37:47, 13.00s/it]                                                       {'loss': 0.8818, 'learning_rate': 1.902929243305096e-05, 'epoch': 0.17}
 17%|█▋        | 869/5198 [3:07:11<15:37:47, 13.00s/it] 17%|█▋        | 870/5198 [3:07:24<15:38:40, 13.01s/it]                                                       {'loss': 0.8666, 'learning_rate': 1.902661272989761e-05, 'epoch': 0.17}
 17%|█▋        | 870/5198 [3:07:24<15:38:40, 13.01s/it] 17%|█▋        | 871/5198 [3:07:37<15:35:39, 12.97s/it]                                                       {'loss': 0.8787, 'learning_rate': 1.9023929522302394e-05, 'epoch': 0.17}
 17%|█▋        | 871/5198 [3:07:37<15:35:39, 12.97s/it] 17%|█▋        | 872/5198 [3:07:50<15:37:03, 13.00s/it]                                                       {'loss': 0.846, 'learning_rate': 1.9021242811307044e-05, 'epoch': 0.17}
 17%|█▋        | 872/5198 [3:07:50<15:37:03, 13.00s/it] 17%|█▋        | 873/5198 [3:08:05<16:28:48, 13.72s/it]                                                       {'loss': 0.8612, 'learning_rate': 1.901855259795462e-05, 'epoch': 0.17}
 17%|█▋        | 873/5198 [3:08:06<16:28:48, 13.72s/it] 17%|█▋        | 874/5198 [3:08:18<16:01:12, 13.34s/it]                                                       {'loss': 0.8764, 'learning_rate': 1.9015858883289556e-05, 'epoch': 0.17}
 17%|█▋        | 874/5198 [3:08:18<16:01:12, 13.34s/it] 17%|█▋        | 875/5198 [3:08:31<15:50:35, 13.19s/it]                                                       {'loss': 0.8668, 'learning_rate': 1.9013161668357655e-05, 'epoch': 0.17}
 17%|█▋        | 875/5198 [3:08:31<15:50:35, 13.19s/it] 17%|█▋        | 876/5198 [3:08:42<15:17:45, 12.74s/it]                                                       {'loss': 0.847, 'learning_rate': 1.901046095420606e-05, 'epoch': 0.17}
 17%|█▋        | 876/5198 [3:08:42<15:17:45, 12.74s/it] 17%|█▋        | 877/5198 [3:08:55<15:02:44, 12.54s/it]                                                       {'loss': 0.8801, 'learning_rate': 1.9007756741883284e-05, 'epoch': 0.17}
 17%|█▋        | 877/5198 [3:08:55<15:02:44, 12.54s/it] 17%|█▋        | 878/5198 [3:09:07<14:55:11, 12.43s/it]                                                       {'loss': 0.8865, 'learning_rate': 1.9005049032439193e-05, 'epoch': 0.17}
 17%|█▋        | 878/5198 [3:09:07<14:55:11, 12.43s/it] 17%|█▋        | 879/5198 [3:09:19<14:56:50, 12.46s/it]                                                       {'loss': 0.899, 'learning_rate': 1.9002337826925012e-05, 'epoch': 0.17}
 17%|█▋        | 879/5198 [3:09:19<14:56:50, 12.46s/it] 17%|█▋        | 880/5198 [3:09:31<14:47:31, 12.33s/it]                                                       {'loss': 0.8664, 'learning_rate': 1.899962312639333e-05, 'epoch': 0.17}
 17%|█▋        | 880/5198 [3:09:31<14:47:31, 12.33s/it] 17%|█▋        | 881/5198 [3:09:49<16:37:37, 13.87s/it]                                                       {'loss': 0.3353, 'learning_rate': 1.8996904931898085e-05, 'epoch': 0.17}
 17%|█▋        | 881/5198 [3:09:49<16:37:37, 13.87s/it] 17%|█▋        | 882/5198 [3:10:00<15:48:53, 13.19s/it]                                                       {'loss': 0.8367, 'learning_rate': 1.899418324449457e-05, 'epoch': 0.17}
 17%|█▋        | 882/5198 [3:10:00<15:48:53, 13.19s/it] 17%|█▋        | 883/5198 [3:10:12<15:11:18, 12.67s/it]                                                       {'loss': 0.8867, 'learning_rate': 1.8991458065239444e-05, 'epoch': 0.17}
 17%|█▋        | 883/5198 [3:10:12<15:11:18, 12.67s/it] 17%|█▋        | 884/5198 [3:10:25<15:12:42, 12.69s/it]                                                       {'loss': 0.8989, 'learning_rate': 1.8988729395190712e-05, 'epoch': 0.17}
 17%|█▋        | 884/5198 [3:10:25<15:12:42, 12.69s/it] 17%|█▋        | 885/5198 [3:10:39<15:48:21, 13.19s/it]                                                       {'loss': 0.9104, 'learning_rate': 1.8985997235407735e-05, 'epoch': 0.17}
 17%|█▋        | 885/5198 [3:10:39<15:48:21, 13.19s/it] 17%|█▋        | 886/5198 [3:10:51<15:16:00, 12.75s/it]                                                       {'loss': 0.9259, 'learning_rate': 1.898326158695124e-05, 'epoch': 0.17}
 17%|█▋        | 886/5198 [3:10:51<15:16:00, 12.75s/it] 17%|█▋        | 887/5198 [3:11:06<16:05:47, 13.44s/it]                                                       {'loss': 0.8518, 'learning_rate': 1.8980522450883287e-05, 'epoch': 0.17}
 17%|█▋        | 887/5198 [3:11:06<16:05:47, 13.44s/it] 17%|█▋        | 888/5198 [3:11:17<15:21:34, 12.83s/it]                                                       {'loss': 0.9162, 'learning_rate': 1.8977779828267314e-05, 'epoch': 0.17}
 17%|█▋        | 888/5198 [3:11:17<15:21:34, 12.83s/it] 17%|█▋        | 889/5198 [3:11:30<15:16:26, 12.76s/it]                                                       {'loss': 0.834, 'learning_rate': 1.8975033720168094e-05, 'epoch': 0.17}
 17%|█▋        | 889/5198 [3:11:30<15:16:26, 12.76s/it] 17%|█▋        | 890/5198 [3:11:44<15:56:19, 13.32s/it]                                                       {'loss': 0.8899, 'learning_rate': 1.897228412765177e-05, 'epoch': 0.17}
 17%|█▋        | 890/5198 [3:11:44<15:56:19, 13.32s/it] 17%|█▋        | 891/5198 [3:11:56<15:20:18, 12.82s/it]                                                       {'loss': 0.9002, 'learning_rate': 1.896953105178582e-05, 'epoch': 0.17}
 17%|█▋        | 891/5198 [3:11:56<15:20:18, 12.82s/it] 17%|█▋        | 892/5198 [3:12:08<15:01:10, 12.56s/it]                                                       {'loss': 0.9106, 'learning_rate': 1.8966774493639084e-05, 'epoch': 0.17}
 17%|█▋        | 892/5198 [3:12:08<15:01:10, 12.56s/it] 17%|█▋        | 893/5198 [3:12:21<15:04:45, 12.61s/it]                                                       {'loss': 0.9485, 'learning_rate': 1.896401445428176e-05, 'epoch': 0.17}
 17%|█▋        | 893/5198 [3:12:21<15:04:45, 12.61s/it] 17%|█▋        | 894/5198 [3:12:34<15:16:39, 12.78s/it]                                                       {'loss': 0.807, 'learning_rate': 1.896125093478538e-05, 'epoch': 0.17}
 17%|█▋        | 894/5198 [3:12:34<15:16:39, 12.78s/it] 17%|█▋        | 895/5198 [3:12:46<15:08:09, 12.66s/it]                                                       {'loss': 0.8596, 'learning_rate': 1.895848393622284e-05, 'epoch': 0.17}
 17%|█▋        | 895/5198 [3:12:46<15:08:09, 12.66s/it] 17%|█▋        | 896/5198 [3:12:58<14:58:13, 12.53s/it]                                                       {'loss': 0.8499, 'learning_rate': 1.895571345966839e-05, 'epoch': 0.17}
 17%|█▋        | 896/5198 [3:12:58<14:58:13, 12.53s/it] 17%|█▋        | 897/5198 [3:13:16<16:37:50, 13.92s/it]                                                       {'loss': 0.3469, 'learning_rate': 1.8952939506197622e-05, 'epoch': 0.17}
 17%|█▋        | 897/5198 [3:13:16<16:37:50, 13.92s/it] 17%|█▋        | 898/5198 [3:13:28<16:06:21, 13.48s/it]                                                       {'loss': 0.8643, 'learning_rate': 1.8950162076887477e-05, 'epoch': 0.17}
 17%|█▋        | 898/5198 [3:13:28<16:06:21, 13.48s/it] 17%|█▋        | 899/5198 [3:13:40<15:41:42, 13.14s/it]                                                       {'loss': 0.863, 'learning_rate': 1.894738117281625e-05, 'epoch': 0.17}
 17%|█▋        | 899/5198 [3:13:40<15:41:42, 13.14s/it] 17%|█▋        | 900/5198 [3:13:56<16:36:17, 13.91s/it]                                                       {'loss': 0.9051, 'learning_rate': 1.8944596795063584e-05, 'epoch': 0.17}
 17%|█▋        | 900/5198 [3:13:56<16:36:17, 13.91s/it] 17%|█▋        | 901/5198 [3:14:12<17:11:11, 14.40s/it]                                                       {'loss': 0.9084, 'learning_rate': 1.894180894471047e-05, 'epoch': 0.17}
 17%|█▋        | 901/5198 [3:14:12<17:11:11, 14.40s/it] 17%|█▋        | 902/5198 [3:14:24<16:29:57, 13.83s/it]                                                       {'loss': 0.8875, 'learning_rate': 1.8939017622839253e-05, 'epoch': 0.17}
 17%|█▋        | 902/5198 [3:14:24<16:29:57, 13.83s/it] 17%|█▋        | 903/5198 [3:14:36<15:55:23, 13.35s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.8936222830533613e-05, 'epoch': 0.17}
 17%|█▋        | 903/5198 [3:14:36<15:55:23, 13.35s/it] 17%|█▋        | 904/5198 [3:14:52<16:39:29, 13.97s/it]                                                       {'loss': 0.8495, 'learning_rate': 1.8933424568878586e-05, 'epoch': 0.17}
 17%|█▋        | 904/5198 [3:14:52<16:39:29, 13.97s/it] 17%|█▋        | 905/5198 [3:15:04<16:02:31, 13.45s/it]                                                       {'loss': 0.9324, 'learning_rate': 1.8930622838960555e-05, 'epoch': 0.17}
 17%|█▋        | 905/5198 [3:15:04<16:02:31, 13.45s/it] 17%|█▋        | 906/5198 [3:15:16<15:28:59, 12.99s/it]                                                       {'loss': 0.9124, 'learning_rate': 1.8927817641867244e-05, 'epoch': 0.17}
 17%|█▋        | 906/5198 [3:15:16<15:28:59, 12.99s/it] 17%|█▋        | 907/5198 [3:15:28<15:07:00, 12.68s/it]                                                       {'loss': 0.8338, 'learning_rate': 1.8925008978687737e-05, 'epoch': 0.17}
 17%|█▋        | 907/5198 [3:15:28<15:07:00, 12.68s/it] 17%|█▋        | 908/5198 [3:15:44<16:25:11, 13.78s/it]                                                       {'loss': 0.3599, 'learning_rate': 1.8922196850512446e-05, 'epoch': 0.17}
 17%|█▋        | 908/5198 [3:15:44<16:25:11, 13.78s/it] 17%|█▋        | 909/5198 [3:15:56<15:48:10, 13.26s/it]                                                       {'loss': 0.9012, 'learning_rate': 1.8919381258433135e-05, 'epoch': 0.17}
 17%|█▋        | 909/5198 [3:15:56<15:48:10, 13.26s/it] 18%|█▊        | 910/5198 [3:16:09<15:34:31, 13.08s/it]                                                       {'loss': 0.8828, 'learning_rate': 1.8916562203542916e-05, 'epoch': 0.18}
 18%|█▊        | 910/5198 [3:16:09<15:34:31, 13.08s/it] 18%|█▊        | 911/5198 [3:16:22<15:35:02, 13.09s/it]                                                       {'loss': 0.8899, 'learning_rate': 1.8913739686936244e-05, 'epoch': 0.18}
 18%|█▊        | 911/5198 [3:16:22<15:35:02, 13.09s/it] 18%|█▊        | 912/5198 [3:16:34<15:12:15, 12.77s/it]                                                       {'loss': 0.9049, 'learning_rate': 1.8910913709708918e-05, 'epoch': 0.18}
 18%|█▊        | 912/5198 [3:16:34<15:12:15, 12.77s/it] 18%|█▊        | 913/5198 [3:16:46<14:53:42, 12.51s/it]                                                       {'loss': 0.8705, 'learning_rate': 1.8908084272958077e-05, 'epoch': 0.18}
 18%|█▊        | 913/5198 [3:16:46<14:53:42, 12.51s/it] 18%|█▊        | 914/5198 [3:16:59<14:56:48, 12.56s/it]                                                       {'loss': 0.8401, 'learning_rate': 1.8905251377782206e-05, 'epoch': 0.18}
 18%|█▊        | 914/5198 [3:16:59<14:56:48, 12.56s/it] 18%|█▊        | 915/5198 [3:17:11<14:45:05, 12.40s/it]                                                       {'loss': 0.9068, 'learning_rate': 1.8902415025281136e-05, 'epoch': 0.18}
 18%|█▊        | 915/5198 [3:17:11<14:45:05, 12.40s/it] 18%|█▊        | 916/5198 [3:17:22<14:31:48, 12.22s/it]                                                       {'loss': 0.8768, 'learning_rate': 1.889957521655603e-05, 'epoch': 0.18}
 18%|█▊        | 916/5198 [3:17:22<14:31:48, 12.22s/it] 18%|█▊        | 917/5198 [3:17:34<14:25:12, 12.13s/it]                                                       {'loss': 0.8553, 'learning_rate': 1.8896731952709408e-05, 'epoch': 0.18}
 18%|█▊        | 917/5198 [3:17:34<14:25:12, 12.13s/it] 18%|█▊        | 918/5198 [3:17:48<15:02:53, 12.66s/it]                                                       {'loss': 0.9057, 'learning_rate': 1.8893885234845117e-05, 'epoch': 0.18}
 18%|█▊        | 918/5198 [3:17:48<15:02:53, 12.66s/it] 18%|█▊        | 919/5198 [3:18:00<14:45:20, 12.41s/it]                                                       {'loss': 0.8717, 'learning_rate': 1.8891035064068354e-05, 'epoch': 0.18}
 18%|█▊        | 919/5198 [3:18:00<14:45:20, 12.41s/it] 18%|█▊        | 920/5198 [3:18:13<15:05:03, 12.69s/it]                                                       {'loss': 0.8816, 'learning_rate': 1.888818144148565e-05, 'epoch': 0.18}
 18%|█▊        | 920/5198 [3:18:14<15:05:03, 12.69s/it] 18%|█▊        | 921/5198 [3:18:27<15:15:28, 12.84s/it]                                                       {'loss': 0.8145, 'learning_rate': 1.888532436820488e-05, 'epoch': 0.18}
 18%|█▊        | 921/5198 [3:18:27<15:15:28, 12.84s/it] 18%|█▊        | 922/5198 [3:18:39<15:10:11, 12.77s/it]                                                       {'loss': 0.8239, 'learning_rate': 1.8882463845335263e-05, 'epoch': 0.18}
 18%|█▊        | 922/5198 [3:18:39<15:10:11, 12.77s/it] 18%|█▊        | 923/5198 [3:18:51<14:51:35, 12.51s/it]                                                       {'loss': 0.841, 'learning_rate': 1.8879599873987343e-05, 'epoch': 0.18}
 18%|█▊        | 923/5198 [3:18:51<14:51:35, 12.51s/it] 18%|█▊        | 924/5198 [3:19:04<14:52:10, 12.52s/it]                                                       {'loss': 0.8507, 'learning_rate': 1.8876732455273022e-05, 'epoch': 0.18}
 18%|█▊        | 924/5198 [3:19:04<14:52:10, 12.52s/it] 18%|█▊        | 925/5198 [3:19:15<14:34:29, 12.28s/it]                                                       {'loss': 0.9107, 'learning_rate': 1.8873861590305527e-05, 'epoch': 0.18}
 18%|█▊        | 925/5198 [3:19:15<14:34:29, 12.28s/it] 18%|█▊        | 926/5198 [3:19:32<16:08:18, 13.60s/it]                                                       {'loss': 0.3715, 'learning_rate': 1.8870987280199428e-05, 'epoch': 0.18}
 18%|█▊        | 926/5198 [3:19:32<16:08:18, 13.60s/it] 18%|█▊        | 927/5198 [3:19:45<15:50:24, 13.35s/it]                                                       {'loss': 0.9165, 'learning_rate': 1.886810952607063e-05, 'epoch': 0.18}
 18%|█▊        | 927/5198 [3:19:45<15:50:24, 13.35s/it] 18%|█▊        | 928/5198 [3:19:57<15:23:37, 12.98s/it]                                                       {'loss': 0.8668, 'learning_rate': 1.8865228329036372e-05, 'epoch': 0.18}
 18%|█▊        | 928/5198 [3:19:57<15:23:37, 12.98s/it] 18%|█▊        | 929/5198 [3:20:09<15:00:41, 12.66s/it]                                                       {'loss': 0.9381, 'learning_rate': 1.886234369021524e-05, 'epoch': 0.18}
 18%|█▊        | 929/5198 [3:20:09<15:00:41, 12.66s/it] 18%|█▊        | 930/5198 [3:20:21<14:54:14, 12.57s/it]                                                       {'loss': 0.8772, 'learning_rate': 1.885945561072715e-05, 'epoch': 0.18}
 18%|█▊        | 930/5198 [3:20:21<14:54:14, 12.57s/it] 18%|█▊        | 931/5198 [3:20:37<15:54:30, 13.42s/it]                                                       {'loss': 0.876, 'learning_rate': 1.885656409169335e-05, 'epoch': 0.18}
 18%|█▊        | 931/5198 [3:20:37<15:54:30, 13.42s/it] 18%|█▊        | 932/5198 [3:20:52<16:33:21, 13.97s/it]                                                       {'loss': 0.9148, 'learning_rate': 1.885366913423643e-05, 'epoch': 0.18}
 18%|█▊        | 932/5198 [3:20:52<16:33:21, 13.97s/it] 18%|█▊        | 933/5198 [3:21:05<16:06:46, 13.60s/it]                                                       {'loss': 0.9237, 'learning_rate': 1.8850770739480312e-05, 'epoch': 0.18}
 18%|█▊        | 933/5198 [3:21:05<16:06:46, 13.60s/it] 18%|█▊        | 934/5198 [3:21:17<15:33:22, 13.13s/it]                                                       {'loss': 0.8202, 'learning_rate': 1.8847868908550252e-05, 'epoch': 0.18}
 18%|█▊        | 934/5198 [3:21:17<15:33:22, 13.13s/it] 18%|█▊        | 935/5198 [3:21:30<15:29:03, 13.08s/it]                                                       {'loss': 0.846, 'learning_rate': 1.8844963642572837e-05, 'epoch': 0.18}
 18%|█▊        | 935/5198 [3:21:30<15:29:03, 13.08s/it] 18%|█▊        | 936/5198 [3:21:42<15:23:19, 13.00s/it]                                                       {'loss': 0.8834, 'learning_rate': 1.8842054942676e-05, 'epoch': 0.18}
 18%|█▊        | 936/5198 [3:21:42<15:23:19, 13.00s/it] 18%|█▊        | 937/5198 [3:21:55<15:23:31, 13.00s/it]                                                       {'loss': 0.84, 'learning_rate': 1.8839142809988987e-05, 'epoch': 0.18}
 18%|█▊        | 937/5198 [3:21:56<15:23:31, 13.00s/it] 18%|█▊        | 938/5198 [3:22:08<15:15:28, 12.89s/it]                                                       {'loss': 0.824, 'learning_rate': 1.88362272456424e-05, 'epoch': 0.18}
 18%|█▊        | 938/5198 [3:22:08<15:15:28, 12.89s/it] 18%|█▊        | 939/5198 [3:22:20<15:03:29, 12.73s/it]                                                       {'loss': 0.8559, 'learning_rate': 1.8833308250768153e-05, 'epoch': 0.18}
 18%|█▊        | 939/5198 [3:22:20<15:03:29, 12.73s/it] 18%|█▊        | 940/5198 [3:22:34<15:22:43, 13.00s/it]                                                       {'loss': 0.8635, 'learning_rate': 1.8830385826499507e-05, 'epoch': 0.18}
 18%|█▊        | 940/5198 [3:22:34<15:22:43, 13.00s/it] 18%|█▊        | 941/5198 [3:22:45<14:48:18, 12.52s/it]                                                       {'loss': 0.8696, 'learning_rate': 1.882745997397104e-05, 'epoch': 0.18}
 18%|█▊        | 941/5198 [3:22:46<14:48:18, 12.52s/it] 18%|█▊        | 942/5198 [3:22:58<14:38:31, 12.39s/it]                                                       {'loss': 0.8581, 'learning_rate': 1.8824530694318675e-05, 'epoch': 0.18}
 18%|█▊        | 942/5198 [3:22:58<14:38:31, 12.39s/it] 18%|█▊        | 943/5198 [3:23:11<14:54:41, 12.62s/it]                                                       {'loss': 0.8652, 'learning_rate': 1.882159798867966e-05, 'epoch': 0.18}
 18%|█▊        | 943/5198 [3:23:11<14:54:41, 12.62s/it] 18%|█▊        | 944/5198 [3:23:23<14:47:51, 12.52s/it]                                                       {'loss': 0.9453, 'learning_rate': 1.8818661858192562e-05, 'epoch': 0.18}
 18%|█▊        | 944/5198 [3:23:23<14:47:51, 12.52s/it] 18%|█▊        | 945/5198 [3:23:36<15:04:09, 12.76s/it]                                                       {'loss': 0.8942, 'learning_rate': 1.88157223039973e-05, 'epoch': 0.18}
 18%|█▊        | 945/5198 [3:23:36<15:04:09, 12.76s/it] 18%|█▊        | 946/5198 [3:23:53<16:24:42, 13.90s/it]                                                       {'loss': 0.3641, 'learning_rate': 1.8812779327235106e-05, 'epoch': 0.18}
 18%|█▊        | 946/5198 [3:23:53<16:24:42, 13.90s/it] 18%|█▊        | 947/5198 [3:24:05<15:52:20, 13.44s/it]                                                       {'loss': 0.8854, 'learning_rate': 1.880983292904854e-05, 'epoch': 0.18}
 18%|█▊        | 947/5198 [3:24:05<15:52:20, 13.44s/it] 18%|█▊        | 948/5198 [3:24:18<15:41:13, 13.29s/it]                                                       {'loss': 0.8896, 'learning_rate': 1.88068831105815e-05, 'epoch': 0.18}
 18%|█▊        | 948/5198 [3:24:18<15:41:13, 13.29s/it] 18%|█▊        | 949/5198 [3:24:30<15:18:53, 12.98s/it]                                                       {'loss': 0.8932, 'learning_rate': 1.8803929872979214e-05, 'epoch': 0.18}
 18%|█▊        | 949/5198 [3:24:30<15:18:53, 12.98s/it] 18%|█▊        | 950/5198 [3:24:43<15:04:00, 12.77s/it]                                                       {'loss': 0.8767, 'learning_rate': 1.8800973217388215e-05, 'epoch': 0.18}
 18%|█▊        | 950/5198 [3:24:43<15:04:00, 12.77s/it] 18%|█▊        | 951/5198 [3:24:55<14:45:41, 12.51s/it]                                                       {'loss': 0.8893, 'learning_rate': 1.879801314495639e-05, 'epoch': 0.18}
 18%|█▊        | 951/5198 [3:24:55<14:45:41, 12.51s/it] 18%|█▊        | 952/5198 [3:25:08<15:04:30, 12.78s/it]                                                       {'loss': 0.9115, 'learning_rate': 1.879504965683294e-05, 'epoch': 0.18}
 18%|█▊        | 952/5198 [3:25:08<15:04:30, 12.78s/it] 18%|█▊        | 953/5198 [3:25:20<14:36:43, 12.39s/it]                                                       {'loss': 0.8319, 'learning_rate': 1.8792082754168385e-05, 'epoch': 0.18}
 18%|█▊        | 953/5198 [3:25:20<14:36:43, 12.39s/it] 18%|█▊        | 954/5198 [3:25:32<14:29:53, 12.30s/it]                                                       {'loss': 0.8363, 'learning_rate': 1.878911243811459e-05, 'epoch': 0.18}
 18%|█▊        | 954/5198 [3:25:32<14:29:53, 12.30s/it] 18%|█▊        | 955/5198 [3:25:44<14:38:33, 12.42s/it]                                                       {'loss': 0.8002, 'learning_rate': 1.8786138709824726e-05, 'epoch': 0.18}
 18%|█▊        | 955/5198 [3:25:44<14:38:33, 12.42s/it] 18%|█▊        | 956/5198 [3:25:58<15:04:48, 12.80s/it]                                                       {'loss': 0.8429, 'learning_rate': 1.8783161570453295e-05, 'epoch': 0.18}
 18%|█▊        | 956/5198 [3:25:58<15:04:48, 12.80s/it] 18%|█▊        | 957/5198 [3:26:10<14:57:47, 12.70s/it]                                                       {'loss': 0.8828, 'learning_rate': 1.878018102115614e-05, 'epoch': 0.18}
 18%|█▊        | 957/5198 [3:26:11<14:57:47, 12.70s/it] 18%|█▊        | 958/5198 [3:26:23<14:52:45, 12.63s/it]                                                       {'loss': 0.854, 'learning_rate': 1.8777197063090394e-05, 'epoch': 0.18}
 18%|█▊        | 958/5198 [3:26:23<14:52:45, 12.63s/it] 18%|█▊        | 959/5198 [3:26:35<14:46:20, 12.55s/it]                                                       {'loss': 0.863, 'learning_rate': 1.877420969741454e-05, 'epoch': 0.18}
 18%|█▊        | 959/5198 [3:26:35<14:46:20, 12.55s/it] 18%|█▊        | 960/5198 [3:26:48<14:59:40, 12.74s/it]                                                       {'loss': 0.8796, 'learning_rate': 1.877121892528838e-05, 'epoch': 0.18}
 18%|█▊        | 960/5198 [3:26:49<14:59:40, 12.74s/it] 18%|█▊        | 961/5198 [3:27:01<14:52:40, 12.64s/it]                                                       {'loss': 0.8758, 'learning_rate': 1.876822474787303e-05, 'epoch': 0.18}
 18%|█▊        | 961/5198 [3:27:01<14:52:40, 12.64s/it] 19%|█▊        | 962/5198 [3:27:16<15:48:17, 13.43s/it]                                                       {'loss': 0.8973, 'learning_rate': 1.8765227166330933e-05, 'epoch': 0.19}
 19%|█▊        | 962/5198 [3:27:16<15:48:17, 13.43s/it] 19%|█▊        | 963/5198 [3:27:28<15:11:44, 12.92s/it]                                                       {'loss': 0.8948, 'learning_rate': 1.8762226181825857e-05, 'epoch': 0.19}
 19%|█▊        | 963/5198 [3:27:28<15:11:44, 12.92s/it] 19%|█▊        | 964/5198 [3:27:40<14:54:39, 12.68s/it]                                                       {'loss': 0.9327, 'learning_rate': 1.875922179552288e-05, 'epoch': 0.19}
 19%|█▊        | 964/5198 [3:27:40<14:54:39, 12.68s/it] 19%|█▊        | 965/5198 [3:27:56<15:56:06, 13.55s/it]                                                       {'loss': 0.9179, 'learning_rate': 1.875621400858842e-05, 'epoch': 0.19}
 19%|█▊        | 965/5198 [3:27:56<15:56:06, 13.55s/it] 19%|█▊        | 966/5198 [3:28:07<15:14:30, 12.97s/it]                                                       {'loss': 0.8725, 'learning_rate': 1.875320282219019e-05, 'epoch': 0.19}
 19%|█▊        | 966/5198 [3:28:07<15:14:30, 12.97s/it] 19%|█▊        | 967/5198 [3:28:20<15:01:57, 12.79s/it]                                                       {'loss': 0.8911, 'learning_rate': 1.8750188237497247e-05, 'epoch': 0.19}
 19%|█▊        | 967/5198 [3:28:20<15:01:57, 12.79s/it] 19%|█▊        | 968/5198 [3:28:32<14:53:42, 12.68s/it]                                                       {'loss': 0.8045, 'learning_rate': 1.874717025567995e-05, 'epoch': 0.19}
 19%|█▊        | 968/5198 [3:28:32<14:53:42, 12.68s/it] 19%|█▊        | 969/5198 [3:28:44<14:40:05, 12.49s/it]                                                       {'loss': 0.9138, 'learning_rate': 1.874414887790999e-05, 'epoch': 0.19}
 19%|█▊        | 969/5198 [3:28:44<14:40:05, 12.49s/it] 19%|█▊        | 970/5198 [3:28:56<14:25:39, 12.28s/it]                                                       {'loss': 0.9205, 'learning_rate': 1.8741124105360363e-05, 'epoch': 0.19}
 19%|█▊        | 970/5198 [3:28:56<14:25:39, 12.28s/it] 19%|█▊        | 971/5198 [3:29:09<14:36:24, 12.44s/it]                                                       {'loss': 0.809, 'learning_rate': 1.873809593920539e-05, 'epoch': 0.19}
 19%|█▊        | 971/5198 [3:29:09<14:36:24, 12.44s/it] 19%|█▊        | 972/5198 [3:29:21<14:24:52, 12.28s/it]                                                       {'loss': 0.9189, 'learning_rate': 1.8735064380620717e-05, 'epoch': 0.19}
 19%|█▊        | 972/5198 [3:29:21<14:24:52, 12.28s/it] 19%|█▊        | 973/5198 [3:29:38<16:05:59, 13.72s/it]                                                       {'loss': 0.346, 'learning_rate': 1.873202943078329e-05, 'epoch': 0.19}
 19%|█▊        | 973/5198 [3:29:38<16:05:59, 13.72s/it] 19%|█▊        | 974/5198 [3:29:50<15:42:49, 13.39s/it]                                                       {'loss': 0.8706, 'learning_rate': 1.8728991090871387e-05, 'epoch': 0.19}
 19%|█▊        | 974/5198 [3:29:50<15:42:49, 13.39s/it] 19%|█▉        | 975/5198 [3:30:02<15:16:56, 13.03s/it]                                                       {'loss': 0.8673, 'learning_rate': 1.8725949362064596e-05, 'epoch': 0.19}
 19%|█▉        | 975/5198 [3:30:02<15:16:56, 13.03s/it] 19%|█▉        | 976/5198 [3:30:16<15:17:58, 13.05s/it]                                                       {'loss': 0.9873, 'learning_rate': 1.8722904245543817e-05, 'epoch': 0.19}
 19%|█▉        | 976/5198 [3:30:16<15:17:58, 13.05s/it] 19%|█▉        | 977/5198 [3:30:28<15:00:36, 12.80s/it]                                                       {'loss': 0.8816, 'learning_rate': 1.871985574249127e-05, 'epoch': 0.19}
 19%|█▉        | 977/5198 [3:30:28<15:00:36, 12.80s/it] 19%|█▉        | 978/5198 [3:30:43<15:56:57, 13.61s/it]                                                       {'loss': 0.8619, 'learning_rate': 1.8716803854090495e-05, 'epoch': 0.19}
 19%|█▉        | 978/5198 [3:30:43<15:56:57, 13.61s/it] 19%|█▉        | 979/5198 [3:30:55<15:14:13, 13.00s/it]                                                       {'loss': 0.85, 'learning_rate': 1.8713748581526334e-05, 'epoch': 0.19}
 19%|█▉        | 979/5198 [3:30:55<15:14:13, 13.00s/it] 19%|█▉        | 980/5198 [3:31:08<15:15:41, 13.03s/it]                                                       {'loss': 0.8306, 'learning_rate': 1.871068992598495e-05, 'epoch': 0.19}
 19%|█▉        | 980/5198 [3:31:08<15:15:41, 13.03s/it] 19%|█▉        | 981/5198 [3:31:20<15:01:09, 12.82s/it]                                                       {'loss': 0.8686, 'learning_rate': 1.8707627888653816e-05, 'epoch': 0.19}
 19%|█▉        | 981/5198 [3:31:20<15:01:09, 12.82s/it] 19%|█▉        | 982/5198 [3:31:32<14:35:24, 12.46s/it]                                                       {'loss': 0.8653, 'learning_rate': 1.8704562470721728e-05, 'epoch': 0.19}
 19%|█▉        | 982/5198 [3:31:32<14:35:24, 12.46s/it] 19%|█▉        | 983/5198 [3:31:44<14:28:34, 12.36s/it]                                                       {'loss': 0.8534, 'learning_rate': 1.870149367337878e-05, 'epoch': 0.19}
 19%|█▉        | 983/5198 [3:31:44<14:28:34, 12.36s/it] 19%|█▉        | 984/5198 [3:31:56<14:22:16, 12.28s/it]                                                       {'loss': 0.8936, 'learning_rate': 1.8698421497816386e-05, 'epoch': 0.19}
 19%|█▉        | 984/5198 [3:31:56<14:22:16, 12.28s/it] 19%|█▉        | 985/5198 [3:32:09<14:32:35, 12.43s/it]                                                       {'loss': 0.904, 'learning_rate': 1.869534594522727e-05, 'epoch': 0.19}
 19%|█▉        | 985/5198 [3:32:09<14:32:35, 12.43s/it] 19%|█▉        | 986/5198 [3:32:22<14:41:05, 12.55s/it]                                                       {'loss': 0.9345, 'learning_rate': 1.8692267016805473e-05, 'epoch': 0.19}
 19%|█▉        | 986/5198 [3:32:22<14:41:05, 12.55s/it] 19%|█▉        | 987/5198 [3:32:34<14:32:39, 12.43s/it]                                                       {'loss': 0.9207, 'learning_rate': 1.8689184713746333e-05, 'epoch': 0.19}
 19%|█▉        | 987/5198 [3:32:34<14:32:39, 12.43s/it] 19%|█▉        | 988/5198 [3:32:46<14:23:56, 12.31s/it]                                                       {'loss': 0.8614, 'learning_rate': 1.868609903724651e-05, 'epoch': 0.19}
 19%|█▉        | 988/5198 [3:32:46<14:23:56, 12.31s/it]